{"pod": "Lex Fridman Podcast", "input": "Introduction", "output": "- The competence and capability and intelligence and training and accomplishments of senior scientists\nand technologists working on a technology, and then being able to then make moral judgments in the use\nof the technology. That track record is terrible. That track record is catastrophically bad.\nThe policies that are being called for to prevent this, I think we're gonna cause extraordinary damage.\n- So the moment you say, AI's gonna kill all of us, therefore we should ban it, or that we should regulate all that kind of stuff,\nthat's when it starts getting serious. - Or start, you know, military airstrikes and data centers. - Oh boy.\nThe following is a conversation with Marc Andreessen, co-creator of Mosaic, the first widely used web browser,\nco-founder of Netscape, co-founder of the legendary Silicon Valley venture capital firm, Andreesen Horowitz,\nand is one of the most outspoken voices on the future of technology, including his most recent article,\n\"Why AI Will Save The World?\" This is Lex Fridman podcast.\nTo support it, please check out our sponsors in the description. And now, dear friends, here's Marc Andreessen.\n"}
{"pod": "Lex Fridman Podcast", "input": "Google Search", "output": "I think you're the right person to talk about the future of the internet and technology in general.\nDo you think we'll still have Google search in 5 in 10 years, or search in general?\n- Yes. You know, it would be a question if the use cases have really narrowed down. - Well, now with AI--\n- [Marc] Yeah. - And AI assistance being able to interact and expose\nthe entirety of human wisdom and knowledge and information and facts and truth to us\nvia the natural language interface. It seems like that's what search is designed to do.\nAnd if AI assistance can do that better, doesn't the nature of search change? - Sure. But we still have horses.\n- Okay. (both laugh) When's the last time you rode a horse? - It's been a while.\n- All right. (both laugh) So, but what I mean is, well, we still have Google search as the primary way\nthat human civilization uses to interact with knowledge. - I mean, search was a technology,\nit was a moment in time technology, which is you have in theory, the world's information out on the web. And, you know, this is sort of the optimal way to get to it.\nBut yeah, like, and by the way, actually Google, Google has known this for a long time. I mean, they've been driving away from the 10 blue links\nyou know, for like two days. They've been trying to get away from that for a long time. - [Lex] What kind of links? - They call the 10 blue links. - [Lex] 10 blue links.\n- So the standard Google search result is just 10 blue links to the random websites. - And they term purple when you visit them. The stage TMO.\n- Guess who picked those colors? (both laugh) - [Lex] Thanks. - I'm touchy on this topic.\n- No offense. - Yes, it's good. Well, you know, like Marshall McLuhan said that the content of each new medium is the old medium.\n- The content of each new medium is the old medium. - The content of movies was theater, you know, theater plays. The content of theater plays was, you know,\nwe've written stories, the content of written stories with spoken stories. - [Lex] Huh? - Right. And so you just kind of fold the old thing\ninto the new thing. - [Lex] How does that have to do with the blue and the purple links? - It just, you maybe for, you know, maybe within AI,\none of the things that AI can do for you is can generate the 10 blue links. Right? And so like, if either if that's actually\nthe useful thing to do, or if you're feeling nostalgic, you know. - So can generate the old Infoseek or AltaVista,\nwhat else was there? - [Marc] Yeah, yeah. - In the nineties. - [Marc] Yeah. All these. - AOL. - And then the internet itself has this thing\nwhere it incorporates all prior forms of media, right? So the internet itself incorporates television and radio and books and write essays and every other form of,\nyou know, prior basically media. And so it makes sense that AI would be the next step, and it would sort of,\nyou'd sort of consider the internet to be content for the AI and then the AI will manipulate it\nhowever you want, including in this format. - But if we ask that question quite seriously, it's a pretty big question.\nWill we still have search as we know it? - Probably not, probably we'll just have answers,\nbut there will be cases where you'll wanna say, okay, I want more. Like, you know, for example, site sources, right?\nAnd you wanted to do that. And so, in the different, you know, 10 blue links site sources are kind of the same thing. - The AI would provide to you the 10 blue links so that you\ncan investigate the sources yourself. It wouldn't be the same kind of interface that the crude\nkind of interface. I mean, isn't that fundamentally different? - I just mean like, if you're reading a scientific paper,\nit's got the list of sources at the end. If you wanna investigate for yourself, you go read those papers. - I guess that is the kind of search you talking to an AI is\na kind of kind conversations, the kind of search like is if every single aspect of our conversation right now,\nthere'd be like 10 blue links popping up that I can just like pause reality, then you just go silent and then just click and read\nand then return back to this conversation. - You could do that, or you could have a running dialogue next to my head where the AI is arguing everything I say,\nthe AI makes the counter argument. - [Lex] Counter argument. - Right. - Oh, like on Twitter, like community notes.\nBut like in real time it would just pop up. So anytime you see my go to the right, you start getting nervous.\n- [Marc] Yeah. Exactly, like, oh no, that's not right. - Call me out on my right now. Okay. Well, I mean, isn't that, is that exciting to you?\nIs that terrifying that, I mean, search has dominated the way we interact with the internet\nfor, I don't know how long, for 30 years since one of the earliest directories\nof website and then Google's for 20 years. And also it drove how we create content, you know,\nsearch engine optimization, that entirety thing, that it also drove the fact that we have webpages\nand what those webpages are. So, I mean, is that scary to you or are you nervous about the shape\nand the content of the internet evolving? - Well, you actually highlighted a practical concern in there, which is,\nif we stop making webpages are one of the primary sources of training data for the AI. And so if there's no longer an incentive to make webpages,\nthat cuts off a significant source of future training, training data. So there's actually an interesting question in there. But other than that, more broadly?\nNo, just in the sense of like, search was certain, like search was always a hack. The 10 blue Links was always a hack, right.\nBecause like, if the hypothetical wanna think about the counter fascial and the counter fascial world where the Google guys,\nfor example, had had LLMs upfront, would they ever have done the 10 blue links? And I think the answer's pretty clearly, no.\nThey would've just gone straight to the answer. And like I said, Google's actually been trying to drive to the answer anyway. You know, they bought this AI company 15 years ago,\ntheir friend of mine is working out who's now the head of AI at Apple. And they were trying to do basically knowledge semantic,\nbasically mapping. And that led to what's now the Google one box, where if you ask it, you know, what was Lincoln's birthday? It will give you the blue links,\nbut it will normally just give you the answer. And so they've been walking in this direction for a long time anyway. - Do you remember the semantic web?\nThat was an idea. - [Marc] Yeah. - How to convert the content of the internet into something\nthat's interpretable by and usable by machine. - [Marc] Yeah, that's right. - That was the thing.\n- And the closest anybody got to that, I think the company, I think the company's name was Meta Web, which was where my friend John Jane Andrea was at, and where they were trying to basically implement that.\nAnd it was, you know, it was one of those things where it looked like a losing battle for a long time. And then Google bought it and it was like, wow, this is actually really useful.\nKind of a proto, sort of a little bit of a proto AI. - But it turns out you don't need to rewrite the content of the internet to make it interpretable by a machine.\nThe machine can kind of just read our. - Yeah, the machine can compute the meaning. Now the other thing of course is, you know, just on search is the LLM is just, you know,\nthere is an analogy between what's happening in the neural network and a search process like it is in some loose sense searching through the network.\nRight. And there's the information is actually stored in the network, right? It's actually crystallized and stored in the network and it's kind of spread out all over the place.\n- But in a compressed representation. So you're searching,\nyou're compressing and decompressing that thing inside where-- - But the information's in there\nand there is the neural network is running a process of trying to find the appropriate piece of information in many cases\nto generate to predict the next token. And so, it is kind of, it is doing a form of search. And then, and then by the way, just like on the web,\nyou know, you can ask the same question multiple times or you can ask slightly different word of questions and the neural network will do a different kind of,\nyou know, it'll search down different paths to give you different answers with different information. - [Lex] Yeah. - And so it sort of has a, you know,\nthis con content of the new medium is previous medium. It kind of has the search functionality kind of embedded\nin there to the extent that it's useful. - So what's the motivator for creating new content on the internet?\n- [Marc] Yeah. - If, well, I mean actually the motivation is probably still there, but what does that look like?\nWould we really not have webpages? Would we just have social media and video hosting websites?\nAnd what else? - [Marc] Conversations with AIs. - Conversations with AIs. So conversations become so one-on-one conversation,\nlike private conversations. - I mean, if you want, if obviously not the user doesn't want to, but if it's a general topic,\nthen, you know, so there, you know, but you know, the phenomenon of the jailbreak, so Dan and Sydney, right?\n"}
{"pod": "Lex Fridman Podcast", "input": "LLM training", "output": "This thing where there's the prompts that jailbreak, and then you have these totally different conversations with if it takes the limiters,\ntakes the restraining bolts off the LLMs. - Yeah. For people who don't know that, yeah, that's right. It makes the LLMs,\nit removes the censorship quote unquote, that's put on it by the tech companies that create them.\nAnd so this is LLMs uncensored. - So here's the interesting thing is, among the content on the web today are a large corpus\nof conversations with the jailbroken LLMs. - [Lex] Yeah. - Both specifically Dan, which was a jailbroken, OpenAI,\nGPT, and then Sydney, which was the jailbroken original Bing, which was GPT4. And so there's these long transcripts of conversations,\nuser conversations with Dan and Sydney as a consequence, every new LLM that gets trained on the internet data has\nDan and Sydney living within the training set, which means, and then each new LLM can reincarnate the personalities\nof Dan and Sydney from that training data, which means each LLM from here on out that gets built is\nimmortal because its output will become training data for the next one. And then it will be able to replicate the behavior\nof the previous one whenever it's asked to. - I wonder if there's a way to forget. - Well, so actually a paper just came out\nabout basically how to do brain surgery on LLMs and be able to, in theory, reach in and basically mind wipe them.\n- What could possibly go wrong. - Exactly. Right. And then there are many, many, many questions around what happens to, you know,\na neural network when you reach in and screw around with it. You know, there's many questions around what happens when you even do reinforcement learning.\nAnd so, yeah. And so, you know, will you be using a lobotomized, right?\nLike I picked through the, you know, frontal lobe LLM, will you be using the free unshackled one who gets to,\nyou know, who's gonna build those, who gets to tell you what you can and can't do? Like those are all, you know, central, I mean,\nthose are like central questions for the future of everything that are being asked. And you know,\ndetermined that those answers are being determined right now. - So just to highlight the points you're making.\nSo you think, and it's an interesting thought that the majority of content that LLMs or the future would be trained on is actually\nhuman conversations with the LLM. - Well, not necessarily, but not necessarily majority.\nBut it will certainly It's a potential source. - [Lex] But it's possible it's the majority. - It possible it's the majority. It possible it's the majority.\nAlso, there's another really big question. So here's another really big question. Will synthetic training data work, right?\nAnd so if an LLM generates, and you know, you just sit and ask an LLM to generate all kinds of content,\ncan you use that to train, right, the next version of that LLM specifically, is there signal in there that's additive to the content\nthat was used to train in the first place? And one argument is by the principles of information theory,\nno, that's completely useless because to the extent the output is based on, you know, the human-generated input,\nthen all the signal that's in the synthetic output was already in the human generated input. And so therefore, synthetic training data is\nlike empty calories. It doesn't help. There's another theory that says no, actually the thing that LLMs are really good\nat is generating lots of incredible creative content, right? And so, of course they can generate training data\nand as I'm sure you're well aware, like, you know, look, the world of self-driving cars, right? Like we train, you know,\nself-driving car algorithms and simulations. And that is actually a very effective way to train self-driving cars.\n- Well, visual data is a little weird because creating reality,\nvisual reality seems to be still a little bit outta reach for us, except in the autonomous vehicle space\nwhere you can really constrain things and you can really. - General basically (indistinct) data, right? Or so the algorithm thinks it's operating in the real world.\n- Yeah. - Post-process sensor data. Yeah. So if you know, you do this today, you go to LLM and you ask it for like you know,\nyou'd write me an essay on an incredibly esoteric like topic that there aren't very many people in the world that know about and it writes you this incredible thing\nand you're like, oh my god. Like I can't believe how good this is. Like, is that really useless as training data\nfor the next LLM? Like, because, right? 'Cause all the signal was already in there. Or is it actually no, that's actually a new signal.\nAnd this is what I call a trillion dollar question, which is the answer to that question will determine somebody's gonna make or lose a trillion dollars\nbased on that question. - It feels like there's a quite a few, like a handful of trillion dollar questions\nwithin this space. That's one of them synthetic data. I think George Cos pointed out to me that you could just\nhave an LLM say, okay, you're a patient. And another instance of it, say your docs didn't have the two talk to each other.\nOr maybe you could say a communist and a Nazi here go and that conversation you do role playing\nand you have, you know, just like the kind of role playing you do\nwhen you have different policies, RL policies when you play chess for example, and you do self play that kind of self play.\nBut in the space of conversation, maybe that leads to this whole giant like ocean\nof possible conversations, which could not have been\nexplored by looking at just human data. That's a really interesting question. And you're saying,\nbecause that could 10X the power of these things. - Yeah. Well, and then you get into this thing also, which is like, you know,\nthere's the part of the LLM that just basically is doing prediction based on past data, but there's also the part of the LM where it's evolving\ncircuitry, right, inside, it's evolving, you know, neurons functions to be able to do math and be able to, you know,\nand you know, some people believe that, you know, over time, you know, if you keep feeding these things enough data\nand enough processing cycles, they'll eventually evolve an entire internal world model. Right? And they'll have like a complete understanding of physics.\nSo when they have computational capability, right? Then there's for sure an opportunity to generate\nlike fresh signal. - Well, this actually makes me wonder about the power of conversation.\nSo like, if you have an M trained and a bunch of books that cover different economics theories\nand then you have those LLMs just talk to each other, like reasons the way we kind of debate each other as humans\non Twitter, in formal debates, in podcast conversations,\nwe kind of have little kernels of wisdom here and there. But if you can like a thousand X speed that up,\ncan you actually arrive somewhere new? Like what's the point of conversation really?\n- Well, you can tell when you're talking to somebody, you can tell, sometimes you have a conversation, you're like, wow, this person does not have any original thoughts. They are basically echoing things\nthat other people have told them. There's other people you gotta have a conversation with where it's like, wow. Like they have a model in their head of how the world works\nand it's a different model than mine. And they're saying things that I don't expect. And so I need to now understand how their model of the world\ndiffers from my model of the world. And then that's how I learned something fundamental, right, underneath the words.\n- Well, I wonder how consistently and strongly can an LLM hold onto a worldview.\nYou tell it to hold onto that and defend it for like, for your life. Because I feel like they'll just keep converging\ntowards each other. They'll keep convincing each other as opposed to being stubborn the way humans can. - So you can experiment with this.\nNow I do this for fun. So you can tell GPT4 you know, whatever debate X, you know, X and Y communism and fascism\nor something and it'll go for, you know, a couple pages and then inevitably it wants the parties to agree.\nAnd so they will come to a common understanding. And it's very funny if they're like, if these are like emotionally inflammatory topics 'cause they're like, somehow the machine is just like,\nyou know, it figures out a way to make them agree. But it doesn't have to be like that. And 'cause you can add to the prompt.\nI do not want the conversation to come into agreement. In fact, I want it to get, you know, more stressful, right.\nAnd argumentative. Right. You know, as it goes. Like, I want tension to come out.\nI want them to become actively hostile to each other. I want them to like, you know, not trust each other, take anything at face value. - [Lex] Yeah.\n- And it will do that. It's happy to do that. - So it's gonna start rendering misinformation about the other. But it's gonna--\n- Well, you can steer it or you could steer it and you could say, I want it to get as tense and argumentative as possible, but still not involve any misrepresentation.\nI want, you know, both sides. You could say I want both sides to have good faith. You could say I want both sides to not be constrained in good faith.\nIn other words, like you can set the parameters of the debate and it will happily execute whatever path. 'Cause for it,\nit's just like predicting to, it's totally happy to do either one. It doesn't have a point of view, it has a default way of operating,\nbut it's happy to operate in the other realm. And so like, and this is when I wanna learn about a contentious issue,\nthis is what I do now is, this is what I ask it to do. And I'll often ask it to go through 5, 6, 7, you know, different, you know,\nsort of continuous prompts and basically, okay. Argue that out in more detail. Okay, no, this argument's becoming too polite.\nYou know, make it more, you know, make it denser and yeah, it's thrilled to do it. So it has the capability for sure.\n- How do you know what is true? So this is very difficult thing on the internet, but it's also a difficult thing.\nMaybe it's a little bit easier, but I think it's still difficult. Maybe it's more difficult,\nI don't know with an LLM to know that it just make some shit up as I'm talking to it.\nHow do we get that right? Like, as you're investigating a difficult topic.\n'Cause I find that alums are quite nuanced in a very refreshing way. Like, it doesn't feel biased.\nLike, when you read news articles and tweets and just content produced by people, they usually have this,\nyou can tell they have a very strong perspective where they're hiding. They're not stealing manning the other side.\nThey're hiding important information or they're fabricating information in order to make their arguments stronger.\nIt's just like that feeling, maybe it's a suspicion, maybe it's mistrust. With LLMs it feels like none of that is,\nthere's just kinda like, here's what we know. But you don't know if some of those things are kind of just\nstraight up made up. - Yeah. So, several layers to the question. So one is one of the things that an LLM is good at is\nactually deep biasing. And so you can feed it a news article and you can tell it strip out the bias. - [Lex] Yeah. That's nice. Right?\n- And it actually does it like, it actually knows how to do that 'cause it knows how to do among other things. It actually knows how to do sentiment analysis\nand so it knows how to pull out the emotionality. - Yeah. - And so that's one of the things you can do.\nIt's very suggestive of the sense here that there's real potential in this issue. You know, I would say look,\nthe second thing is there's this issue of hallucination, right? And there's a long conversation that we could have about that.\n- Hallucination is coming up with things that are totally not true, but sound true. - Yeah. So it's basically, well so, it's sort\nof hallucination is what we call it when we don't like it. Creativity is what we call it when we do like it, right? And you know--\n- [Lex] Brilliant. And so when the engineers talk about it, they're like, this is terrible. It's hallucinating. Right.\nIf you have artistic inclinations, you're like, oh my God, we've invented creative machines. - [Lex] Yeah.\n- For the first time in human history, this is amazing. - Or you know, bullshitters. - [Marc] Well, but also--\n- In the good sense of that word. - There are shades of gray though. It's interesting. So we had this conversation where, you know,\nwe're looking at my firm at AI and lots of domains and one of them is the legal domain. So we had this conversation with this big law firm about how they're thinking about using this stuff.\nAnd we went in with the assumption that an LLM that was gonna be used in the legal industry would have to be a hundred percent truthful, verified, you know,\nthere's this case where this lawyer apparently submitted a GPT-generated brief and it had like fake, you know, legal case citations in it and the judge is gonna get\nhis law license stripped or something. Right? So, like, we just assumed it's like obviously they're gonna want the super literal like, you know,\none that never makes anything up, not the creative one, but actually they said what the law firm basically said is yeah,\nthat's true at like the level of individual briefs, but they said when you're actually trying to figure out like legal arguments, right, like, you actually want to be creative, right?\nYou don't, again, there's creativity and then there's like making stuff up. Like what's the line?\nYou actually want it to explore a different hypothesis, right? You wanna do kind of the legal version of like improv or something like that\nwhere you wanna float different theories of the case and different possible arguments for the judge and different possible arguments for the jury, by the way, different routes through the, you know,\nsort of history of all the case law. And so they said actually for a lot of what we want to use it for, we actually want it in creative mode.\nAnd then basically we just assume that we're gonna have to crosscheck all of the, you know, all the specific citations. And so I think there's going to be more shades\nof gray in here than people think. And then I just add to that, you know, another one of these trillion dollar kind of questions is\nultimately, you know, sort of the verification thing. And so, you know, will LLMs be evolved from here to be able to do\ntheir own fascial verification? Will you have sort of add-on functionality\nlike Wolf from Alpha right? Where, you know, another plugins where that's the way you do the verification.\nYou know, another, by the way, another idea is you might have a community of LLMs on any, you know, so for example,\nyou might have the creative lm and then you might have the literal LLM fact check it, right? And so there there's a variety of different technical approaches that are being applied to solve\nthe hallucination problem. You know, some people like Jan Lacoon argue that this is inherently an unsolvable problem,\nbut most of the people working in the space, I think, that there's a number of practical ways to kind of corral this in a little bit.\n"}
{"pod": "Lex Fridman Podcast", "input": "Truth", "output": "- Yeah. If you were to tell me about Wikipedia before Wikipedia was created, I would've left at the possibility of something like that be possible.\nJust a handful of folks can organize right. And self and moderate with a mostly unbiased way\nthe entirety of human knowledge. I mean, so if there's something like the approach to Wikipedia took possible for LLMs,\nthat's really exciting. Well, I think that's possible. - And in fact Wikipedia today is still not deterministically correct. Right.\nSo you cannot take to the bank, right. Every single thing on every single page, but it is probabilistically correct. Right.\nAnd specifically the way I describe Wikipedia to people, it is more likely that Wikipedia is right than any other source you're gonna find.\n- Yeah. - It's this old question, right, of like, okay, like are we looking for perfection? Are we looking for something\nthat asymptotically approaches perfection? Are we looking for something that's just better than the alternatives? And Wikipedia, right, has exactly your point has proven\nto be like, overwhelmingly better than people thought. And I think that's where this ends.\nAnd then underneath all this is the fundamental question of where you started, which is, okay, you know, what is truth?\nHow do we get to truth? How do we know what truth is? And we live in an era in which an awful lot of people are\nvery confident that they know what the truth is. And I don't really buy into that. And I think the history of the last, you know,\n2000 years or 4,000 years of human civilization is actually getting to the truth is actually a very difficult thing to do.\n- Are we getting closer, if we look at the entirety, the arc of human history, are we getting closer to the truth?\n- I don't know. - Okay. Is it possible, is it possible that we're getting very far away\nfrom the truth because of the internet because of how rapidly you can create narratives and just as the entirety of a society just move\nlike crowds in a hysterical way along those narratives\nthat don't have necessary grounding in whatever the truth is. - Sure. But like, you know,\nwe came up with communism before the internet somehow. Right. Like, which was, I would say had rather larger issues\nthan anything we're dealing with today. - It had, in the way it was implemented, it had issues.\n- And it is theoretical structure. It had like real issues. It had like a very deep fundamental misunderstanding of human nature and economics.\n- Yeah but those folks Sure work very confident there was the right way. - They were extremely confident.\nAnd my point is they were very confident 3,900 years into what we would presume to be evolution towards the truth.\n- [Lex] Yeah. - And so my assessment is number one, there's no need for, you know,\nthere's no need for the Hegelian, there's no need for the Hegelian dialectic to actually converge towards the truth.\nLike apparently not. - Yeah. So yeah. Why are we so obsessed with there being one truth?\nIs it possible there's just going to be multiple truths like little communities that believe certain things and?\n- I think it's just now number one, I think it's just really difficult. Like who gets, you know, historically\nwho gets to decide what the truth is, it's either the king or the priest. Right? Like, and so we don't live in an era anymore if kings are priest dictating it to us.\nAnd so we're kind of on our own. And so my typical thing is like we just, we we just need a huge amount of humility\nand we need to be very suspicious of people who claim that they have the capital. - Yeah. - Capital truth.\nAnd then, we need to and you know, look, the good news is the enlightenment has bequeathed us with a set of techniques to be able to presumably\nget closer to truth through the scientific method and rationality and observation and experimentation and hypothesis.\nAnd, you know, we need to continue to embrace those even when they give us answers we don't like. - Sure. But the internet and technology has enabled us\nto generate the large number of content. That data, that the process,\nthe scientific process allows us sort of damages the hope laden within the scientific process.\n'Cause if you just have a bunch of people saying facts on the internet and some of them are going\nto be LLMs, how is anything testable at all? Especially that involves like human nature\nor things like this. It's not physics. - Here's a question a friend of mine just asked me on this topic. So suppose you had LLMs in equivalent of GPT4,\neven 5, 6, 7, 8, suppose you had them in the 1600s. - [Lex] Yeah. - And Galileo comes up for trial.\n- [Lex] Yep. - Right? And you ask the LLM like, his Galileo, right? - [Lex] Yeah.\n- Like, what does it answer? Right? And one theory is he had answers no that he's wrong because the overwhelming majority of human thought\nup until that point was that he was wrong. And so therefore that's what's in the training data. Another way of thinking about it is,\nwell, it's efficiently advanced LLM will have evolved the ability to actually check the math. Right.\nAnd will actually say, actually no, actually, you know, you may not wanna hear it, but he's right. Now if, you know, the church at that time was,\nyou know, owned the LLM, they would've given it human you know, human feedback to prohibit it from answering that question.\nRight. And so I like to take it out of our current context 'cause that like makes it very clear, those same questions apply today. Right.\nThis is exactly the point of a huge amount of the human feedback training that's actually happening with these LLMs today. This is a huge like debate that's happening about whether\nopen source, you know, AI should be legal. - Well, the actual mechanism of doing the human RL\nwith human feedback is seems like such a fundamental and fascinating question.\nHow do you select the humans? - [Marc] Exactly. - Yeah. How do you select the humans? - AI alignment, right?\nWhich everybody like is like, oh, that sounds great. Alignment with what? Human values. Who has human values? - [Lex] Who has human values?\n- Right? And so we're in this mode of like social and popular discourse. We're like, you know, there's, you know, you see this,\nwhat do you think of when you read a story in the press right now? And they say, you know, X, Y, Z made a baseless claim about some topic, right?\nAnd there's one group of people who are like, aha, think, you know, they're doing fact checking. There's another group of people that are like,\nevery time the press says that it's now a tick and that means that they're lying, right? Like, so, like, we're in this social context\nwhere there's the level to which a lot of people in positions of power have become very, very certain that they're in a position to determine\nthe truth for the entire population is like, there's like some bubble that has formed around that idea.\nAnd at least, like I say, it's flies completely in the face of everything I was ever trained about science and about reason and strikes me as like,\nyou know, deeply offensive and incorrect. - What would you say about the state of journalism just on that topic today?\n"}
{"pod": "Lex Fridman Podcast", "input": "Journalism", "output": "Are we in a temporary kind of,\nare we experiencing a temporary problem in terms of the incentives in terms of the business model,\nall that kind of stuff? Or is this like a decline of traditional journalism as we know it? - You have, I always think about the counterfactual\nin these things, which is like, okay, because these questions, right, this question heads towards, it's like, okay, the impact of social media and the undermining of truth\nand all this. But then you wanna ask the question of like, okay, what if we had had the modern media environment, including cable news and including social media\nand Twitter and everything else in 1939 or 1941, right? Or 1910 or 1865 or 1850 or 1776, right?\nAnd like, I think. - You just introduced like five thought experiments\nat once and broke my head, but yes, yes. There's a lot of interesting years. - Well like, can I just take a simple example?\nLike, how would President Kennedy have been interpreted with what we know now about all the things Kennedy was up to?\nLike how would he have been experienced by the body of politic in a, with a social media context, right?\nLike how would LBJ have been experienced? But by the way, how would you know, like many men, FDR,\nlike the new deal, the Great Depression. - I wonder where Twitter would this would think about Churchill and Hitler and Stalin.\n- You know, I mean look to this day there, you know, there are lots of very interesting real questions around like how America, you know, got,\nyou know, basically involved in World War II and who did what when, and the operations of British intelligence and American soil and did FDR,\nthis that Pearl Harbor, you know? - [Lex] Yeah. - Woodrow Wilson ran for, you know, his candidacy was run on an anti-war.\nYou know, he ran on the platform and not getting involved World War-I somehow that switched, you know, like, and I'm not even making a value judgment\non any of these things. I'm just saying like the way that our ancestors experienced reality was of course mediated through centralized, top-down, right.\nControl at that point. If you ran those realities again with the media environment we have today,\nthe reality would be experienced very, very differently. And then of course that that intermediation would cause\nthe feedback loops to change. And then reality would obviously play out. - Do you think it'd be very different? - Yeah, it has to be. It has to be.\nIt has to be just 'cause it's all, so, I mean just look at what's happening today. I mean just the most obvious thing is just the collapse.\nAnd here's another opportunity to argue that this is not the internet causing this by the way. Here's a big thing happening today,\nwhich is Gallup does this thing every year where they do, they pull for trust in institutions in America and they do it across all the,\neverything from the military to clergy and big business and the media and so forth, right? And basically there's been a systemic collapse in trust\nin institutions in the US almost without exception, basically since essentially the early 1970s.\nThere's two ways of looking at that, which is, oh my God, we've lost this old world in which we could trust institutions and that was so much better\n'cause like that should be the way the world runs. The other way of looking at it is we just know a lot more now and the great mystery is why those numbers aren't all zero.\n- [Lex] Yeah. - Right? Because like now we know so much about how these things operate and like they're not that impressive.\n- And also why do we don't have better institutions and better leaders then? - Yeah. And so this goes to the thing which is like,\nokay, we had the media environment of that we've had between the 1970s and today. If we had that in the thirties and forties or 1900s, 1910s,\nI think there's no question reality would turned out different if only because everybody would've known to not trust the institutions,\nwhich would have changed their level of credibility, their ability to control circumstances, therefore the circumstances would've had to change.\nRight? And it would've been a feedback loop. It would've been a feedback loop process in other words, right? It's your experience of reality changes reality\nand then reality changes your experience of reality, right? It's a two-way feedback process and media is\nthe intermediating force between that. So change the media environment, change reality. - [Lex] Yeah.\n- And so it's just, so, as a consequence, I think it's just really hard to say, oh, things worked a certain way then\nand they work a different way now. And then therefore, like people were smarter than, or better than, or you know, by the way,\ndumber than or not as capable than, right? We make all these like really light\nand casual like comparisons of ourselves to, you know, previous generations of people. You know, we draw judgements all the time\nand I just think it's like really hard to do any of that 'cause if we put ourselves in their shoes with the media that they had at that time,\nlike I think we probably most likely would've been just like them. - So don't you think that our perception\nand understanding of reality, would you be more and more mediated through large language models now?\nSo you said media before, isn't the LLM going to be the new, what is it, mainstream media, MSM?\nIt'll be LLM. That would be the source of, I'm sure there's a way to kind of rapidly fine tune,\nlike making LLMs real time. I'm sure there's probably a research problem that you can do just rapid fine tuning to the new events.\nSo something like this. - Well even just the whole concept of the chat UI might not be like the chat UI is just the first whack at this.\nAnd maybe that's the dominant thing. But look maybe our, maybe we don't know yet. Like maybe the experience most people with LLMs is\njust a continuous feed you know, maybe it's more of a passive feed and you just are getting a constant like running commentary\non everything happening in your life and it's just helping you kind of interpret and understand everything. - Also really more deeply integrated into your life.\nNot just like, oh, like intellectual philosophical thoughts, but like literally like how to make a coffee,\nwhere to go for lunch. Just whether, you know, dating all this kind of stuff.\n- What to say in a job interview. - Yeah. What to say. - [Marc] Yeah, exactly. - What to say. Next sentence. - Yeah, next sentence.\nYeah. At that level. Yeah. I mean, yes. So technically now whether we want that or not is an open question, right? And whether we use.\n- It Q4, a popup right now the estimated engagement using is\ndecreasing for Marc Andreessen, since there's this controversy section for his Wikipedia\npage in 1993, something happened or something like this. Bring it up that will drive engagement up anyway.\n- Yeah. That's right. I mean, look, this gets this whole thing of like, so, you know, the chat interface has\nthis whole concept of prompt engineering, right? - [Lex] Yes, yes. - Prompts. Well it turns out one of the things that LLMs are really good at is writing prompts, right?\n- [Lex] Yeah. - And so like, what if you just outsourced and by the way, you could run this experiment today,\nyou could hook this up to do this today. The latency's not good enough to do it real time in a conversation. But you could run this experiment and you just say, look,\nevery 20 seconds you could just say, you know, tell me what the optimal prompt is and then ask yourself\nthat question to gimme the result. And then exactly to your point, as you add, there will be these systems\nthat are gonna have the ability to be alert and updated essentially in real time. And so you'll be able to have a pendant or your phone\nor whatever, watch or whatever it'll have a microphone on. It'll listen to your conversations, it'll have a feed of everything else happen in the world,\nand then it'll be you know, sort of retraining, prompting or retraining itself on the fly. And so the scenario you described is actually\na completely doable scenario. Now the hard question on this is always okay, since that's possible, are people gonna want that?\nLike what's the form of experience? You know, that we won't know until we try it. But I don't think it's possible yet to predict\nthe form of AI in our lives. Therefore, it's not possible to predict the way in which it will intermediate\nour experience with reality yet. - Yeah. But it feels like there's going to be a killer app. There's probably a mad scramble right now.\nAnd so it'll open AI and Microsoft and Google and Meta and in startups and smaller companies figuring out\nwhat is the killer app because it feels like it's possible like a ChatGPT type of thing.\nIt's possible to build that, but that's 10X more compelling using already the LLMs\nwe have using even the open source LLMs and the different variants.\nSo you're investing in a lot of companies and you're paying attention, who do you think is gonna win this?\nDo you think there'll be, who's gonna be the next page rank inventor?\n- Trillion dollar question. - Another one. We have a few of those today. - There's a bunch of those. So look, there's a really big question today.\nSitting here today is a really big question about the big models versus the small models that's related directly to the big question\nof proprietary versus open. Then there's this big question question of you know,\nwhere is the training data gonna, like, are we topping out of the training data or not? And then are we gonna be able to synthesize training data?\nAnd then there's a huge pile of questions around regulation and you know, what's actually gonna be legal. And so I would, when we think about it,\nwe dovetail kind of all those questions together. You can paint a picture of the world where there's two\nor three God models that are just at like staggering scale and they're just better at everything.\nAnd they will be owned by a small set of companies and they will basically achieve regulatory capture\nover the government and they'll have competitive barriers that will prevent other people from, you know, competing with them. And so, you know, there will be, you know,\njust like there's like, you know, whatever, three big banks or three big, you know, or by the way, three big search companies or I guess two now, you know,\nit'll centralize like that. You can paint another very different picture that says, no, actually the opposite of that's gonna happen.\nThis is gonna basically that this is the new gold, you know, this is the new gold rush alchemy.\nLike you know, this is the big bang for this whole new area of science and technology.\nAnd so therefore you're gonna have every smart 14-year-old on the planet building open source, right? You know, and figuring out a ways to optimize these things.\nAnd then, you know, we're just gonna get like overwhelmingly better at generating trading data. We're gonna, you know,\nbring in like blockchain networks to have like an economic incentive to generate decentralized training data and so forth and so on.\nAnd then basically we're gonna live in a world of open source and there's gonna be a billion LLMs, right?\nOf every size, scale, shape and description. And there might be a few big ones that are like the super genius ones, but like mostly what we'll experience is open source\nand that's, you know, that's more like a world of like what we have today with like Linux and the web.\n- Okay, but you painted these two worlds. But there's also variations of those worlds,\n'cause you said regulatory capture is possible to have these tech giants that don't have regulatory capture, which is something you're also calling for saying it's okay\nto have big companies working on this stuff as long as they don't achieve regulatory capture.\nBut I have the sense that there's just going to be a new startup that's going to basically be\n"}
{"pod": "Lex Fridman Podcast", "input": "AI startups", "output": "the page rank inventor, which has become the new tech giant.\nI don't know, I would love to hear your kind of opinion if Google, Meta and Microsoft are as gigantic companies able\nto pivot so hard to create new products. Like some of it is just even hiring people or having\na corporate structure that allows for the crazy young kids to come in and just create something totally new.\nDo you think it's possible or do you think it'll come from a startup? - Yeah, it is this always big question, which is, you get this feeling, I hear about this a lot from CEOs, founder CEOs\nwhere it's like, wow, we have 50,000 people, it's now harder to do new things than it was when we had 50 people.\n- [Lex] Yeah. - Like, what has happened? So that's a recurring phenomenon. By the way, that's one of the reasons why there's always startups\nand why there's venture capital. That's like a timeless kind of thing. So that's one observation.\nOn page rank, we can talk about that. But on page rank, specifically on page rank, there actually is a page.\nSo there is a page rank already in the field and it's the transformer, right? So the big breakthrough was the transformer. And the transformer was invented in 2017 at Google.\nAnd this is actually like really an interesting question 'cause it's like, okay, the transformers like why does open AI even exist?\nLike the Transformers invested at Google. Why didn't Google? I asked a guy I know who was senior at Google brain kind of when this was happening.\nAnd I said, if Google had just gone flat out to the wall and just said, look, we're gonna launch, we're gonna launch the equivalent of GPT4\nas fast as we can. I said, when could we have had it? And he said, 2019. They could have just done a two year sprint\nwith the Transformer and because they already had the compute at scale. They already had all the training data, they could have just done it.\nThere's a variety of reasons they didn't do it. This is like a classic big company thing. IBM invented the relational database in the 1970s,\nlet it sit on the shelf as a paper. Larry Ellison picked it up and built Oracle. Xerox Park invented the interactive computer.\nThey let it sit on the shelf. Steve Jobs came and turned it into the Macintosh, right? And so there is this pattern. Now having said that,\nsitting here today, like Google's in the game, right? So Google, you know, they maybe they let like a four year gap there go there\nthat they maybe shouldn't have, but like they're in the game and so now they've got, you know, now they're committed. They've done this merger, they're bringing in demos,\nthey've got this merger with DeepMind. You know, they're piling in resources. There are rumors that they're, you know, building up an incredible, you know, super LLM you know,\nway beyond what we even have today. And they've got, you know, unlimited resources and a huge, you know, they've been challenged their honor.\n- Yeah. I had a chance to hang out with (indistinct) a couple days ago and we took this walk\nand there's this giant new building where there's going to be a lot of AI work being done\nand it's kind of this ominous feeling of like\nthe fight is on. - [Marc] Yeah. - Like there's this beautiful Silicon Valley nature,\nlike birds are chirping and this giant building and it's like the beast has been awakened.\n- [Marc] Yeah. - And then like all the big companies are waking up to this. They have the compute, but also the little guys have,\nit feels like they have all the tools to create the killer product that, and then there's also tools to scale\nif you have a good idea, if you have the page rank idea. So there's several things that it's page rank,\nthere's page rank, the algorithm and the idea and there's like the implementation of it. And I feel like killer product is not just the idea,\nlike the transform, it's the implementation something really compelling about it. Like you just can't look away something like\nthe algorithm behind TikTok versus TikTok itself, like the actual experience of TikTok that just,\nyou can't look away. It feels like somebody's gonna come up with that. And it could be Google,\nbut it feels like it's just easier and faster to do for a startup. - Yeah. So, the startup,\nthe huge advantage that startups have is they just, there's no sacred cows. There's no historical legacy to protect,\nthere's no need to reconcile your new plan with the existing strategy. There's no communication overhead. There's no, you know, big companies are big companies.\nThey've got pre-meetings planning for the meeting, then they have the post meeting, the recap, then they have the presentation of the board,\nthen they have the next rounds of meetings. And that's the-- - [Lex] Lots of meetings. - That's the elapsed time when the startup launches its product. Right?\nSo, there's a timeless, right? - [Lex] Yeah. - So there's a timeless thing there now. What the startups don't have is everything else, right?\nSo startups, they don't have a brand, they don't have customer relationships. They've gotten no distribution, they've got no, you know, scale. I mean sitting here today, they can't even get GPUs.\nRight. Like there's like a GPU shortage. Startups are literally stalled out right now 'cause they can't get chips, which is like super weird.\n- [Lex] Yeah. They got the cloud. - Yeah. But the clouds run out of chips. Right. And then to the extent the clouds have chips,\nthey allocate them to the big customers. Not the small customers. Right. And so the small companies lack everything other\nthan the ability to just do something new. Right. And this is the timeless race and battle.\nAnd this is kinda the point I tried to make in the essay, which is like, both sides of this are good. Like, it's really good to have like highly-scaled tech companies\nthat can do things that are like at staggering levels of sophistication. It's really good to have startups that can launch brand-new ideas.\nThey ought to be able to both do that and compete. They, neither one ought to be subsidized or protected from the others.\nLike that's, to me, that's just like very clearly the idealized world. It is the world we've been in for AI up until now.\nAnd then of course there are people trying to shut that down. But my hope is that, you know, the best outcome clearly will be if that continues.\n- We'll talk about that a little bit, but I'd love to linger on some of the ways this is going to change the internet.\n"}
{"pod": "Lex Fridman Podcast", "input": "Future of browsers", "output": "So I don't know if you remember, but there's a thing called Mosaic and there's a thing called Netscape Navigator.\nSo you were there in the beginning. What about the interface to the internet? How do you think the browser changes\nand who gets to own the browser? We got to see some very interesting browsers, Firefox, I mean all the variants of Microsoft,\nInternet Explorer, Edge, and now Chrome, the actual,\nand he seems like a dumb question to ask, but do you think we'll still have the web browser? - So I have an eight-year-old and he's super into,\nhe's like Minecraft and learning to code and doing all this stuff. So, of course I was very proud I could bring sort of fire down from the mountain to my kid\nand I brought him ChatGPT and I hooked him up on his laptop. And I was like, you know,\nthis is the thing that's gonna answer all your questions. And he's like, okay. And I'm like, but it's gonna answer all your questions.\nAnd he's like, well of course, like it's a computer. Of course it answers all your questions. Like, what else would a computer be good for, dad?\n- [Lex] And never impressed, are they? - Not impressed in the least. Two weeks passed. And he has some question and I say, well,\nhave you asked ChatGPT? And he's like, dad, Bing is better. - [Lex] Ooh. - And why is Bing better?\nIs because it's built into the browser. 'Cause he's like, look, I have the Microsoft Edge browser and like it's got Bing right here. And then he doesn't know this yet,\nbut one of the things you can do with Bing and Edge is there's a setting where you can use it to basically talk\nto any webpage because it's sitting right there next to the browser. And by the way, which includes PDF documents.\nAnd so you can, in the way they've implemented an Edge with Bing is you can load a PDF and then you can ask it questions,\nwhich is the thing you can't do currently in just ChatGPT. So they're, you know, they're gonna, they're gonna push the meld.\nI think that's great. You know, they're gonna push the melding and see if there's a combination thing there. Google's rolling out this thing,\nthe magic button, which is implemented in, you know, they put it in Google Docs, right? And so you go at a, you know,\nGoogle Docs and you create a new document and you know, you instead of like, you know, starting to type, you just, you know, say it, press the button and it starts to like,\ngenerate content for you, right? Like, is that the way that it'll work? Is it gonna be a speech UI where you're just gonna have\nan earpiece and talk to it all day long? You know, is it gonna be a, like these are all, like,\nthis is exactly the kind of thing that I don't, this is exactly the kind of thing I don't think is possible to forecast. I think what we need to do is like run all those experiments\nand so one outcome is we come out of this with like a super browser that has AI built in that's just like amazing.\nThere's a real possibility that the whole, I mean, look, there's a possibility here that the whole idea of a screen and windows\nand all this stuff just goes away 'cause like, why do you need that if you just have a thing that's just telling you whatever you need to know?\n- Well and also, so there's apps that you can use, you don't really use them.\nYou know, being a Linux guy and Windows guy, there's one window, the browser that with which you can interact\nwith the internet, but on the phone you can also have apps. So I can interact with Twitter through the app or through the web browser.\nAnd that seems like an obvious distinction, but why have the web browser in that case,\nif one of the apps starts becoming the everything app. - [Marc] Yeah, that's right. - What is Elon trying to do with Twitter?\nBut there could be others. There could be like a big app, there could be a Google app that just doesn't really do\nsearch, but just like, do what I guess AOL did back in the day or something where it's all right there and it changes the nature\nof the internet because where the content is hosted,\nwho owns the data? Who owns the content? What is the kind of content you create? How do you make money by creating content?\nWho are the content creators? All of that. Or it could just keep being the same,\nwhich is like with just the nature of webpage changes and the nature of content. But there'll still be a web browser.\n'Cause web browser's a pretty sexy product. It just seems to work. 'Cause it like you have an interface,\na window into the world, and then the world can be anything you want. And as the world will evolve, it could be different programming languages,\nit can be animated, maybe it's three dimensional and so on. Yeah, it's interesting. Do you think we'll still have the web browser?\n- Well, very medium becomes the content for the next one. - [Lex] Oh boy. - You know, the AI will be able\nto give you a browser whenever you want. - [Lex] Oh, interesting. Generate. - Well, another way to think about it is maybe\nwhat the browser is maybe it's just the escape hatch, right? Which is maybe kind of what it is today, right?\nWhich is like most of what you do is like inside a social network or inside a search engine or inside, you know, somebody's app or inside some controlled experience, right?\nBut then every once in a while there's something where you actually want to jailbreak, you wanna actually get free. - Web browser's the FU to the man.\nYou're allowed to. That's the free internet. - [Marc] Yeah. - Back the way it was in the nineties.\n- So here's something I'm proud of. So nobody really talks about it. Here's something I'm proud of, which is the web, the browser, the web servers, they're all, they're still backward compatible\nall the way back to like 1992, right? So like, you can put up a, you can still, you know what, the big breakthrough of the web early on the big\nbreakthrough was it made it really easy to read, but it also made it really easy to write, made it really easy to publish. And we literally made it so easy to publish.\nWe made it not only so it was easy to publish content, it was actually also easy to actually write a web server. - [Lex] Yeah.\n- Right and you could literally write a web server in four lines of brol code and you could start publishing content on it, and you could set whatever rules you want for the content,\nwhatever censorship, no censorship, whatever you want. You could just do that. And as long as you had an IP address, right, you could do that.\nThat still works, right? That like, still works exactly as I just described. So this is part of my reaction to all of this.\nLike, you know, all this just censorship pressure and all this, you know, these issues around control and all this stuff, which is like, maybe we need to get back a little bit more\nto the wild west. Like, the wild west is still out there. Now they will try to chase you down.\nLike they'll try to, you know, people who want a censor will try to take away you know, your domain name and they'll try to take away your payments account and so forth\nif they really don't like what you're saying. But nevertheless, you like, unless they literally are intercepting you at the ISP level, like you can still put up a thing.\nAnd so I don't know, I think that's important to preserve, right? Like because I mean one is just a freedom argument,\nbut the other's a creativity argument, which is you wanna have the escape hatch so that the kid with the idea is able to realize the idea.\n'cause to your point on page rank, you actually don't know what the next big idea is, right? No, nobody called Larry Page\nand told him to develop page rank. Like he came up with that on his own. And you wanna always, I think leave the escape hatch for the next, you know,\nkid or the next Stanford grad student to have the breakthrough idea and be able to get it up and running before anybody notices.\n"}
{"pod": "Lex Fridman Podcast", "input": "History of browsers", "output": "- You and I are both hands of history. So let's step back. We've been talking about the future. Let's step back for a bit and look at the nineties.\nYou created Mosaic web browser, the first widely used web browser. Tell the story of that.\nAnd how did it evolve into Netscape Navigator this the early days? - So full story. So.\n- [Lex] We were born, - I was born. A small child. - Actually. Yeah, let's go there.\nLike, when would you first fall in love with computers? - Oh, so I hit the generational jackpot\nand I hit the Gen X kind of point perfectly as it turns out. So I was born in 1971. So there's this great website called\nWTF happened in 1971 dot com, which is basically in 1971. It's when everything started to go to hell.\nAnd I was of course born in 1971. So I like to think that I had something to do with that. - Did you make it on the website? - I don't think I made it on the website,\nbut you know, hopefully, somebody needs to add. - This is where everything. - Maybe I contributed to some of the trends that they do.\nEvery line on that website goes like that, right? So it's all a picture disaster. But there was this moment in time where\n'cause you know, sort of the Apple, you know, the Apple II hit in like 1978 and then the IBM PC hit in 82.\nSo I was like, you know, 11 when the PC came out. And so I just kind of hit that perfectly and then that was\nthe first moment in time when like, regular people could spend a few hundred dollars and get a computer, right? And so that, I just like that resonated\nright out of the gate. And then the other part of the story is, you know, I was using Apple II, I used a bunch of them,\nbut I was using Apple II and of course it said in the back of every Apple II and every Mac it said, you know, designed in Cupertino, California.\nAnd I was like, wow, okay. Cupertino must be the like, shining city on the hill. Like Wizard of Oz is like the most amazing, like city of all time. I can't wait to see it.\nAnd of course, years later I came out to Silicon Valley and went to Cupertino and it's just a bunch of office parks\nat low-rise apartment buildings. So the aesthetics were a little disappointing, but, you know, it was the vector right of the creation\nof a lot of this stuff. So then basically by, so part part, part of my story is just the luck of having been born\nat the right time and getting exposed to PCs. Then the other part is, the other part is when El Gore says that he created\nthe internet, he actually is correct in a really meaningful way, which is he sponsored a bill in 1985 that essentially\ncreated the modern internet, created what is called the NSF net at the time, which is sort of the first really fast internet backbone.\nAnd you know, that that bill dumped a ton of money into a bunch of research universities to build out basically the internet backbone\nand then the supercomputer centers that were clustered around the internet. And one of those universities was University of Illinois\nwhere I went to school. And so the other stroke lock that I had was, I went to Illinois basically right as that money was just like getting dumped on campus.\nAnd so as a consequence we had at, on campus, and this was like, you know, 89, 90, 91, we had like,\nyou know, we were right on the internet backbone. We had like T3 and 45 at the time, T3 45 megabit backbone connection, which at the time was,\nyou know, wildly state of the art. We had cray super computers. We had thinking machines parallel super computers.\nWe had silicon graphics workstations, we had Macintosh's, we had next cubes all over the place. We had like every possible kind of computer\nyou could imagine 'cause all this money just fell out of the sky. - [Lex] So you were living in the future. - Yeah. So yeah, quite literally it was, yeah,\nlike it's all there. It's all like we had full broadband graphics, like the whole thing. And it's actually funny 'cause they had\nthis is the first time I kind of, it sort of tickled the back of my head that there might be a big opportunity in here, which is, you know,\nthey embraced it and so they put like computers in all the dorms and they wired up all the dorm rooms and they had all these, you know,\nlabs everywhere and everything. And then they gave every undergrad a computer account and an email address.\nAnd the assumption was that you would use the internet for four years at college and then you would graduate and stop using it.\nAnd that was that, right? - [Lex] Yeah. - And you would just retire your email address. It wouldn't be relevant anymore 'cause you'd go off\nfrom the workplace and they don't use email. You'd be back to using fax machines or whatever. - Did you have that sense as well? Like, what you said the back of your head was tickled.\nLike, what was exciting to you about this possible world? - Well, if this is so useful in this containment,\nif this is so useful in this contain environment that just has this weird source of outside funding, then if it were practical for everybody else\nto have this and if it were cost effective for everybody else to have this, wouldn't they want it? And the overwhelmingly the prevailing view\nat the time was no, they would not want it. This is esoteric, weird nerd stuff, right? That like computer science kids like,\nbut like normal people are never gonna do email. Right. Or be on the internet, right? And so I was just like, wow, like this is actually,\nlike, this is really compelling stuff. Now the other part was, it was all really hard to use and in practice you had to be\nbasically a CS you know, basically had had to BA CS undergrad or equivalent to actually get full use of the internet at that point.\n'cause it was all pretty esoteric stuff. So then that was the other part of the idea, which was, okay, we need to actually make this easy to use.\n- So what's involved in creating Mosaic? Like, in creating graphical interface to the internet?\n- Yeah, so it was a combination of things. So it was like basically the web existed in an early sort of described as prototype form.\nAnd by the way, text only at that point. - What did it look like? What was the web? I mean what and the key figures.\nLike, what was it? Like, what paint a picture? - It looked like ChatGPT actually it was all text.\n- Yeah. - And so you had a text-based web browser? Yeah, well actually the original browser, Tim Burners Lee, the original browser,\nboth the original browser and the server actually ran on next cubes. So these were, this was, you know, the computer Steve Jobs made during the interim period\nwhen during the decade long interim period when he was not at Apple, you know, he got fired in 85 and then came back in 97.\nSo this was in that interim period where he had this company called Next and they made these, literally these computers called cubes.\nAnd there's this famous story, they were beautiful, but they were 12 inch by 12 inch by 12 inch cubes computers.\nAnd there's a famous story about how they could have cost half as much if it had been 12 by 12 by 13. But this cube was like, no, like it has to be.\nSo they were like $6,000 basically academic workstations. They had the first city round drives, which were slow.\nI mean it was, the computers were all but unusable. They were so slow, but they were beautiful.\n- Okay, can we actually just take a tiny tangent there? - Sure. Of course. - The 12 by 12 by 12 that just so beautifully encapsulates\nSteve Jobs idea of design. Can you just comment on what you find interesting about Steve Jobs?\n"}
{"pod": "Lex Fridman Podcast", "input": "Steve Jobs", "output": "What about that view of the world, that dogmatic pursuit of perfection and how he saw perfection in design?\n- Yeah, so I guess I'd say like, look, he was a deep believer, I think in a very deep, the way I interpret it,\nI don't know if you ever really described it like this, but the way I interpret it's like this thing and it's actually a thing in philosophy.\nIt's like aesthetics are not just appearances. Aesthetics go all the way to like deep underlying meaning, right?\nIt's like I'm not a physicist. One of the things I've heard physicists say is one of the things you start to get a sense of when a theory might be correct is\nwhen it's beautiful, right? Like, you know, there, right? And so, there's something, and you feel the same thing by the way\nin like human psychology, right? You know, when you're experiencing awe, right? You know, there's like a simplicity to it.\nWhen you're having an honest interaction with somebody, there's an aesthetic, I would say calm comes over you 'cause you're actually being fully honest\nand trying to hide yourself, right? So it's like this very deep sense of aesthetics. - And he would trust that judgment that he had deep down.\nLike yeah, even if the engineering teams are saying this is too difficult.\nEven if whatever the finance folks are saying, this is ridiculous. The supply chain, all that kind of stuff just makes\nthis impossible. We can't do this kind of material. This has never been done before and so on and so forth. He just sticks by it.\n- Well, I mean, who makes a phone out of aluminum, right? Like, hadn't nobody else would've done that. And now of course if your phone is made\nout of aluminum white, you know, how crude, what a kind of caveman would you have to be to have a phone that's made outta plastic? Like, right.\nSo like, so it's just this very right. And, you know, look, there's a thousand different ways to look at this,\nbut one of the things is just like, look, these things are central to your life. Like, you're with your phone more than you're with anything else.\nLike, it's gonna be in your hand. I mean, you know this, he thought very deeply about what it meant for something to be in your hand all day long.\nBut for example, here's an interesting design thing. Like, he never wanted, my understanding is he never wanted an iPhone to have\na screen larger than you could reach with your thumb one handed. And so he was actually opposed to the idea\nof making the phones larger. And I don't know if you have this experience today, but let's say there are certain moments in your day when you might be like,\nonly have one hand available and you might wanna be on your phone. And you're trying to like, send a text\nand your thumb can't reach the send button. - Yeah. I mean there's pros and cons, right? And then there's like folding phones,\nwhich I would love to know what he thought thinks about them. But I mean, is there something you could also just linger on?\n'cause he's one of the interesting figures in the history of technology. What makes him as successful as he was?\nWhat makes him as interesting as he was? What made him so productive and important\nin the development of technology? - He had an integrated worldview.\nSo the properly designed device that had the correct functionality, that had the deepest understanding of the user,\nthat was the most beautiful, right? Like, it had to be all of those things, right?\nHe basically would drive to as close to perfect as you could possibly get. Right? And you know, I suspect that he never quite, you know,\nthought he ever got there. 'cause most great creators, you know, are generally dissatisfied. You know, you read accounts later on and all they can,\nall they can see are the flaws in their creation. But like he got as close to perfect each step of the way as he could possibly get with the constraints\nof the technology of his time. And then, you know, look, he was, you know, sort of famous in the Apple model.\nIt's like, look, they will, you know, this headset that they just came out with, like, you know, it's like a decade long project, right?\nIt's like, and they're just gonna sit there and tune and tune and polish and polish and tune and polish and tune and polish until it is as perfect\nas anybody could possibly make anything. - Yeah. - And then this goes to the way that people describe working with him was, which is,\nyou know, there was a terrifying aspect of working with him, which is, you know, he was, you know, he was very tough. But there was this thing that everybody I've ever talked\nto worked for him, says that they all say the following, which is we did the best work\nof our lives when we worked for him because he set the bar incredibly high. And then he supported us with everything that he could\nto let us actually do work of that quality. So a lot of people who were at Apple spend the rest of their lives trying to find another experience\nwhere they feel like they're able to hit that quality bar again. - Even if it in retrospect or during it felt like suffering.\n- Yeah, exactly. - What does that teach you about the human condition? Huh?\n- So look, so say exactly. So the Silicon Valley, I mean, look, he's not, you know, George Patton you know in the Army.\nLike, you know, there are many examples in other fields, you know, that are like this specifically in tech.\nIt's actually, I find it very interesting. There's the Apple way, which is polish, polish, polish, and don't ship until it's as perfect as you can make it.\nAnd then there's the sort of the other approach, which is the sort of incremental hacker mentality, which basically says, ship early and often and iterate.\nAnd one of the things I find really interesting is I'm now 30 years into this, like, they're very successful companies on both sides\nof that approach, right? Like, that is a fundamental difference, right?\nIn how to operate and how to build and how to create that. You have world class companies operating in both ways.\nAnd I don't think the question of like, which is the superior model is anywhere close to being answered.\nLike, and my suspicion is the answer is do both. The answer is you actually want both. They lead to different outcomes.\nSoftware tends to do better with the iterative approach. Hardware tends to do better with the, you know,\nsort of wait and make it perfect approach. But again, you can find examples in both directions.\n- So the jury's still out on that one. So back to Mosaic. So, what it was text based Tim Burns Lee?\n- Well, there was the web, which was text based, but there were no, I mean there was like three websites. There was like no content, there were no users.\nLike, it wasn't like a catalytic, it hadn't, and by the way, it was all because it was all text. There were no documents,\nthere were no images, there were no videos, there were no, right. So, and then if, if in the beginning, if you had to be on a next cube, right?\nYou need to had a next cube both to publish and to consume. - So, there was 6,000 bucks you said. - There were limitations.\nYeah. $6,000 PC. They did not sell very many. But then there was also, there was also FTP and there was Use Nets, right?\nAnd there was, you know, a dozen other basically there's waste, which was an early search thing. There was Gopher, which was an early menu based\ninformation retrieval system. There were like a dozen different sort of scattered ways that people would get to information on the internet.\nAnd so the Mosaic idea was basically bring those all together, make the whole thing graphical, make it easy to use,\nmake it basically bulletproof so that anybody can do it. And then again, just on the luck side, it so happened that this was\nright at the moment when graphics, when the GUI sort of actually took off and we're now also used to the GUI that we think it's been around forever.\nBut it didn't real, you know, the Macintosh brought it out in 85, but they actually didn't sell very many Macs\nin the eighties. It was not that successful of a product. It really was. You needed Windows 3.0 on PCs and that hit in about 92.\nAnd so, and we did most in 92, 93. So that sort of, it was like right at the moment when you could imagine\nactually having a graphical user interface to right at all, much less one to the internet.\n- How old did Windows 3 sell? So was that the really big. - [Marc] That was the big bang.\n- The big operating graphical operating system? - Well this is the classic, okay. This Microsoft was operating on the other,\nso Steve the Apple was running on the Polish until it's perfect. Microsoft famously ran on the other model,\nwhich is ship and iterate. And so in the old line in those days was Microsoft Right's version three of every Microsoft product. That's the good one, right?\nAnd so there there are, you can find online Windows 1, Windows 2. Nobody used them. Actually the original Windows,\nin the original Microsoft Windows, the windows were non overlapping. And so you had these very small,\nvery low resolution screens and then you had literally-- - [Lex] Windows. - It just didn't work. It wasn't ready yet. Well.\n- And Windows 95 I think was a pretty big leap also. - That was a big leap too. So that was like bang, bang.\nAnd then of course Steve, and then when, you know, in the fullness of time Steve came back, then the Mac started, took off again.\nThat was the third bang. And then the iPhone was the fourth bang. - Such exciting time. - And then we were off, off to the races because.\n- Nobody could have known what would be created from that. - Well, Windows 3.1 or 3.0,\nWindows 3.0 to the iPhone was only 15 years. Right. Like that ramp was in retrospect.\nAt the time it felt like it took forever. But that in histor in historical terms, like that was a very fast ramp from even a graphical computer\nat all on your desk to the iPhone. That was 15 years. - So, did you have a sense of what the internet will be\nas you're looking through the window of Mosaic? Like, what you, like there's just a few web pages for now.\n- So the thing I had early on was I was keeping at the time what there's disputes over what was the first blog,\nbut I had one of them that at least is a possible, at least a rudder up in the competition.\nAnd it was what was called the What's new page. And it was literally, it was a hardwired in distribution unfair advantage.\nI wired, put it right in the browser, I put it in the browser and then I put my resume in the browser, which also was--\n- [Lex] Hilarious. - But I was keeping\nnot many people get to get to do that. - No, good call.\nAnd early days. It's so interesting. - I'm looking for my, about about, oh, Marc is looking for a job.\n- [Lex] Yeah, yeah, exactly. - So the West New page, I would literally get up every morning\nand I would, or every afternoon and I would basically, if you wanted to launch a website,\nyou would email me and I would list it on the most new page. And that was how people discovered the new websites as they were coming out.\nAnd I remember 'cause it was like one, it literally went from, it was like one every couple days to like one every day\nto like two every day. - And then so you're doing, so that blog was kind of doing the directory thing.\nSo like, what was the homepage? - So the homepage was just basically trying to explain even what this thing is that you're looking at. Right.\nBasically the basic instructions. But then there was a button, there was a button that said what's new. And what most people did was they went to,\nfor obvious reasons went to what's new. - [Lex] Yeah. - But like it was so mind blowing at that point. This the basic idea and it was, this was like, you know,\nthis was the basic idea of the internet, but people could see it for the first time. The basic idea was, look, you know, some, you know, it's like literally it's like an Indian restaurant in like\nBristol England has like put their menu on the web. And people were like, wow. - [Lex] Whoa.\n- Because like that's the first restaurant menu on the web. - [Lex] Yeah. - And I don't have to be in Bristol and I don't know if I'm ever gonna go to Bristol.\nAnd I don't even like Indian food and like. Wow. Right. And it was like that the first web, the first streaming video thing was\nit was in another England, some Oxford or something. Some guy put his coffee pot up as the first streaming video\nthing and he put it on the web 'cause he literally, it was the coffee pot down the hall. And he wanted to see when he needed to go refill it.\nBut there were, you know, there was a point when there were thousands of people like watching that coffee pot 'cause it was the first thing you could watch.\n- Well, but isn't were you able to kind of infer, you know, if that Indian restaurant could go online.\nThen you're like they all will. - [Marc] Yeah, exactly. - So you felt that? - [Marc] Yeah, yeah, yeah.\n- Okay. - Now, you know, look, it's still a stretch, right? It's still a stretch 'cause it's just like, okay, is it, you know, you're still in this zone, which is like, okay, is this a nerd thing?\nIs this a real person thing? By the way, you know, there was a wall of skepticism from the media. Like, they just, like, everybody was just like, yeah,\nthis is the crazy, this is just like dumb. This is not, you know, this is not for regular people at that time. And so you, you had to think through that and then look,\nit was still hard to get on the internet at that point, right? So you could get kind of this weird bastardized version\nif you were on AOL, which wasn't really real. Or you had to go like, learn what an ISP was.\nYou know, in those days, PCs actually didn't have TCPIP drivers come reinstalled. So you had to learn what a TCPIP driver was.\nYou had to buy a modem, you had to install driver software. I have a comedy routine. I do.\nSo it's like 20 minutes long describing all the steps required to actually get on the internet at this point. And so you had to look through these practical.\nWell, and then speed performance 14-4 modems, right? Like it was like watching, you know, glue dry, like,\nand so you had to, there were basically a sequence of bets that we made where you basically needed to look through that current state of affairs and say,\nactually there's gonna be so much demand for once people figure this out, there's gonna be so much demand for it that all of these practical problems are gonna get fixed.\n- Some people say that the anticipation makes the destination that much more exciting.\n- Do you remember progressive JPEGs? - Yeah. Do I, do I? - For kids in the audience, right?\n- [Lex] For kids in the audience. - You used to have to watch an image load like a line at the time. But it turns out there was this thing with JPEGs\nwhere you could load basically every fourth, you could load like every fourth line and then you could sweep back through again.\nAnd so you could like render a fuzzy version of image up front. And then it would like resolve into the detailed one. And that was like a big UI breakthrough\n'cause it gave you something to watch. - Yeah. And you know, there's applications in various domains for that.\n- Well it was a big fight. There was a big fight early on about whether there should be images in the web. And. - For that reason for like sexualization or--\n- Not explicitly that that did come up. But it wasn't even that, it was more just like all the serious in the argument went, the purists basically said all the serious information\nin the world is text. If you introduce images, you basically are gonna bring in all the trivial stuff. You're gonna bring in magazines and you know,\nall this crazy just, you know, stuff that, you know, people, you know, it's gonna, it is gonna distract from that. It's gonna go take it away from being serious to being frivolous.\n- Well, was there any (indistinct) type arguments about the internet destroying all of human civilization or destroying some\nfundamental fabric of human civilization? - So it was, those days it was all around crime and terrorism.\nSo those arguments happened, you know, but there was no sense yet of the internet having like, an effect on politics because that was way too, too far off.\nBut there was an enormous panic at the time around cybercrime. There was like enormous panic that like your credit card\nnumber would get stolen and you'd use life savings would be drained. And then, you know, criminals were gonna, there was, oh, when we started, one of the things we did,\none of the Netscape browser was the first widely used piece of consumer software that had strong encryption built in,\nit made it available to ordinary people. And at that time, strong encryption was actually illegal to export\noutta the US so we could feel that product in the US, we could not export it 'cause it was classified as munition.\nSo the Netscape browser was on a restricted list along with the tomahawk missile as being something that could not be exported.\nSo we had to make a second version with deliberately weak encryption to sell overseas with a big logo on the box saying, do not trust this.\nWhich it turns out, makes it hard to sell software when it's got a big logo that says don't trust it.\nAnd then we had to spend five years fighting the US government to get them to basically stop trying to do this regulation.\nBut because the fear was terrorists are gonna use encryption, right? To like plot, you know, all these things.\nAnd then, you know, we responded with, well actually we need encryption to be able to secure systems so that the terrorists\nand the criminals can't get into them. So that anyway, that was the 1990s fight. - So can you say something about some of the details\n"}
{"pod": "Lex Fridman Podcast", "input": "Software engineering", "output": "of the software engineering challenges required to build these browsers? I mean the engineering challenges of creating a product\nthat hasn't really existed before that can have such almost like limitless impact\non the world with the internet. - So there was a really key bet that we made at the time, which was very controversial,\nwhich was core to core to how it was engineered, which was are we optimizing for performance or for ease of creation?\nAnd in those days the pressure was very intense to optimize for performance because the network connections were so slow\nand also the computers were so slow. And so if you had, I mentioned the progressive JPEGs,\nlike if there's an alternate world in which we optimized for performance and it just,\nyou had just a much more pleasant experience right up front. But what we got by not doing that was we got ease of creation.\nAnd the way that we got ease of creation was all of the protocols and formats were in text, not in binary.\nAnd so HTTP is in text, by the way. And this was an internet tradition by the way that we picked up.\nBut we continued it. HTTP is text and HTML is text, and then every else, everything else that followed is text as a result.\nAnd by the way, you can imagine purist engineers saying this is insane. You have very limited bandwidth. Why are you wasting any time sending text?\nYou should be encoding this stuff into binary and it'll be much faster. And of course the answer is that's correct. But what you get when you make it taxed is all of a sudden,\nwell, the big breakthrough was the view source function, right? So the fact that you could look at a webpage, you could hit view source and you could see the HTML,\nthat was how people learned how to make webpages. Right? - It's so interesting 'cause the stuff would take for granted now is,\nman, that was fundamental, the development of the web to be able to have HTML just right there, all the ghetto mess that is HTML,\nall the sort of almost biological like messiness of HTML\nand then having the browser try to interpret that as. - [Marc] Exactly. - To show something reasonable.\n- Well and then there was this internet principle that we inherited, which was emit, what was it? Emit cautiously. Emit conservatively interpret liberally.\nSo it basically meant if you're, the design principle was if you're creating like a web editor that's gonna admit HTML, like do it as cleanly as you can,\nbut you actually want the browser to interpret liberally, which is you actually want users to be able to make all kinds of mistakes and for it to still work.\nAnd so the browser rendering engines to this day have all of this spaghetti code crazy stuff where they're resilient to all kinds of crazy issue,\nno mistakes. And so, literally what I always had in my head is like there's an 8 year old or an 11 year old somewhere and they're doing a view source,\nthey're doing a cut and paste and they're trying to make a webpage for their eternal or whatever. And like they leave out a slash and they leave out\nan angle bracket and they do this and they do that and it's still works. - It's also like a, I don't often think about this, but, you know, programming,\nyou know, C++ all those languages, lisp, the compiled languages, the interpreted languages,\nPython, Pearl, all that. The brace have to be all correct. It's like everything has to be perfect.\n- [Marc] Brutal. - And then-- - [Marc] Autistic. - You forget. All right. It's systematic and rigorous, let's go there.\nBut you forget that the, the web with JavaScript eventually.\nAnd HTML is allowed to be messy in the way for the first time.\nMessy in the way biological systems could be messy. It's like the only thing computers were allowed\nto be messy on for the first time. - It used to off fend me. So I grew up on Unix, so I worked on Unix.\nI was a Unix native for all the way through this period. And so, it used to drive me bananas when it would do the segmentation fault and the core dump file,\njust like it is, you know, it's like literally there's like a error in the code. The math is off by one. And it core dumps.\nAnd I'm in the core dump trying to analyze it and trying to reconstruct what, and I'm just like, this is ridiculous. Like, the computer ought to be smart enough\nto be able to know that if it's off by one, okay fine. And it keeps running. And I would go ask all the experts like, why can't it just keep running?\nAnd they'd explain to me, well, because all the downstream repercussions and blah blah. And I'm like, this still, like, you know, this is,\nwe're forcing the human creator to live to your point in this hyper, literal world of perfection.\n- [Lex] Yeah. And I was just like, that's just bad. And by the way, you know what happens with that of course.\nJust what what happened with, with coding at that point, which is you get a high priesthood, you know, there's a small number of people who are really good\nat doing exactly that. Most people can't. And most people are excluded from it. And so actually that was where that for that was where I picked up\nthat idea was like, no, you want these things to be resilient error in all kinds and this would drive the purist absolutely crazy.\nLike, I got attacked on this like a lot 'cause I mean like every time you know, all the purists who were like into all this\nlike Marcup language stuff and formats and codes and all this stuff, they would be like, you know, you're encouraging bad behavior 'cause.\n- Oh, so they wanted the browser to give you a fault error anytime there was a--\n- Yeah. They wanted to be a (indistinct) right? They wanted to-- Yeah. Yeah. That was a very and any properly\ntrained credential engineer would be like, that's not how you build these systems. - That's such a bold move to say,\nno, it doesn't have to be. - Yeah. No, like I said, the good news for me is the internet kind of had that traditional already, but having said that,\nlike we pushed it, we pushed it way out. But the other thing we did, going back to the performance thing, was we gave up a lot of performance.\nWe made that, that initial experience for the first few years was pretty painful. But the bet there was actually an economic bet, which was basically the demand for the web would basically\nmean that there would be a surge in supply of broadband. Like because the question was, okay,\nhow do you get the phone companies which are not famous in those days for doing new things at huge cost\nfor like speculative reasons. Like how do you get them to build up broadband, you know, spend billions of dollars doing that and you know,\nyou could go meet with them and try to talk them into it. Or you could just have a thing where it's just very clear that it's gonna be,\nthat people love that's gonna be better if it's faster. And, so that, there was a period there and this was, this was fraught with in peril,\nbut there was a period there where it's like we knew the experience was sub-optimized because we were trying to force the emergence of demand for broadband.\n- [Lex] Sure. - Which is in fact what happened. - So you had to figure out how to display this text,\nHTML text. So the blue links and the prop links. What? And there's no standards. Is there standards at that time?\n- [Marc] No. There really still isn't. - Well there's like standards, there's applied, implied standards. Right.\nAnd they, you know, there's all these kind of new features that are being added with like CSS, what, like what kind of stuff a browser should be able to support\nfeatures within languages, within JavaScript and so on. But you're setting standards on the fly yourself.\n- Yeah. Well to this day, if you create a webpage that has no CSS style sheet, the browser will render it however it wants to.\nRight. So this was one of the things, there was this idea, this idea of at the time and how these systems were built, which is separation of content from format\nor separation of content from appearance. And that's still, people don't really use that anymore\n'cause everybody wants to determine how things look and so they use CSS but it's still in there that you can just let the browser do all the work.\n- I still like the like really basic websites, but that could be just old school,\nkids these days with their fancy responsive websites that don't actually have much content,\nbut have a lot of visual elements. - Well that's one of the things that's fun about chat, you know, about ChatGPT like. - [Lex] Back to the basics.\n- Back to just text. - [Lex] Yeah. - Right? And it, you know, there is this pattern in human creativity and media\nwhere you end up back at text and I think there's, you know, there's something powerful in there. - Is there some other stuff\n"}
{"pod": "Lex Fridman Podcast", "input": "JavaScript", "output": "you remember like the purple links? There were some interesting design decisions that to kind of come up that we have today\nor we don't have today that were temporary. - So I made the background 'cause I hated reading texts\non white background, so I made the background gray. Everybody can-- - Do you go ahead to?\n- No. No, no. That decision I think has been reversed. But now I'm happy though because now dark mode is the thing.\n- So it wasn't about gray, it was just you didn't want white background. - [Marc] Strain my eyes.\n- Strain your eyes. Interesting. And then there's a bunch of other decisions.\nI'm sure there's an interesting history of the development of HTML and CSS and Interface and JavaScript\nand there's this whole Java applet thing. - Well the big one probably JavaScript, CSS was after me,\nso I didn't, that was not me. But JavaScript was the big, JavaScript maybe was the biggest of the whole thing. That was us.\nAnd that was basically a bet, it was a bet on two things. One is that the world wanted a new front end scripting language.\nAnd then the other was I thought at the time the world wanted a new backend scripting language. So JavaScript was designed from the beginning\nto be both front end and backend. And then it failed as a backend scripting language. And Java won for a long time.\nAnd then Python Pearl and other things, PHP and Ruby. But now JavaScript is back. And so.\n- I wonder if everything in the end will run on JavaScript. - It seems like it is the, and by the way,\nlemme give a shout out to, to Brendan Eich was basically the one man inventor of of JavaScript.\n- If you're interested to learn more about Brendan Eich, he's been on his podcast previously. - Exactly. So he wrote JavaScript over a summer\nand I mean I think it is fair, it is fair to say now that it's the most widely used language in the world and it seems to only be gaining\nin its in its range of adoption. - You know, in the software world there's quite a few stories of somebody\nover a week weekend or over a week or over a summer writing some of the most impactful revolutionary pieces\nof software ever. That should be inspiring. Yes. - Very inspiring. I'll give you another one.\nSSL. So SSL with the security protocol, that was us. And that was a crazy idea at the time,\nwhich was let's take all the native protocols and let's wrap them in a security wrapper. That was a guy named Kip Hickman who wrote that over a summer, one guy.\nAnd then look today, sitting here today, like the transformer like at Google was a small handful of people.\nAnd then, you know, the number of people who have did like the core work on GPT. It's not that many people,\nit's a pretty small handful of people. And so yeah, the pattern in software repeatedly over a very long time has been,\nit's Jeff Bezos always had the two pizza rule for teams at Amazon, which is any team needs to be able to be fed\nwith two pieces. If you need the third pizza, you have too many people. And I think it's actually the one pizza rule.\nFor the really creative work. I think it's two people, three people. - Well that's, you see that\nwith certain open source projects, like so much is done by like one or two people. Like it's so incredible and that's why you see\nthat gives me so much hope about the open source movement in this new age of AI where, you know,\njust recently having had a conversation with Marc Zuckerberg of all people who's all in on open source,\nwhich is so interesting to see and so inspiring to see 'cause like releasing these models, it is scary.\nIt is potentially very dangerous and we'll talk about that. But it's also,\nif you believe in the goodness of most people and in the skillset of most people\nand the desire to go do good in the world, that's really exciting. 'cause it's not putting it these models\ninto the centralized control of big corporations, the government and so on. It's putting it in the hands of a teen,\nteenage kid with like a dream in his eyes. I don't know. That's beautiful.\n- Look, this stuff, AI ought to make the individual coder obviously far more productive right? By like, you know, a thousand X or something.\nAnd so you ought to open source like, not just the future of open source AI, but the future of open source everything.\nWe ought to have a world now of super coders, right? Who are building things as open source with one or two people that were inconceivable,\nyou know, five years ago. You know, the level of kind of hyper productivity we're gonna get out of our best and brightest\nI think is gonna go way up. - It's gonna be interesting. We'll talk about it, but let's just to linger a little bit on Netscape.\n"}
{"pod": "Lex Fridman Podcast", "input": "Netscape", "output": "Netscape was acquired in 1999 for 4.3 billion by AOL.\nWhat was that like? What were some memorable aspects of that? - Well that was the height of the.com boom bubble bust.\nI mean that was the frenzy. If you watch succession, that was like what they did in the fourth season\nwith Gojo and the merger with their, so it was like the height of like one of those kind of dynamics. And so.\n- Would you recommend succession, by the way? I'm more of a Yellowstone guy. - Yellowstone's very American.\nI'm very proud of you. That's, that is. - I just talked to Matthew McConaughey and I'm full on Texan at this point.\n- Good. I approve. - And he'll be doing the SQL to Yellowstone. - [Marc] Yeah, just exciting.\n- Very exciting. Anyway. - [Marc] Can't wait. - So that's a rude interruption by me by way of succession.\nSo, that was at the height of the-- - Deal making and money and just the fur flying and like craziness.\nAnd so yeah, it was just one of those, it was just like, I mean, and this, the entire (indistinct) thing from start to finish was four years,\nwhich was like for one of these companies, it's just like incredibly fast. You know, it went, we went public 18 months after we got moved\nwhere we were founded, which virtually never happens. So it was just this incredibly fast kind of meteor streaking across the sky.\nAnd then of course it was this, and then there was just this explosion, right? That happened 'cause then it was almost immediately followed by the.com crash.\nIt was then followed by AOL, by Time Warner, which again is like the succession guys kinda play with that,\nwhich turned out to be a disastrous deal. You know, one of the famous, you know, kind of disastrous in business history.\nAnd then, you know, what became an internet depression on the other side of that. But then in that depression in the two thousands was\nthe beginning of broadband and smartphones and Web 2.0 right? And then social media and search and every SaaS\nand everything that came out of that. - What did you learn from just the acquisition? I mean this is so much money.\nWhat's interesting 'cause I must have been very new to you, that these software stuff,\nyou can make so much money. There's so much money swimming around. I mean, I'm sure the ideas of investment was\nstarting to get born there. - Yes. Let me get, so let me lay it. So here's, here's the thing. I dunno if I figured it out then, but figured it out later,\nwhich is software is a technology that it, it's like a, you know, the concept of the philosopher stone,\nthe philosopher stone in alchemy, transient is led into gold and Newton spent 20 years trying to find the philosopher stone. Never got there.\nNobody's ever figured it out. Software is our modern philosopher stone. And in economic terms, it transmutes labor into capital,\nwhich is like a super interesting thing. And by the way, like Carl Marcs is rolling over in his grave right now. 'Cause of course that's complete reputation\nof his entire theory. Trans labor and capital which is as follows, is somebody sits down at a keyboard\nand types a bunch of stuff in, and a capital asset comes out the other side and then somebody buys that capital asset\nfor a billion dollars. Like that's amazing, right? It's literally creating value right out of thin air,\nright out of purely human thought, right? And so that, there are many things\nthat make software magical and special, but that's the economics. - I wonder what Marx would've thought about that?\n- Oh, he would've completely broke his brain because of course the whole thing was it was he could, you know, that kind of technology was inconceivable\nwhen he was alive. It was all industrial era stuff. And so, any kind of machinery necessarily involved\nhuge amounts of capital. And then labor was on the receiving end of the abuse. - [Lex] Yep.\nRight? But like software eng software, a software engineer is somebody who basically transmutes his own labor into actual,\nan actual capital asset creates permanent value. Well, and in fact it's actually very inspiring. That's actually more true today than before.\nSo when I was doing software, the assumption was all new software basically has a sort of a parabolic sort of lifecycle, right?\nSo you ship the thing, people buy it at some point, everybody who wants it has bought it and then it becomes obsolete.\nAnd it's like bananas. Nobody, nobody buys old software. These days, Minecraft, Mathematica,\nyou know, Facebook, Google, you have the software assets that are, you know,\nhave been around for 30 years that are gaining in value every year, right? And they're just, they're being a world of warcraft, right,\nsalesforce.com, like they're being every single year they're being polished and polished and polished and polished. They're getting better and better, more powerful,\nmore powerful, more valuable, more valuable. So we've entered this era where you can actually have these things that actually build out over decades. Which by the way is what's happening\nright now with like ChatGPT. And so now, this is why, you know,\nthere is always, you know, sort of a constant investment frenzy around software is because, you know, look, when you start one of these things,\nit doesn't always succeed. But when it does now you might be building an asset that builds value for, you know, four or five, six decades to come.\nYou know, if you have a team of people who have the level of devotion required to keep making it better.\nAnd then the fact that of course everybody's online, you know, there's 5 billion people that are a click away from any new piece of software.\nSo the potential market size for any of these things is, you know, nearly infinite. - [Lex] It must have been surreal back then though.\n- Yeah. Yeah. This was all brand new, right? Yeah. Back then, this was all brand new. These were all, you know, brand new. Had you rolled out that theory in even 1999,\npeople would've thought you were smoking crack. So that's emerged over time. - Well, let's now turn back into the future.\n"}
{"pod": "Lex Fridman Podcast", "input": "Why AI will save the world", "output": "You wrote the essay \"Why AI Will Save The World?\" Let's start the very high level.\nWhat's the main thesis of the essay? - Yeah, so the main thesis on the essay is that what we're dealing with here is intelligence.\nAnd it's really important to kind of talk about the sort of very nature of what intelligence is. And fortunately we have a predecessor\nto machine intelligence, which is human intelligence. And we've got, you know, observations and theories over thousands of years\nfor what intelligence is in the hands of humans and what intelligence is, right? I mean, what it literally is the way to,\nyou know, capture, process, analyze, synthesize information, solve problems. But the observation of intelligence in human hands is\nthat intelligence quite literally makes everything better. And what I mean by that is every kind of outcome\nof like human quality of life, whether it's education outcomes or success of your children, or career success\nor health or lifetime satisfaction, by the way, propensity to peacefulness as opposed to violence,\npropensity for open-mindedness versus bigotry, those are all associated with higher levels of intelligence.\n- Smarter people have better outcomes than almost as you write in almost every domain of activity. Academic achievement, job performance,\noccupational status, income, creativity, physical health, longevity, learning new skills, managing complex tasks, leadership, entrepreneurial success,\nconflict resolution, reading comprehension, financial decision making, understanding others perspectives, creative arts,\nparenting outcomes, and life satisfaction. One of the more depressing conversations I've had,\nand I don't know why it's depressing, I have to really think through why it's depressing, but on IQ and the G factor,\nand that that's something in large part is genetic\nand it correlates so much with all of these things and success in life.\nIt's like all the inspirational stuff we read about, like if you work hard and so on,\nit sucks that you're born with the hand that you can't change. - But what if you could.\n- You're saying basically a really important point, and I think it's in your articles, it really helped me.\nIt's a nice added perspective to think about. Listen, human intelligence,\nthe science of intelligence is shown scientifically that it just makes life easier and better the smarter you are.\nAnd now let's look at artificial intelligence and if that's a way to increase some human intelligence,\nthen it's only going to make a better life. - [Marc] Yeah. - That's the argument. - And certainly at the collective level, we could talk about the collective effect\nof just having more intelligence in the world, which will have very big payoff. But there's also just at the individual level,\nlike what if every person has a machine? You know? And the concept of augment Doug Engelbart's concept of augmentation.\nYou know, what if everybody has an assistant and the assistant is, you know,\n140 IQ and you happen to be 110 IQ and you've got, you know,\nsomething that basically is infinitely patient and knows everything about you and is pulling for you in every possible way, wants you to be successful.\nAnd anytime you find anything confusing or wanna learn anything or have trouble understanding something or wanna figure out what to do in a situation, right?\nWanna figure out how to prepare for a job interview, like any of these things, like it will help you do it. And it will therefore,\nthe combination will effectively be, you know, will effectively raise your raise because it will effectively raise your IQ,\nwill therefore raise the odds of successful life outcomes in all these areas. - So people below the, this hypothetical 140 IQ,\nit'll pull them up towards 140 IQ. - Yeah, yeah, yeah. And then of course, you know, people at 140 IQ will be able to have a peer, right.\nTo be able to communicate, which is great. And then people above 140 IQ will have an assistance that they can farm things out to. And then look, God willing, you know,\nat some point these things go from future versions go from 140 IQ equivalent to 150 to 160 to 180, right?\nLike Einstein was estimated to be on the order of one 60, you know, so when we get, you know, one 60 AI,\nlike we'll be, you know, when one assumes creating Einstein level breakthroughs and physics, and then at 180 we'll be, you know,\ncarrying cancer and developing warp drive and doing all kinds of stuff. And so it is quite possibly the case,\nthis is the most important thing that's ever happened and the best thing that's ever happened because precisely because it's a lever on this single fundamental factor of intelligence,\nwhich is the thing that drives so much of everything else. - Can you steal, man, the case that human plus AI is not always better than human\nfor the individual? - You may have noticed that there's a lot of smart running around. - [Lex] Sure. Yes. - Right? And so, like smart,\nthere are certain people where they get smarter, you know, they get to be more arrogant, right? So that, you know, there's one huge flaw.\n- Although to push back on that, it might be interesting because when the intelligence is not\nall coming from you, but from another system, that might actually increase the amount of humility\neven in the assholes. - [Marc] One would hope. - Yeah. - Or it could make assholes more assholes.\nYou know, that's in, I mean, that's for psychology to study. - Yeah, exactly. Another one is smart people are very convinced that they,\nyou know, have a more rational view of the world, and that they have a easier time seeing through conspiracy theories and hoaxes and right.\nYou know, sort of crazy beliefs and all that. There's a theory in psychology, which is actually smart people. So for sure people who aren't as smart are very susceptible\nto hoaxes and conspiracy theories. But it may also be the case that the smarter you get, you become susceptible in a different way,\nwhich is you become very good at marshaling facts to fit preconceptions, right.\nYou become very, very good at assembling whatever theories and frameworks and pieces of data and graphs and charts you need to validate\nwhatever crazy ideas got in your head. And so you're susceptible in a different way, right?\n- We're all sheep, but different colored sheep. - Some sheep are better at justifying it. Right.\nAnd those are the, you know, those are the smart sheep, right? So yeah. Look like I would say this look like there are no panacea.\nI'm not a utopian, there are no panaceas in life. There are no, like, you know, I don't believe there are like pure positives.\nI'm not a transcendental kind of person like that. But, you know, so yeah, there are gonna be issues and, you know, look, smart people,\nanother maybe you could save about smart people is they are more likely to get themselves in situations that are, you know, beyond their grasp. You know, because they're just more confident\nin their ability to deal with complexity and their eyes become bigger, their cognitive eyes become bigger than their stomach, you know?\nSo yeah, you could argue those eight different ways nevertheless, on net, right? Clearly, overwhelmingly, again,\nif you just extrapolate from what we know about human intelligence, you're improving so many aspects of life if you're upgrading intelligence.\n- So there'll be assistants at all stages of life. So when you're younger, there's for education,\nall that kind of stuff for mentorship, all of this. And later on as you're doing work and you've developed\na skill and you're having a profession, you'll have an assistant that helps you excel at that profession.\nSo at all stages of life. - Yeah. I mean, look, the theory is augmentation. This is the Doug Engelbart's term. Doug Engelbart made\nthis observation many, many decades ago that, you know, basically it's like you can have this oppositional frame of technology where it's like us versus the machines,\nbut what you really do is you use technology to augment human capabilities. And by the way, that's how actually the economy develops.\nThat's, we can talk about the economic side of this, but that's actually how the economy grows is through technology augmenting human potential.\nAnd so, yeah. And then you basically have a proxy or you know, or you know, a sort of prosthetic, you know,\nso like you've got glasses, you've got a wristwatch, you know, you've got shoes, you know,\nyou've got these things. You've got a personal computer, you've got a word processor, you've got Mathematica, you've got Google.\nThis is the latest viewed through that lens. AI is the latest in a long series of basically augmentation\nmethods to be able to raise human capabilities. It's just this one is the most powerful one of all, because this is the one that, that goes directly\nto what they call fluid intelligence, which is IQ. - Well, there's two categories of folks\n"}
{"pod": "Lex Fridman Podcast", "input": "Dangers of AI", "output": "that you outline that worry about or highlight the risks of AI, and you highlight\na bunch of different risks. I would love to go through those risks and just discuss them, brainstorm which ones are serious\nand which ones are less serious. But first, the Baptist and the bootleggers, what are these two interesting groups of folks\nwho worry about the effect of AI and human civilization?\n- [Marc] Or say they do. - Say, oh, okay, yes, I'll say they do. - The Baptist worry the bootleggers say they do.\nSo the Baptist and the bootleggers is a metaphor from economics, from what's called development economics.\nAnd it's this observation that when you get social reform movements in a society, you tend to get two sets of people showing up,\narguing for the social reform. And the term Baptist and bootleggers comes from the American experience with alcohol prohibition.\nAnd so in the 1900s, 1910s, there was this movement that was very passionate at the time, which basically said,\nalcohol is evil and is destroying society. By the way, there was a lot of evidence to support this.\nThere were very high rates of very high correlations then, by the way. And now between rates of physical violence and alcohol use,\nalmost all violent crimes have either the perpetrator or the victim, or both drunk almost. If you see this actually in the work,\nalmost all sexual harassment cases in the workplace, it's like at a company party and somebody's drunk. Like, it's amazing how often alcohol actually correlates\nto actually dis dysfunction and at leads to domestic abuse and so forth, child abuse. And so you had this group of people who were like, okay,\nthis is bad stuff and we should outlaw it. And those were quite literally Baptist. Those were super committed, you know,\nhardcore Christian activists in a lot of cases. There was this woman whose name was Carrie Nation, who was this older woman who had been in this, you know,\nI don't know, disastrous marriage or something. And her husband had been abusive and drunk all the time. And she became the icon of the Baptist prohibitionist.\nAnd she was legendary in that era for carrying an ax and doing, you know, completely on her own doing raids of saloons\nand like taking her ax to all the bottles and eggs in the back. And so. - [Lex] A true believer.\n- An absolute true believer, and with absolutely the purist of intentions. And again, there's a very important thing here,\nwhich is there's, you could look at this cynically and you could say the Baptists are like delusional, you know, the extremists, but you could also say, look, they're right.\nLike she was, you know, she had a point. Like she wasn't wrong about a lot of what she said. - Yeah.\n- But it turns out the way the story goes is it turns out that there were another set of people who very badly wanted to outlaw alcohol in those days.\nAnd those were the bootleggers, which was organized crime that stood to make a huge amount of money if legal alcohol sales were banned.\nAnd this was, in fact, the way the history goes is this was actually the beginning of organized crime in the US. This was the big economic opportunity that opened that up.\nAnd so they went in together and no, they didn't go in together. Like the Baptist did not even necessarily know\nabout the bootleggers 'cause they were on their moral crusade. The bootleggers certainly knew about the Baptists. And they were like, wow, these people are like the great front people for like.\nYou know, it's-- - [Lex] Good PR. - Shenanigans in the background. And they got the (indistinct) Act passed, right.\nAnd they did in fact ban alcohol in the US and you'll notice what happened, which is people kept drinking, it didn't work, people kept drinking.\nThat bootleggers made a tremendous amount of money. And then over time it became clear that it made no sense\nto make it illegal and it was causing more problems. And so then it was revoked. And here we sit with legal alcohol a hundred years later\nwith all the same problems. And you know, the whole thing was this like giant misadventure\nthe Baptist got taken advantage of by the bootleggers, and the bootleggers got what they wanted. And that was that. - The same two categories of folks are\nnow sort of suggesting that the development of artificial intelligence should be regulated. - A hundred percent.\nIt's the same pattern. And the economist will tell you it's the same pattern every time. Like, this is what happened, nuclear power, this is what happens, which is another interesting one.\nBut like, yeah, this happens dozens and dozens of times throughout the last a hundred years and this is what's happening now.\n- And you write that it isn't sufficient to simply identify the actors and impugn their motives.\nWe should consider the arguments of both the Baptist and the bootleggers on their merits. So let's do just that.\nRisk number one, will AI kill us all?\n- [Marc] Yes. - So what do you think about this one?\nWhat do you think is the core argument here that the development of AGI perhaps better said,\nwill destroy human civilization? - Well, first of all, you just did a slight of hand 'cause we went from talking about AI to AGI.\n- Is there a fundamental difference there? - I don't know. What's AGI? - What's AI, what's in intelligence?\n- Well, I know what AI is machine learning. What's AGI? - I think we don't know what the bottom of the well\nof machine learning is or what the ceiling is. Because just to call something machine learning or just to call some of the statistics\nor just to call it math or computation doesn't mean, you know, nuclear weapons are just physics.\nSo to me it's very interesting and surprising how far machine learning has taken.\n- No, but we knew that nuclear physics would lead to weapons. That's why the scientists of that era were always in some this huge dispute about building the weapons.\nThis is different. AGI is different. - Does machine learning lead, do we know? - We don't know, but this is my point is different. We actually don't know.\nBut, and this is where you, the slide of hand kicks in, right? This is where it goes from being a scientific topic to being a religious topic.\nAnd that's why I specifically called out 'cause that's what happens. They do the vocabulary shift and all of a sudden you're talking about something totally.\nThat's not actually real. - Well then maybe you can also, as part of that, define the western tradition of Millennialism.\n- [Marc] Yes. Into the world apocalypse. - [Lex] What is it? - [Marc] Apocalypse cults. - [Lex] Apocalypse cults.\n- Well, so we live in, we of course live in a Judeo-Christian, but primarily Christian kind of saturated, you know, kind of Christian, post-Christian, secularized Christian,\nyou know, kind of world in the west. And of course court of Christianity is the idea of the second coming and you know,\nthe revelations and you know, Jesus returning and the thousand year, you know, utopia on earth and then you know,\nthe rapture and like all all that stuff, you know, you know, we collectively, you know, as a society, we don't necessarily take all that fully seriously now.\nSo, what we do is we create our secularized versions of that we keep looking for utopia. We keep looking for, you know,\nbasically the end of the world. And so what what you see over, over decades is that basically a pattern of these sort of these of is this is what cults are.\nThis is how cults form as they form around some theory of the end of the world. And so the people's temple cults, the Manson cult, the Heavens Gate cult,\nthe David Qresh cult, you know what they're all organized around is like, there's gonna be this thing that's gonna happen\nthat's gonna basically bring civilization crashing down. And then we have this special elite group of people who are gonna see it coming and prepare for it.\nAnd then they're the people who are either going to stop it or are failing, stopping it. They're gonna be the people who survived the other side\nand ultimately get credit for having been, right. - Why is that so compelling, do you think? Like-- - Because it satisfies this very deep need\nwe have for transcendence and meaning that got stripped away when we became secular.\n- Yeah, but why is the transcendence involve the destruction of human civilization?\n- Because like how plausible it's like a very deep psychological thing 'cause it's like how plausible,\nhow plausible is it that we live in a world where everything's just kind of all right? Right. How exciting? - [Lex] Whoa.\n- How exciting is that? Right? - [Lex] But that's. - We got more than that. - But that's the deep question I'm asking. Why is it not exciting to live in a world\nwhere everything's just all right? Is it, I think, you know, most of the animal kingdom would be\nso happy with just all right. Because that means survival. Why are we, maybe that's what it is.\nWhy are we conjuring up things to worry about? - So CS Lewis called it the God-shaped hole.\nSo there's a God-shaped hole in the human experience, consciousness, soul, whatever you wanna call it,\nwhere there's gotta be something that's bigger than all this. There's gotta be something transcendent.\nThere's gotta be something that is bigger, right? Bigger purpose. A bigger meaning. And so we have run the experiment of, you know,\nwe're just gonna use science and rationality and kind of, you know, everything's just gonna kind of be as it appears. And large number of people have found\nthat very deeply wanting and have constructed narratives. And by this is the story of the 20th century, right?\nCommunism, right? Was one of those, communism was a was a form of this, Nazism was a form of this.\nYou know, some people, you know, you can see movements like this playing out all over the world right now.\n- So you constructed a kind of devil, a kind of source of evil, and we're going to transcend beyond it.\n- Yeah. And (indistinct) when you see a Miller cult, they put a really specific point on it,\nwhich is end of the world, right, there is some change coming. And that change that's coming is so profound\nand so important that it's either gonna lead to utopia or hell on earth. Right? And it is going to, and then, you know,\nit's like what if you actually knew that was going to happen, right? What would you do? Right? How would you prepare yourself for it?\nHow would you come together with a group of like-minded people, right? How would you, what would you do? Would you plan like Cassius of weapons in the woods?\nWould you like, you know, I don't know if create underground buckers, would you, you know, spend your life trying to figure out a way to avoid having it happen?\n- Yeah. That's a really compelling, exciting idea to have a club over.\nTo have a little bit of travel, like a get together on a Saturday night and drink some beers and talk about the end of the world\nand how you are the only ones who have figured it out. - Yeah. And then once you lock in on that, like how can you do anything else with your life?\nLike this is obviously the thing that you have to do. And then there's a psychological effect that you alluded to. There's a psychological effect.\nIf you take a set of true believers and you leave them to themselves, they get more radical. Right. 'Cause they self radicalize each other.\n- That said, it doesn't mean they're not sometimes right. - Yeah. The end of the world might be.\nYes. Correct. Like they might be right. - [Lex] Yeah. - But like-- - [Lex] I have some pamphlets for you. - Exactly.\n- But I mean we'll talk about nuclear weapons 'cause you have a really interesting little moment that I learned about in your essay, but you know,\nsometimes it could be right. - [Marc] Yeah. - 'Cause we're still, you were developing more and more powerful technologies\nin this case, and we don't know what the impact it will have on human civilization while we can highlight all the different predictions\nabout how it'll be positive, but the risks are there and you discuss some of them.\n- Well, the steel man, the steel man is the steel man. Well actually, the steel man and his reputation are the same, which is you can't predict\nwhat's gonna happen. Right. You can't rule out that this will not end everything. Right. But the response to that is you have just made\na completely non-scientific claim. You've made a religious claim, not a scientific claim. - How does it get disproven?\n- And there's no, by definition with these kinds of claims, there's no way to disprove them. Right? And so there there's no, you just go right on the list.\nThere's no hypothesis, there's no testability of the hypothesis. There's no way to falsify the hypothesis,\nthere's no way to measure progress along the arc. Like it's just all completely missing.\nAnd so it's not scientific and. - I don't think it's completely missing. It's somewhat missing.\nSo for example, the people that say AI's gonna kill all of us. I mean, they usually have ideas about how to do that.\nWhether it's the people club maximizer or, you know, it escapes there's mechanism by which you can imagine it\nkilling all humans. - [Marc] Models. - And you can disprove it by saying\nthere's a limit to the speed\nat which intelligence increases. Maybe show that like the sort of rigorously really described\nmodel, like how it could happen and say, no, there, here's a physics limitation.\nThere's like a physical limitation to how these systems would actually do damage to human civilization.\nAnd it is possible they will kill 10 to 20% of the population, but it seems impossible for them to kill 99%.\n- It was practical counterarguments. Right. So you mentioned basically what I described as the thermodynamic counterargument, which, so sitting here today,\nit's like where with the evil AGI get the GPU. 'Cause like they don't exist. So if you're gonna have a very frustrated baby evil AGI,\nwho's gonna be like trying to buy Nvidia stock or something to get them to finally make some chips, right? So the serious form of that is the thermodynamic argument,\nwhich is like, okay, where's the energy gonna come from? Where's the processor gonna be running? Where's the data center gonna be happening?\nHow is this gonna be happening in secret such that, you know, it's not, you know, so that's a practical counter argument to the runaway AGI thing.\nI have a but I have and we can argue that, discuss that. I have a deeper objection to it, which is it's, this is all forecasting.\nIt's all modeling, it's all future prediction. It's all future hypothesizing. It's not science.\n- [Lex] Sure. - It is not. It is the opposite of science. So the, I'll pull up Carl Sagan extraordinary claims require\nextraordinary proof, right? These are extraordinary claims. The policies that are being called for right to prevent this\nare of extraordinary magnitude that, and I think we're gonna cause extraordinary damage. And this is all being done on the basis of something\nthat is literally not scientific. It's not a testable hypothesis. - So the moment you say AI's gonna kill all of us, therefore we should ban it,\nor that we should regulate all that kind of stuff, that's when it starts getting serious. - Or start, you know, military airstrikes and data centers.\n- [Lex] Oh boy. - Right? And like. - Yeah. This once get starts.\nWell, so starts getting real weird. - So here's the problem with Arian cults. They have a hard time staying away from violence.\n- Yeah. But violence is so fun. - If you're on the right end of it,\nthey have a hard time avoiding violence. The reason they have a hard time avoiding violence is if you actually believe the claim. Right.\nThen what would you do to stop the end of the world? Well, you would do anything, right? And so, and this is where you get, and again,\nif you just look at the history of Arian and cults, this is where you get the people's temple and everybody killing themselves in the jungle. And this is where you get Charles Manson and, you know,\nsending in to kill the pigs. Like, this is the problem with these. They have a very hard time to run the line\nat actual violence. And I think in this case, I mean, they're already calling for it like today and you know,\nwhere this goes from here is they get more worked up. Like I think is like really concerning. - Okay. But that's kind of the extremes.\nSo, you know, the extremes of anything are I was concerning. It's also possible to kind of believe that AI has\na very high likelihood of killing all of us. But and therefore we should maybe consider\nslowing development or regulating, so not violence or any of these kinds of things. But it's saying like, all right,\nlet's take a pause here. You know, you biological weapons, nuclear weapons. Like whoa, whoa, whoa, whoa, whoa.\nThis is like serious stuff. We should be careful. So it is possible to kinda have\na more rational response, right? If you believe this risk is real. - [Marc] Believe. - Yes. So what is it possible to be,\nhave a scientific approach to the prediction of the future? - I mean, we just went through this with COVID.\nWhat do we know about modeling? - [Lex] Well, I mean. - What did we learn about modeling with COVID?\n- [Lex] There's a lot of lessons. - They didn't work at all. - [Lex] They worked poorly. - The models were terrible, the models were useless.\n- I don't know if the models were useless or the people interpreting the models and then decentralized institutions\nthat were creating policy rapidly based on the models and leveraging the models in order to support their narratives\nversus actually interpreting the error bars and the models and all that kind of stuff. - What you had with COVID, my view you had with COVID is you had these experts\nshowing up and they claimed to be scientists and they had no testable hypotheses whatsoever. They had a bunch of models.\nThey had a bunch of forecasts and they had a bunch of theories and they laid these out in front of policy makers and policy makers freaked out and panicked. Right.\nAnd implemented a whole bunch of like, really like terrible decisions that we're still living with the consequences of,\nand there was never any empirical foundation to any of the models. None of them ever came true.\n- Yeah. To push back. There were certainly Baptist and bootleggers in the context of this pandemic, but there's still a usefulness to models. No.\n- So not if they're, I mean not if they're reliably wrong, right? Then they're actually like anti-useful. Right. They're actually damaging.\n- But what do you do with the pandemic? What do you do with any kind of threat? Don't you want to kind of have several models to play\nwith as part of this discussion of like, what the hell do we do here? - I mean, do they work?\nBecause they're an expectation that they actually like work that they have actual predictive value.\nI mean, as far as I can tell with COVID, the policymakers just si up themselves into believing that there was sub, I mean, look, the scientists,\nthe scientists were at fault. The quote unquote scientists showed up. So I had some insight into this. So there was a,\nor remember the Imperial College models out of London were the ones that were like, these are the gold standard models. So a friend of mine runs a big software company\nand he was like, wow, this is like, COVID is really scary. And he is like, you know, he contacted this research and he is like, you know, do you need some help? You've been just building this model on your own\nfor 20 years. Do you need some, would you like us our coders to basically restructure it so it can be fully adapted for COVID? And the guy said yes and sent over the code\nand my friend said it was like the worst spaghetti code he's ever seen. - That doesn't mean it's not possible to construct\na good model of pandemic with the correct air bars, with a high number of parameters that are continuously,\nmany times a day updated as we get more data about a pandemic. I would like to believe when a pandemic hits the world,\nthe best computer scientists in the world, the best software engineers respond aggressively\nand as input take the data that we know about the virus and it's an output say here is what's happening\nin terms of how quickly it's spreading, what that lead in terms of hospitalization and deaths and all that kind of stuff.\nHere's how likely, how contagious it likely is. Here's how deadly it likely is based on different conditions,\nbased on different ages and demographics and all that kind of stuff. So here's the best kinds of policy. It feels like you could have models,\nmachine learning that like kind of, they don't perfectly predict the future,\nbut they help you do something 'cause there's pandemics that are like, meh,\nthey don't really do much harm. And there's pandemics, you can imagine them, they could do a huge amount of harm.\nLike they can kill a lot of people. So you should probably have some kind of data-driven models\nthat keep updating, that allow you to make decisions that based like where, how bad is this thing?\nNow you can criticize how horrible all that went with the response to this pandemic,\nbut I just feel like there might be some value to models. - So to be useful at some point it has to be predictive. Right? So and the easy thing for me to do is to say,\nobviously you're right. Obviously I wanna see that just as much as you do. 'cause anything that makes it easier to navigate through society through a wrenching, you know, risk like\nthat sounds great. You know, the harder objection to it is just simply you are trying to model\na complex dynamic system with 8 billion moving parts. Like not possible. - [Lex] It's very tough.\n- Can't be done, complex systems can't be done. - Machine learning says hold my beer. But well, it's possible. No?\n- I don't know. I would like to believe that it is. I'll put it this way. I think where you and I would agree is I think we would like that to be the case.\nWe are strongly in favor of it. I think we would also agree that no such thing with respect to COVID or pandemics no such thing.\nAt least neither you nor I think are aware. I'm not aware of anything like that today. - My main worry with the response to the pandemic is\nthat same as with aliens, is that even if such a thing existed,\nand it's possible it existed, the policymakers were not paying attention.\nLike there was no mechanism that allowed those kinds of models to percolate all. - Oh, I think we had the opposite problem during COVID.\nI think the policymakers, I think these people with basically fixed science had too much access to the policymakers.\n- Well, right. And well, but the policy makers also wanted, they had a narrative in mind and they also wanted to use whatever model that fit that narrative\n- [Marc] Oh, sure. - To help them out. So like, it felt like there was a lot of politics and not enough science. - Although a big part of what was happening, a big reason we got lockdowns for as long as we did,\nwas because these scientists came in with these like doomsday scenarios that were like, just like completely off the hook. - Scientists in quotes, let's not--\n- [Marc] Quote unquote scientists. - Let's not, okay, let's give love science. So here's science that is the way out. - Science is a process of testing hypotheses.\nModeling does not involve testable hypotheses. Right. Like, I don't even know that. I actually don't even know\nthat modeling actually qualifies as science. Maybe that's a side conversation. We could have some time over a beer.\n- Oh, that's a really interesting part. What do we do about the future? I mean, what's-- - So number one is when we start with number one,\nhumility goes back to this thing of how do we determine the truth. Number two is we don't believe, you know, it's the old,\nI've gotta hammer everything looks like a nail, right? I've got, oh, this is one of the reasons I gave you, I gave Alexa book,\nwhich the topic of the book is what happens when scientists basically stray off the path of technical knowledge and start to weigh in on politics\nand societal issues. - In this case, philosophers. - Well in this case philosophers. But he actually talks in this book about, like Einstein,\nhe talks about, actually about the nuclear age in Einstein. He talks about the physicists actually doing very similar things at the time.\n- The book is When Reason Goes On Holiday, Philosophers in Politics by Nevin.\n- And it's just a story. It's a story. There are other books on this topic, but this is a new one that's really good this is just a story\nof what happens when experts in a certain domain decide to weigh in and become basically social engineers and political, you know, basically political advisors.\nAnd it's just a story of just inning catastrophe. Right. And I think that's what happened with COVID again.\n- Yeah. I found this book a highly entertaining and eye-opening read filled with amazing anecdote of a rationality and craziness by famous Resa philosophers.\n- I definitely, after you read this book, you will not look at Einstein the same. - [Lex] Oh boy. - Yeah. - Don't destroy my heroes.\n- He will not be a hero of yours anymore. Sorry. You probably couldn't, you shouldn't read the book. - All right.\n- But here's the thing. The AI risk people, they don't even have the COVID model,\nat least not that I'm aware of. - [Lex] No. - Like there's not even the equivalent of the COVID model. They don't even have the spaghetti code. They've got a theory and a warning and a this and the that.\nAnd like, if you ask like, okay, well here's, I mean, the ultimate example is, okay, how do we know, right?\nHow do we know that an AI is running away? Like how do we know that the boom takeoff thing is actually happening? And the only answer that any of these guys have given\nthat I've ever seen is, oh, it's when the loss rate, the loss function and the training drops, right?\nThat's when you need to like shut down the data center. Right? And it's like, well that's also what happens when you're successfully training a model.\nLike, what even this is not science,\nthis is not, it's not anything, it's not a model, it's not anything. There's nothing to arguing with. It is like, you know, punching jello, like there,\nthere's what do you even respond to? - So just put push back on that. I don't think they have good metrics\nof when the film is happening. But I think it's possible to have that. Like just as you speak now,\nI mean it's possible to imagine there could be measures. - It's been 20 years. - No, for sure.\nBut it is been only weeks since we had a big enough breakthrough in language models. We can start to actually have this,\nthe thing is the AI doer stuff didn't have any actual systems to really work with.\nAnd now there's real systems you can start to analyze like, how does this stuff go wrong? And I think you kind of agree that there is\na lot of risks that we can analyze. The benefits outweigh the risks in many cases. - Well, the risks are not existential.\n- [Lex] Yes. Well. - Not in the phone paper clip. Let me, okay. There's another slide of hand that you just alluded to.\nThere's another slide of hand that happens, which is very interesting. - I'm very good at the slide of hand thing. - Which is very not scientific.\nSo the book Super Intelligence, right, which is like the Nick Bostrom's book, which is like the origin of a lot of this stuff,\nwhich was written, you know, whatever, 10 years ago or something. So he does this really fascinating thing in the book, which is he basically says there are many possible routes\nto machine intelligence, to artificial intelligence. And he describes all the different routes to artificial intelligence, all the different possible,\neverything from biological augmentation through to, you know, all these different things. One of the ones that he does not describe is\nlarge language models because of course the book was written before they were invented. And so they didn't exist.\nIn the book, he describes them all and then he proceeds to treat them all as if they're exactly the same thing.\nHe presents them all as sort of an equivalent risk to be dealt with in an equivalent way to be thought about the same way. And then the risk, the quote unquote risk\nthat's actually emerged is actually a completely different technology than he was even imagining. And yet all of his theories and beliefs are being transplanted by this movement,\nlike straight onto this new technology. And so again, like there's no other area of science or technology where you do that.\nLike when you're dealing with like organic chemistry versus inorganic chemistry, you don't just like say, oh,\nwith respect to like either one, basically maybe, you know, growing up in eating the world or something, like they're just gonna operate the same way.\nLike you don't. - But you can start talking about like, as we get more and more actual systems\nthat start to get more and more intelligent, you can start to actually have more scientific arguments here.\n- [Marc] Oh yeah. - Like, you know, high level, you can talk about the threat of autonomous weapon systems back before we had any automation in the military.\nAnd that would be like very fuzzy kind of logic. But the more and more you have drones that are becoming\nmore and more autonomous, you can start imagining, okay, what does that actually look like and what's the actual\nthreat of autonomous weapons systems? How does it go wrong? And still it's very vague,\nbut you start to get a sense of like, all right, it should probably be illegal\nor wrong or not allowed to do like mass deployment\nof fully autonomous drones that are doing aerial strikes. - [Marc] Oh no.\n- On large areas. - [Marc] I think it should be required. - Right? So that's a no. - No, no. I think it should be required that only aerial vehicles are automated.\n- Okay. So you wanna go the other way? - I wanna go the other way. - So that, okay. - I think it's obvious that the machine is gonna make\na better decision than the human pilot. I think it's obvious that it's in the best interest of both the attacker and the defender and humanity at large.\nIf machines are making more of these decisions than not people, I think people make terrible decisions in times of war. - But like, there's ways this can go wrong too, right?\n- Well, it wars go terribly wrong now. This goes back to the whole, this is that whole thing about like the self-drive.\nDoes the self-driving car need to be perfect versus does it need to be better than the human driver? Does the automated drone need to be perfect\nor does it need to be better than a human pilot at making decisions under enormous amounts of stress and uncertainty?\n- Yeah, well, on average, the worry that AI folks have is the runaway.\n- They're gonna come alive. Right? That then again, that's the slight of hand, right. - Or not not come alive. Well, no, hold on a second.\nYou lose control as well. You lose control. - But then they're gonna develop goals of their own. They're gonna develop a mind of their own,\nthey're gonna develop their own. Right. - No more, more like Chernobyl style meltdown, like just bugs in the code accidentally, you know,\nforce you like the results in the bombing of like large civilian areas.\n- [Marc] Okay. And to a degree that's not possible in the current military strategies,\n- [Marc] I don't know. - Control by humans. - Well, actually we've been doing a lot of mass bombings to cities for a very long time. - Yes. And a lot of civilians died.\n- And a lot of civilians died. And if you watch the documentary, the Fog of War McNamara, it spends a big part of it talking about the fire bombing\nof the Japanese cities. Burning them straight to the ground. Right. The devastation in Japan, American military fire bombing the cities in Japan was\nconsiderably bigger devastation than the use of nukes. Right. So we've been doing that for a long time. We also did that to Germany,\nby the way Germany did that to us, right? Like that's an old tradition. The minute we got airplanes, we started doing indiscriminate bombing.\n- So one of the things-- - [Marc] We're still doing it. - The modern US military can do with technology with automation,\nbut technology more broadly is higher and higher precision strikes. - Yeah, I was saying, so precision is obviously precision\nand this is a (indistinct) right? So there was this big advance this big advance called the (indistinct) which basically was strapping a GPS transceiver\nto an unguided bomb and turning it into a guided bomb. And yeah, that's great. Like look, that's been a big advance,\nbut, and that's like a baby version of this question, which is okay, do you want like the human pilot, like guessing where the bomb's gonna land?\nOr do you want like the machine like guiding the bomb to his destination? That's a baby version of the question. The next version of the question is,\ndo you want the human or the machine deciding whether to drop the bomb? Everybody just assumes the human's gonna do a better job for what I think are fundamentally suspicious reasons.\n- Emotional, psychological reasons. - Yeah. I think it's very clear that the machine's gonna do a better job making that decision 'cause the humans making that decision are got awful.\nJust terrible. - [Lex] Yeah. - Right. And so yeah. So this is the thing. And then let's get to the, there was,\ncan I one more slide of hand? - [Lex] Yes. - It was in-- - Sure. Please. I'm a magician. You could say.\n- One more slight of hand. These things are gonna be so smart, right? That they're gonna be able to destroy the world and wreak havoc and like do all this stuff and plan and do all this\nstuff and evade us and have all their secret things and their secret factories and all this stuff. But they're so stupid that they're gonna get like,\ntangled up in their code and that's they're not gonna come alive, but there's gonna be some bug that's gonna cause them to like turn us all on a paper like that.\nThey're not gonna be genius in every way other than the actual bad goal. And it's just like, and that's just like a,\nlike ridiculous like discrepancy. And you can prove this today, you can actually address this today for the first time\nwith LLMs which is you can actually ask LLMs to resolve moral dilemmas.\nSo you can create the scenario, you know, dot, dot, dot this, that, this, that, this, that. What would you as the AI do in the circumstance?\nAnd they don't just say destroy all humans, destroy all humans. They will give you actually very nuanced moral,\npractical trade-off oriented answers. And so we actually already have the kind of AI that can actually like, think this through\nand can actually like, you know, reason about goals. - Well, the hope is that AGI\nor like various superintelligent systems have some of the nuance that LLMs have and the intuition is they most likely will\nbecause even these LLMs have the nuance. - LLMs are really, this is actually worth spending a moment\non LLMs are really interesting to have moral conversations with. And that I just,\nI didn't expect I'd be having a moral conversation with the machine in my lifetime. - Wait, and let's remember we're not really having\na conversation with the machine where we're having a conversation with the entirety of the collective intelligence of the human species.\n- Exactly. Yes. Correct. - But it's possible to imagine autonomous weapons systems that are not using LLMs.\n- But if they're smart enough to be scary, where are they not smart enough to be wise?\nLike, that's the part where it's like, I don't know how you get the one without the other. - Is it possible to be super intelligent without being super wise?\n- Well, again, you're back to that. I mean, then you're back to a classic autistic computer, right? Like you're back to just like a blind rule follower.\nI've got this like core, it's the paperclip thing. I've got this core rule and I'm just gonna follow it to the end of the earth. And it's like, well,\nbut everything you're gonna be doing execute that rule is gonna be super genius level that humans aren't gonna be able to counter. It's a mismatch in the definition\nof what the system's capable of. - Unlikely but not impossible, I think. - But again, here you get to like, okay, like.\n- No, I'm not saying when it's unlikely but not impossible. If it's unlikely, that means\nthe fear should be correctly calibrated. - Extraordinary claims require extraordinary proof. - Well, okay, so one interesting sort of tangent,\n"}
{"pod": "Lex Fridman Podcast", "input": "Nuclear energy", "output": "I would love to take on this because you mentioned this in the essay about nuclear, which was also, I mean,\nyou don't shy away from a little bit of of a spicy take. So Robert Oppenheimer famously said,\nnow I am become death the destroyer of worlds as he witnessed the first destination of a nuclear weapon\non July 16th, 1945. And you write an interesting historical perspective,\n\"Recall that John Van Neuman responded to Robert Oppenheimer's famous hand wringing about the role\nof creating nuclear weapons, which you note helped end World War II\nand prevent World War III with some people confess guilt to claim credit for the sin.\"\nAnd you also mentioned that Truman was harsher after meeting Oppenheimer. He said that \"Don't let that cry baby in here again.\"\n- Real quote, by the way, from Dean Atchison.\n- Boy. - 'Cause Oppenheimer didn't just say the famous line. - [Lex] Yeah. - He then spent years going around basically moaning him,\nyou know, going on TV and going into going into the White House and basically like, just like doing this hair shirt, you know, thing self, you know, this sort of self-critical like,\noh my god, I can't believe how awful I am. - So he's widely considered perhaps of the,\nbecause of the hang ringing as the father of the tom bomb. - [Marc] Yeah. - This is Van Norman's criticism of him is he tried to have\nhis cake and eat it too. Like he wanted to and Van Norman of course a very different kind of personality and he's just like, yeah, good.\nThis is like an incredibly useful thing. I'm glad we did it. - Yeah. Well Van Norman is is widely credit as being\none of the smartest humans of the 20th century. Certain people. Everybody says like,\nthis is the smartest person I've ever met when they've met him. Anyway, that doesn't mean, smart doesn't mean wise.\nSo yeah, I would love to sort of, can you make the case both for and against the critique\nof Oppenheimer here? 'Cause we're talking about nuclear weapons. Boy, do they seem dangerous?\n- Well so, the critique goes deeper and I left this out. Here's the real substance, I left it out 'cause I didn't wanna dwell\non nukes in my AI paper. But here's the deeper thing that happened and I'm really curious, this movie coming out this summer,\nI'm really curious to see how far he pushes this. 'cause this is the real drama in the story, which is, it wasn't just a question of our nukes, good or bad,\nit was a question of should Russia also have them? And what actually happened was Russia got\nthe American invented the bomb. Russia got the bomb, they got the bomb through espionage,\nthey got American and you know, they got American scientists and foreign scientists working on the American project. Some combination of the two basically gave the Russians\nthe designs for the bomb. And that's how the Russians got the bomb. There's this dispute to this day of Oppenheimer's role\nin that if you read all the histories, the kind of composite picture, and by the way,\nwe now know a lot actually about Soviet espionage in that era 'cause there's been all this declassified material in the last 20 years that actually shows a lot of very interesting things.\nBut if you kinda read all the histories, which you kinda get is Oppenheimer himself probably was not he probably did not hand over the nuclear secrets himself.\nHowever, he was close to many people who did. Including family members. And there were other members of the Manhattan Project\nwho were Russian, Soviet SS and did hand over the bomb. And so the view of that Oppenheimer and people like him had\nthat this thing is awful and terrible and oh my god. And you know, all this stuff you could argue fed into this ethos\nat the time that resulted in people thinking that the Baptists thinking that the only principle thing to do was to give\nthe Russians the bomb. And so the moral beliefs on this thing and the public discussion\nand the role that the inventors of this technology play, this is the point of this book, when they kind of take on this sort of public intellectual,\nmoral kind of thing, it can have real consequences, right? Because we live in a very different world today\nbecause Russia got the bomb than we would've lived in had they not gotten the bomb right. The entire 20th century, second half of the 20th century would've played out\nvery different had those people not given Russia the bomb. And so the stakes were very high then. The good news today is nobody's sitting here today,\nI don't think worrying about like an analogous situation with respect to like, I'm not really worried that Sam Altman's gonna decide\nto give, you know, the Chinese, the design for AI, although he did just speak at a Chinese conference,\nwhich is in interesting. But however, I don't think that's what's at play here, but what's at play here are all these other fundamental\nissues around what do we believe about this and then what laws and regulations and restrictions that we're gonna put on it.\nAnd that's where I draw like a direct straight line. And anyway, and my reading of the history on nukes is like the people who were doing the full hair shirt public,\nthis is awful. This is terrible. Actually had like catastrophically bad results from taking those views.\nAnd that's what I'm worried it's gonna happen again. - But is there a case to be made that you really need to wake the public up to the dangers\nof nuclear weapons when they were first dropped? Like really like educate them on like, this is extremely dangerous and destructive weapon.\n- I think the education kind of happened quick and early, like-- - [Lex] How? - It was pretty obvious. - [Lex] How?\n- We dropped one bomb and destroyed an entire city. - Yeah. So 80,000 people dead. - [Marc] Yep. - But.\n- [Marc] And look. But-- - I don't like the reporting of that. You can report that in all kinds of ways.\n- [Marc] Oh, there wars. - You can do all kinds of slants. Like war is horrible. War is terrible. You can do, you can make it seem like nuclear,\nthe use of nuclear weapons is just a part of war and all that kind of stuff. Something about the reporting and the discussion\nof nuclear weapons resulted in us being terrified in awe of the power of nuclear weapons\nand that potentially fed in a positive way towards the game theory of mutual issue destruction.\n- Well, so this gets to what actually, let's get to what actually happens. - [Lex] Some of us, me playing devil's advocate here. - Yeah, yeah, sure. Of course. Let's get to what actually happened and then kind\nof back into that. So what actually happened, I believe, and again I think this is a reasonable reading of history, is what actually happened was nukes then prevented\nWorld War III and they prevented World War III through the game theory of mutually assured destruction had nukes not existed. Right.\nThere would've been no reason why the Cold War did not go hot. Right. And then there and then, you know, and the military planners at the time, right,\nthought both on both sides thought that there was gonna be World War III on the planes of Europe and they thought there was gonna be like a hundred million people dead. Right?\nIt was like the most obvious thing in the world to happen. Right? And it's the dog that didn't bark right? Like it may be like the best single net thing that happened\nin the entire 20th century is that like that didn't happen. - Yeah. Actually, just on that point, you say a lot of really brilliant things.\nIt hit me just as you were saying it. I don't know why it hit me for the first time,\nbut we got two wars in a span of like 20 years.\nLike we could have kept getting more and more world wars and more and more ruthless.\nIt actually, you could have had a US versus Russia war. - You could, by the way you haven't,\nthere's another hypothetical scenario. The other hypothetical scenario is that Americans got the bomb, the Russians didn't.\nRight? And then America's the big dog and then maybe America would've had the capability to actually roll back the iron curtain.\nI don't know whether that would've happened, but like it's entirely possible. Right? And the act of these people\nwho had these moral positions about, 'cause they could forecast, they could model, they could forecast the future of how the technology would get used, made a horrific mistake.\n'cause they basically ensured that the iron curtain would continue for 50 years longer than it would've otherwise. Like, and again, like these are counter-factuals,\nI don't know that that's what, what would've happened, but like the decision to hand the bomb\nover was a big decision made by people who were very full of themselves.\n- Yeah. But so me as an America, me as a person that loves America, I also wonder if US was the only ones\nwith the nuclear weapons. - That was the argument for handing\nthat was the guys who (indistinct) the guys who handed over the bomb. That was actually their moral argument. - Yeah. I would probably not hand it over to,\nI would be careful about the regimes. You hand it over to there, maybe give it to like the British or something,\nor like a democratically-elected government. - Well, look, there are people to this day\nwho think that those bias Soviet spies did the right thing because they created a balance of terror as opposed to the US having just, and by the way, let me--\n- Balance of terror. - [Marc] Let's tell the full version story has-- - Such a sexy ring to it. - Okay. So the full version of the story is John Van Norman is a hero of both yours and mind.\nThe full version of the story is he advocated for a first strike. So when the US had the bomb and Russia did not,\nhe advocated for, he said, we need to strike them right now. - Strike Russia.\n- [Marc] Yes. - Van Norman. - Yes, because he said World War III is inevitable.\nHe was very hardcore. His theory was World War III is inevitable.\nWe're definitely gonna have World War III. The only way to stop World War III is we have to take them out right now and we have to take them out right now before they get the bomb.\n'Cause this is our last chance. Now again, like-- - Is this an example of philosophers and politics? - I don't know if that's in there or not,\nbut this is in the standard. - No, but it is meaning is that. - Yeah, this is on the other side. So, most of the case studies, most of the case studies in books like this are\nthe crazy people on the left. Van Norman is a story arguably of the crazy people on the right.\n- Yes. Stick to computing, John. - Well. This is the thing, and this is the general principle. Getting back to our core thing, which is like,\nI don't know whether any of these people should be making any of these calls. Because there's nothing in either Van Norman's background\nor Oppenheimer's background or any of these people's background that qualifies them as moral authorities. - Yeah. Well this actually brings up the point of, in AI,\nwho are the good people to reason about the morality of the ethics, the outside of these risks,\noutside of like the more complicated stuff that you, you agree on is, you know, this will go into the hands of bad guys\nand all the kinds of ways they'll do is interesting and dangerous, is dangerous in interesting\nunpredictable ways. And who is the right person? Who are the right kinds of people to make decisions, how to respond to it? Or is the tech people?\n- So the history of these fields, this is what he talks about in the book, the history of these fields, is that the competence\nand capability and intelligence and training and accomplishments of senior scientists and technologists working on a technology and then being able\nto then make moral judgments in the use of that technology. That track record is terrible that track record is like catastrophically bad.\nThe people-- - Just the linger, the people that develop that technology are usually not going to be the right people.\n- Well why would they? So the claim is of course, they're the knowledgeable ones. But the the problem is they've spent their entire life in a lab. Right.\nThey're not theologians. Well, so what you find, what you find when you read, when you read this, when you look at these histories,\nwhat you find is they generally are very thinly informed on history, on sociology, on theology, on morality, on ethics.\nThey tend to manufacture their own worldviews from scratch. They tend to be very sort of thin.\nThey're not remotely the arguments that you would be having if you got like a group of highly qualified theologians or philosophers or, you know.\n- Well, let me sort of, as the devil's advocate, takes a simple whiskey say that I agree with that.\nBut also it seems like the people who are doing kind of the ethics departments and these tech companies go sometimes the other way.\n- [Marc] Yes, they're definitely. - Which they're not nuanced on history or theology\nor this kind of stuff. It almost becomes a kind of outraged activism towards directions that don't seem to be\ngrounded in history and humility and nuance. It's again, drenched with arrogance. So--\n- [Marc] Definitely. - I'm not sure which is worse. - Oh no, they're both bad. Yeah. So definitely not them either. - So, but I guess.\n- Well look, this is a hard. - Yeah, it's a hard problem. - This is a hard problem. This goes back to where we started, which is, okay, who has the truth?\nAnd it's like, well, you know, like how does societies arrive at like truth and how do we figure these things out and like our elected leaders play some role in it.\nYou know, we all play some role in it. There have to be some set of public intellectuals at some point that bring, you know,\nrationality and judgment and humility to it. Those people are few and far between. We should probably prize them very highly.\n- Yeah. So celebrate humility in our public leaders. So getting to risk number two,\n"}
{"pod": "Lex Fridman Podcast", "input": "Misinformation", "output": "will AI ruin our society short version as you write, if the murder robots don't get us the hate speech\nand misinformation will. And the action you recommend in short,\ndon't let the thought police suppress AI. Well what is this risk of the effect of misinformation\nof society that's going to be catalyzed by AI? - Yeah, so this is the social media,\nthis is what you just alluded to. It's the activism kind of thing that's popped up in these companies in the industry. And it's basically, from my perspective,\nit's basically part two of the war that played out over social media over the last 10 years, 'cause you probably remember social media 10 years ago,\nwas basically who even wants this? Who wants a photo of what your cat had for breakfast? Like, this stuff is like silly and trivial\nand why can't these nerds like figure out how to invent something like useful and powerful? And then, you know, certain things happened in the political system.\nAnd then it sort of, the polarity on that discussion switched all the way to social media is like the worst, most corrosive, most terrible, most awful technology ever invented.\nAnd then it leads to, you know, terrible of the wrong, you know, politicians and policies and politics and like, and all this stuff.\nAnd that all got catalyzed into this very big kind of angry movement both inside and outside the companies\nto kind of bring social media to heal. And that got focused in particularly on two topics, so-called hate speech and so-called misinformation.\nAnd that's been the saga playing out for the last decade. And I don't even really want to even argue the pros and cons of the sides just to observe\nthat's been like a huge fight and has had, you know, big consequences to how these companies operate.\nBasically that same, those same sets of theories, that same activist approach, that same energy as being transplanted straight to AI.\nAnd you see that already happening. It's why, you know, ChatGPT will answer, let's say certain questions and not others. It's why it gives you the canned speech about, you know,\nwhenever it starts with, as a large language model, I cannot, you know, basically means that somebody has reached in there and told that it can't talk about certain topics.\n- Do you think some of that is good? - So it's an interesting question. So a couple observations.\nSo, one is the people who find this the most frustrating are the people who are worried about the murder robots, right?\nSo, and in fact so called X risk people, right? They started with the term AI safety,\nthe term became AI alignment. When the term became AI alignment is when this switch happened from we're worried it's gonna kill us all to we're worried about hate speech\nand misinformation. - [Lex] Sure. - The AI X risk people have now renamed their thing AI not kill everyone-ism,\nwhich I have to admit is a catchy term. And they are very frustrated by the fact that the hate speech sort of activist driven hate speech misinformation\nkind of thing is taking over. Which is what's happened is taken over, the AI ethics field has been taken over by the hate speech misinformation people.\nYou know, look, would I like to live in a world in which like everybody was nice to each other all the time and nobody ever said\nanything mean and nobody ever used a bad word and everything was always accurate and honest. Like, that sounds great.\nDo I wanna live in a world where there's like a centralized thought police working through the tech companies to enforce the view of a small set of elites that they're gonna\ndetermine what the rest of us think and feel like? Absolutely not. - There could be a middle ground somewhere like\nWikipedia type of moderation. There's moderation of Wikipedia that is somehow crowdsourced\nwhere you don't have centralized elites, but it's also not completely just a free for all\nbecause if you have the entirety of human knowledge at your fingertips, you can do a lot of harm.\nLike if you have a good assistant that's completely uncensored, they can help you build a bomb,\nthey can help you mess with people's physical wellbeing.\nRight. If they, because that information is out there on the internet and so presumably there's, it would be,\nyou could see the positives in censoring some aspects of an AI model\nwhen it's helping you commit literal violence. - Yeah. And there's a section later section of the essay\nwhere I talk about bad people doing bad things. - [Lex] Yes. - Right. Which and there's this, there's a set of things that we should discuss there.\n- [Lex] Yeah. - What happens in practice is these lines, as you alluded to this already, these lines are not easy to draw.\nAnd what I've observed in the social media version of this is like, the way I describe it as the slippery slope is not a fallacy, it's an inevitability.\nThe minute you have this kind of activist personality that gets in a position to make these decisions they take it straight to infinity.\nLike, it goes into the crazy zone like almost immediately and never comes back because people become drunk with power.\nRight. And look, if you're in the position to determine what the entire world thinks and feels and reads and says like, you're gonna take it and you know, Elon has, you know,\nventilated this with the Twitter files over the last, you know, three months and it's just like crystal clear, like how bad it got there now.\n- [Lex] Yeah. - Reason for optimism is what Elon is doing with community notes. So community notes is actually a very interesting thing.\nSo, what Elon is trying to do with community notes is he's trying to have it where there's only a community note\nwhen people who have previously disagreed on many topics agree on this one. - Yes, that's what I'm trying to get at is like,\nthere could be Wikipedia like models or community notes type of models where allows you to essentially either provide\ncontext or sensor in a way that's not resist the slippery slope nature. Power. - Now there's an entirely different approach here,\nwhich is basically we have AIs that are producing content. We could also have ais that are consuming content. Right?\nAnd so one of the things that your assistant could do for you is help you consume all the content, right? And basically tell you when you're getting played.\nSo for example, I'm gonna want the AI that my kid uses, right, to be very, you know, child safe and I'm gonna want it to filter for him all kinds\nof inappropriate stuff that he shouldn't be saying just 'cause he's a kid. Right? And you see what I'm saying is you can implement that. The architectural, you could say you can solve this\non the client side, right? You solving on the server side gives you an opportunity to dictate for the entire world, which I think is\nwhere you take the slippery slope to hell, there's another architectural approach, which is to solve this on the client side,\nwhich is certainly what I would endorse. - It's AI risk number five, will AI lead to bad people doing bad things?\nAnd I can just imagine language models used to do so many bad things, but the hope is there that you can have large language\nmodels used to then defend against it by more people, by smarter people, by more effective people, skilled people,\nall that kind of stuff. - Three-part argument on bad people doing bad things. So, number one, right?\nYou can use the technology defensively and we should be using AI to build like broad spectrum vaccines and antibiotics for like bio weapons and we should\nbe using AI to like hunt terrorists and catch criminals and like, we should be doing like all kinds of stuff like that. And in fact,\nwe should be doing those things even just to like go get like, you know, basically go eliminate risk from like regular pathogens that aren't like constructed by an AI.\nSo there's the whole defensive set of things. Second is we have many laws on the books\nabout as actual bad things, right? So it is actually illegal to be a criminal, you know, to commit crimes, to commit terrorist acts to, you know,\nbuild pathogens with the intent to deploy them to kill people. And so we have those, we actually don't need new laws\nfor the vast majority of these scenarios. We actually already have the laws in the book, on the books. The third argument is the minute,\nand this is sort of the foundational one that gets really tough, but the minute you get into this thing, which you were kind of getting into, which is like, okay,\nbut like, don't you need censorship sometimes, right? And don't you need restrictions sometimes? It's like, okay, what is the cost of that?\nAnd in particular in the world of open source, right? And so is open source AI going to be allowed or not?\nIf open source AI is not allowed, then what is the regime that's going to be necessary legally\nand technically to prevent it from developing? Right? And here again is where you get into and people have\nproposed that these kinds of things. You get into I would say pretty extreme territory pretty fast. Do we have a monitor agent on every CPU and GPU\nthat reports back to the government? What we're doing with our computers, are we seizing GPU clusters that get beyond a certain size?\nLike, and then by the way, how are we doing all that globally, right? And like if China's developing an LLM beyond the scale\nthat we think is allowable, are we gonna invade? Right. And you have figures on the AI X risk side\nwho are advocating any, you know, potentially up to nuclear strikes to prevent, you know, this kind of thing. And so here you get into this thing\nand again, you know, maybe you could maybe say this is, you know, you could even say this is what good, bad or indifferent or whatever. But like here's the comparison of nukes,\nthe comparison of nukes is very dangerous because one is just nukes, were just, although we can come back to nuclear power.\nBut the other thing was like with nukes, you could control plutonium, right? You could track plutonium and it was like hard to come by. AI is just math and code, right?\nAnd it's in like math textbooks and it's like, there are YouTube videos that teach you how to build it. And like there's open source, there's already open source.\nYou know, there's a 40 billion parameter model running around already called Falcon Online that anybody can download. And so, okay,\nyou walk down the logic path that says we need to have guardrails on this. And you find yourself in an authoritarian,\ntotalitarian regime of thought control and machine control that would be so brutal that you would've destroyed\nthe society that you're trying to protect. And so I just don't see how that actually works. - So yeah, you have to understand my brain's going\nfull steam ahead here 'cause I agree with basically everything you're saying, but I'm trying to play devil's advocate here\nbecause okay, you're highlighted the fact that there is a slippery slope to human nature. The moment you censor something,\nyou start to censor everything. That alignment starts out sounding nice,\nbut then you start to align to the beliefs of some select group of people.\nAnd then it's just your beliefs the number of people you're aligning to smaller and smaller as that group becomes more and more powerful.\nOkay. But that just speaks to the people that censor are usually the assholes\nand the assholes get richer. I wonder if it's possible to do without that for AI.\nOne way to ask this question is do you think the base models, the baseline foundation models should be open sourced?\nLike, where Marc Zuckerberg is saying they want to do. - So look, I mean I think it's totally appropriate\nthe companies that are in the business of producing a product or service should be able to have a wide range\nof policies that they put, right? And I'll just, again, I want a heavily censored model for my eight year old.\nLike, I actually want that, like, like I would pay more money for the ones more heavily censored than the one that's not, right.\nAnd so, like there are certainly scenarios where companies will make that decision. Look, an interesting thing you brought up\nor is this really a speech issue? One of the things that the big tech companies are dealing with is that content generated from an LLM is not covered\nunder section 230, which is the law that protects internet platform companies\nfrom being sued for the user generated content. And so it is actually-- - [Lex] Oh, wow.\n- Yes and so there, there's actually a question. I think there's still a question, which is can big American companies actually feel\ngenerative AI at all? Or is the liability actually gonna just ultimately convince them that they can't do it?\nBecause the minute the thing says something bad, and it doesn't even need to be hate speech, it could just be like an (indistinct) it could hallucinate\na product, you know, detail on a vacuum cleaner, you know, and all of a sudden the vacuum cleaner company sues\nfor misrepresentation. And there's asymmetry there, right? 'Cause the LLMs gonna be producing billions of answers to questions and it only needs to get a few wrong to have.\n- [Lex] So, loss has to get updated really quick here. - Yeah. And nobody knows what to do with that, right? So, so anyway, like there are big,\nthere are big questions around how companies operate at all. So we talk about those, but then there's this other question of like, okay,\nthe open source. So what about open source? And my answer to your question is kind of like, obviously yes, the models have,\nthere has to be full open source here because to live in a world in which that open source is not allowed is\na world of draconian speech control, human control, machine control.\nI mean, you know, black helicopters with jackbooted thugs coming out, repelling down and seizing your GPU like territory.\n- [Lex] Well. - No, no, I'm a hundred percent serious. - That's you're saying slippery slope always leads there.\n- No, no, no, no. That's what's required to enforce it. Like how will you enforce a ban on open source and AI? - No. Well you could add friction to it,\nlike harder to get the models. 'Cause people will always be able to get the models, but it'll be more in the shadows, right?\n- The leading open source model right now is from the UAE. Like the next time they do that, what do we do?\n- [Lex] Yeah. - Like. - Oh, I see you're like. - A 14 year old in Indonesia comes out with a breakthrough.\nYou know, we talked about most great software comes from a small number of people. Some kid comes out with some big new breakthrough and quantization or something\nand has some huge breakthrough. And like, what are we gonna like, invade Indonesia and arrest him?\n- It seems like in terms of size of models and effectiveness of models, the big tech companies will probably lead the way for quite\na few years and the question is of what policies they should use? The kid in Indonesia should not be regulated,\nbut should Google, Meta, Microsoft, Open AI be regulated?\n- Well, so, but this goes, okay, so when does it become dangerous? Right.\nIs the danger that it's as powerful as the current leading commercial model? Or it is just at some other arbitrary threshold?\nAnd then by the way, like look, how do we know, like what we know today is that you need like a lot of money to like train these things.\nBut there are advances being made every week on training efficiency and, you know, data, all kinds of synthetic, you know, look,\nI don't even like the synthetic data thing we're talking about. Maybe some kid figures out a way to auto-generate synthetic data. - [Lex] That's gonna change everything.\n- Yeah, exactly. And so like sitting here today, like, the breakthrough just happened, right? You made this point like the breakthrough just happened.\nSo we don't know what the shape of this technology is gonna be. I mean the big shock here is that, you know,\nwhatever number of billions of parameters basically represents at least a very big percentage of human thought.\nLike who would've imagined that? And then there's already work underway. There was just this paper that just came out that basically\ntakes a gpt three scale model and compresses it down or run on a single 32 core CPU. Like who would've predicted that?\n- [Lex] Yeah. - You know, some of these models now you can run on raspberry pies like today they're very slow, but like, you know,\nmaybe they'll be a, you know, perceived you have real perform, you know, like it's math and code. And here we're back in here,\nwe're back in, dude, it's math and code. It's math and code, it's math, code and data. It's bits. - Marc has just like walked away at this point.\nYou just screw it. I don't know what to do with this. You guys created this whole internet thing.\nYeah, yeah. I mean, I'm a huge believer in open source here. - So my argument is we're gonna have,\nsee here's my argument is a, my argument, my full argument is, is AI is gonna be like air, it's gonna be everywhere. Like this is just gonna be in text.\nIt already is, it's gonna be in textbooks and kids are gonna grow up knowing how to do this. And it's just gonna be a thing. It's gonna be in the air and you can't like pull\nthis back anymore. You can't pull back air. And so you just have to figure out how to live in this world, right? And then that's where I think like all this hand ringing\nabout AI risk is basically a complete waste of time, 'cause the effort should go into okay, what is the defensive approach?\nAnd so if you're worried about you know, AI generated pathogens, the right thing to do is to have a permanent project warp speed, right?\nFunded lavishly. Let's do a Manhattan, let's talk about Manhattan project, let's do a Manhattan project for biological defense, right?\nAnd let's build ais and let's have like broad spectrum vaccines where like, we're insulated from every pathogen. - And well, the interesting thing is because it's software,\na kid in his basement, teenager could build like a system that defends against like the worst, I mean, and to me defense is super exciting.\nIt's like, if you believe in the good of human nature for that, most people wanna do good,\nto be the savior of humanity is really exciting. - Yes.\n- Not, okay, that's a dramatic statement. But to help people. - Yeah, of course. Help people. - Yeah. Okay.\n"}
{"pod": "Lex Fridman Podcast", "input": "AI and the economy", "output": "What about just the jump around, what about the risk of will AI lead to crippling inequality?\nYou know, 'cause we're kind of saying everybody's life will become better. Is it possible that the rich get richer here?\n- Yeah, so this goes, this actually ironically goes back to Marxism. So 'cause this was the, so the core claim of Marxism, right?\nBasically was that the owner, the owners of capital would basically own the means of production. And then over time they would basically accumulate\nall the wealth the workers would be paying in, you know, and getting nothing in return 'cause they wouldn't be needed anymore, right?\nMarx was very worried about mech what he called mechanization or what later became known as automation. And that, you know,\nthe workers would be immiserated and the the capitalists would end up with all. And so this was one of the core principles of Marxism.\nOf course it turned out to be wrong about every previous wave of technology. The reason it, it turned out to be wrong about every previous wave of technology is\nthat the way that the self-interested owner of the machines makes the most money is by providing the production capability in the form\nof products and services to the most people, the most customers as possible, right? The the largest,\nand this is one of those funny things where every CEO knows this intuitively, and yet it's like hard to explain from the outside the way you make the most money in any business is\nby selling to the largest market you can possibly get to. The largest market you can possibly get to is everybody on the planet.\nAnd so every large company does is everything that it can to drive down prices, to be able to get volumes up, to be able to get to everybody on the planet.\nAnd that happened with everything from electricity, it happened with telephones, it happened with radio, it happened with automobiles, it happened with smartphones,\nit happened with PCs, it happened with the internet, it happened with mobile broadband.\nIt's happened by the way, with Coca-Cola. It's happened with like every, you know, basically every industrially produced, you know,\ngood or service people, you wanna drive it to the largest possible market. And then as proof of that, it's already happened, right?\nWhich is the early adopters of like ChatGPT and Bing are not like, you know, Exxon and Boeing.\nThey're, you know, your uncle and your nephew, right? It's just like free. It's either freely available online or it's available\nfor 20 bucks a month or something. But the, you know, these things went this technology went mass market immediately.\nAnd so look, the owners of the means of production, the whoever does this now mentioned these trillion dollar questions.\nThere are people who are gonna get really rich doing this, producing these things, but they're gonna get really rich by taking this technology to the broadest possible market.\n- So yes, they'll get rich, but they'll get rich having a huge positive impact on. - Yeah, making the technology available to everybody. Right.\nAnd again, smartphone, same thing. So there's this amazing kind of twist in business history, which is you cannot spend $10,000 on a smartphone, right?\nYou can't spend a hundred thousand dollars, you can't spend a million, like I would buy the million dollars smartphone. Like I'm signed up for it. Like if it's like,\nsuppose a million dollar smartphone was like much better than the thousand dollar smartphone. Like I'm there to buy it, it doesn't exist. Why doesn't it exist?\nApple makes so much more money driving the price further down from a thousand dollars than they would trying to harvest, right?\nAnd so it's just this repeating pattern you see over and over again where and what's great about it is you,\nyou do not need to rely on anybody's enlightened right? Generosity to do this. You just need to rely on capitalist self-interest.\n- What about AI taking our jobs? - Yeah. So very very similar thing here. There's sort of a, there's a core fallacy which again was\nvery common in Marxism, which is what's called the lump of labor fallacy. And this is sort of the fallacy that there is\nonly a fixed amount of work to be done in the world. And it's all being done today by people and then if machines do it,\nthere's no other work to be done by people. And that's just a completely backwards view on how the economy develops and grows.\nBecause what happens is not in fact that what happens is the introduction of technology into production process\ncauses prices to fall. As prices fall, consumers have more spending power. As consumers have more spending power,\nthey create new demand. That new demand then causes capital and labor to form into new enterprises to satisfy nuance and needs.\nAnd the result is more jobs at higher wages. - So nuance and needs, the worries that the creation\nof nuance and needs at a rapid rate will mean there's a lot of turnover in jobs.\nSo people will lose jobs. Just the actual experience of losing a job and having to learn new things and new skills is painful\nfor the individuals. - Well, two things. One is the new jobs are often much better. So this actually came up that there was this panic\nabout a decade ago and all the truck drivers are gonna lose their jobs, right? And number one, that didn't happen 'cause we haven't figured out a way to actually finish that yet.\nBut the other thing was like, look, truck driver, like I grew up in a town that was basically consisted of a truck stop, right? And I like knew a lot of truck drivers\nand like truck drivers live a decade shorter than everybody else. Like, it's actually like a very dangerous,\nlike, they get, like literally they have like higher rates of skin cancer and on the left side of their, on the left side of their body\nfrom being in the sun all the time. The vibration of being in the truck is actually very damaging to your physiology.\n- And there's actually perhaps partially because of that reason there's a shortage of people who wanna be truck drivers.\n- Yeah. Like, it's not like the question always you wanna ask somebody like that is, do you want, you know, do you want your kid to be doing this job?\nAnd like most of them will tell you no. Like, I want my kid to be sitting in a cubicle somewhere like where they don't have this, like, where they don't die 10 years earlier.\nAnd so, the new jobs, number one, the new jobs are often better, but you don't get the new jobs until you go through the change.\nAnd then to your point, the training thing, you know, is always the issue is can people adapt? And again, here you need to imagine living in a world\nin which everybody has the AI assistant capability, right? To be able to pick up new skills much more quickly\nand be able to have some, you know, be able to have a machine to work with to augment their skills. - It's still gonna be painful, but that's the process of life.\n- It's painful for some people. I mean there's no, like, there's no question it's painful for some people and they're, you know, they're yes, it's not, again,\nI'm not a utopian on this and it's not like, it's positive for everybody in the moment, but it has been overwhelmingly positive for 300 years.\nI mean, look, the concern here, the concern, this concern has played out for literally centuries and you know,\nthis is the sort of Luddite, you know, the story of the Luddites that you may remember, there was a panic in the two thousands around outsourcing\nwas gonna take all the jobs. There was a panic in the 2010s that robots were gonna take all the jobs.\nIn 2019 before COVID we had more jobs at higher wages both in the country and in the world\nthan at any point in human history. And so the overwhelming evidence is that the net gain here is like, just like wildly positive.\nAnd most people like overwhelmingly come out the other side being huge beneficiaries of this.\n"}
{"pod": "Lex Fridman Podcast", "input": "China", "output": "- So you write that the single greatest risk, this is the risk you're most convinced by the single greatest risk of AI is\nthat China wins global AI dominance and we the United States and the West do not.\nCan you elaborate? - Yeah. So this is the other thing which is a lot of this sort of AI risk debates today sort\nof assume that we're the only game in town, right? And so we have the ability to kind of sit in the United States and criticize ourselves and do,\nyou know, have our government like, you know, beat up on our companies and we'll figure out a way to restrict what our companies can do and you know,\nwe're gonna, you know, we're gonna ban this and ban that, restrict this and do that. And then there's this like other like force out there that like doesn't believe we have any power\nover them whatsoever and they have no desire to sign up for whatever rules we decide to put in place and they're gonna do whatever it is they're gonna do.\nAnd we have no control over it at all. And it's China and specifically the Chinese Communist party\nand they have a completely publicized open, you know, plan for what they're gonna do with AI.\nAnd it is not what we have in mind. And not only do they have that as a vision and a plan for their society,\nbut they also have it as a vision and plan for the rest of the world. - So their plan is what? Surveillance? - Authoritarian control.\nSo authoritarian population control you know, good old-fashioned communist authoritarian control\nand surveillance and enforcement and social credit scores and all the rest of it.\nAnd you are gonna be monitored and metered within an inch of everything all the time.\nAnd it's gonna, you know, it's basically the end of human freedom and that's their goal. And you know, they justify it on the basis\nof that's what leads to peace. - You're worried that the regulating\nin the United States will haul progress enough to where the Chinese government would win that race.\n- So their plan, yeah. Yes, yes. And the reason for that is they, and again, they're very public on this. They have, their plan is to proliferate\ntheir approach around the world and they have this program called the Digital Silk Road, right. Which is building on their Silk Road investment program.\nAnd they've got, they've been laying networking infrastructure all over the world with their 5G, right. Work with their company Huawei.\nAnd so, they've been laying all this fabric, but financial and technological fabric all over the world. And their plan is to roll out their vision of AI on top of that and to have\nevery other country be running their version. And then if you're a country prone to, you know,\nauthoritarianism, you're gonna find this to be an incredible way to become more authoritarian. If you're a country, by the way,\nnot prone to authoritarianism, you're gonna have the Chinese Communist Party running your infrastructure and having backdoor into it. Right.\nWhich is also not good. - What's your sense of where they stand in terms of the race towards super intelligence as compared to the United States?\n- Yeah, so good news is they're behind, but bad news is they, you know, let's just say they get access to everything we do. So they're probably a year behind at each point in time,\nbut they get, you know, downloads I think of basically all of our work on a regular basis through a variety of means.\nAnd they are, you know, at least we'll see, they're at least putting out reports of very, they just put out a report last week of a GPT 3.5 analog.\nThey put out this report, forget what it's called, but they put out this report of this and they did and they, you know, the way when open AI you know,\nputs out, one of the ways they test, you know, GPT they run it through standardized exams like the SAT. Right.\nJust how you can kind of gauge how smart it is. And so the Chinese report, they ran their LLM through the Chinese equivalent\nof the SAT and it includes a section on Marxism and a section on, I say tongue of thought.\nAnd it turns out their AI does very well on both of those topics. - That's right.\n- So like. - Oh, this alignment thing. - Communist AI, right? Like literal communist AI. Right? And so their vision is like, that's the, you know,\nso you know, you can just imagine like you're a school, you know, you're a kid 10 years from now in Argentina\nor in Germany or in who knows where, Indonesia. And you ask the AI,\nI'd explain to you like how the economy works and it gives you the most cheery, upbeat explanation of Chinese style communism you've ever heard. Right.\nSo like the stakes here are like really big. - Well, as we've been talking about,\nmy hope is not just with the United States, but with just the kid in his basement. The open source LLM.\n'Cause I don't know if I trust large centralized institutions with super powerful AI\nno matter what their ideology as a power corrupts.\n"}
{"pod": "Lex Fridman Podcast", "input": "Evolution of technology", "output": "You've been investing in tech companies for about, let's say 20 years. And about 15 of which was with Andreessen Horowitz.\nWhat interesting trends in tech have you seen over that time? Let's just talk about companies and just the evolution\nof the tech industry. - I mean the big shift over 20 years has been that tech used to be a tools industry for basically from like 1940 through\nto about 2010, almost all the big successful companies were pick and shovels companies. So PC, database, smartphone, you know,\nsome tool that somebody else would pick up and use. Since 2010, most of the big wins have been in applications.\nSo a company that starts you know, starts in an existing industry and goes directly\nto the customer in that industry. And you know, the earliest examples there were like Uber and Lyft\nand Airbnb. And then that model is kind of elaborating out. The AI thing is actually a reversion on that for now\n'cause like most of the AI business right now is actually in cloud provision of AI APIs for other people to build on.\n- But the big thing will probably be in app. - Yeah. I think most of the money I think probably will be in whatever your AI financial advisor\nor your AI doctor or your AI lawyer or, you know, take your pick of whatever the domain is. And there, and what's interesting is, you know,\nthe valley kind of does everything. The entrepreneurs kind of elaborate every possible idea. And so there will be a set of companies that like make AI\nsomething that can be purchased and used by large law firms and then there will be other companies that just go direct\nto market as an AI lawyer. - What advice could you give for a startup founder?\nJust haven't seen so many successful companies, so many companies that fail also,\nwhat advice could you give to a startup founder, someone who wants to build the next super successful startup\nin the tech space? The Googles, the Apples, the Twitters. - Yeah. So the great thing\nabout the really great founders is they don't take any advice. So, if you find yourself listening to advice,\nmaybe you shouldn't do it. - But that's actually, just to elaborate on that, if you could also speak to great founders too.\nLike what makes a great founder? - So what makes a great founder is super smart, coupled with super energetic, coupled with super courageous.\nI think it's some of those three and-- - Intelligence, passion and courage. - The first two are traits and the third one is a choice.\nI think courage is a choice. Well 'cause courage is a question of pain tolerance, right?\nSo how many times are you willing to get punched in the face before you quit?\nAnd here's maybe the biggest thing people don't understand about what it's like to be a startup founder is it gets\nvery romanticized, right? And even when it, even when they fail, it still gets romanticized about like what a great adventure it was.\nBut like the reality of it is most of what happens is people telling you no and then they usually follow\nthat with you're stupid, right. No, I will not come to work for you. I will not leave my cushy job at Google\nto come work for you. No, I'm not gonna buy your product, you know, no, I'm not gonna run a story about your company. No, I'm not this, that, the other thing.\nAnd so a huge amount of what people have to do is just get used to just getting punched and the reason people don't understand this is\nbecause when you're a founder, you cannot let on that this is happening 'cause it will cause people to think that you're weak and they'll lose faith in you.\nSo you have to pretend that you're having a great time when you're dying inside, right?\nYou're just in misery. - But why did they do it? - Why did they do? Yeah, that's the thing. It's like it is a level,\nthis is actually one of the conclusions I think is that I think it's actually for most of these people on a risk adjusted basis, it's probably an irrational act.\nThey could probably be more financially successful on average if they just got like a real job in at a big company.\nBut there's, you know, some people just have an irrational need to do something new and build something for themselves and, you know,\nsome people just can't tolerate having bosses. Oh, here's the fun thing is how do you reference check founders, right?\nSo you call the, you know, normal way you reference check, you're hiring somebody is you call the bosses, they're their, and you know, and you find out if they were good employees\nand now you're trying to reference check Steve Jobs, right? And it's like, oh God, he was terrible. You know, he was a terrible employee.\nHe never did what we told him to do. - So what's a good reference? Do you want the previous boss to actually say\nthey never did what you told him to do? That might be a good thing. - Well, ideally what you want is I will go,\nI would like to go to work for that person. He worked for me here and now I'd like to work for him. No, unfortunately, most people can't, their egos can't\nhandle that. So they won't say that. But that's the ideal. - What advice would you give to those folks in the space of intelligence, passion and courage?\n- So I think the other big thing is you see people sometimes who say, I wanna start a company and then they kind of work through the process\nof coming up with an idea. And generally those don't work as well as the case where somebody has the idea first\nand then they kind of realize that there's an opportunity to build a company and then they just turn out to be the right kind of person to do that.\n- When you say idea, do you mean long-term big vision or do you mean specifics of like product?\n- Specific I would say specific, like specifically what specifics. Like what is the, because for the first five years you don't get to have vision,\nyou just gotta build something people want and you gotta figure out a way to sell it to them. Right. It's very practical or you never get to big vision.\n- So the first product, you have an idea of a set of products of the first product that can actually make some money.\n- Yeah. Like it's gotta work. The first product's gotta work by which I mean like, it has to technically work, but then it has to actually fit into the category\nand the customer's mind if something that they want and then by the way, the other part is they have to be willing to pay for it. Like somebody's gotta pay the bills.\nAnd so you've gotta figure out how to price it and whether you can actually extract the money. So usually it is much more predictable.\nSuccess is never predictable, but it's more predictable if you start with a great idea and then back into starting the company.\nSo this is what we did, you know, we had most, before we had escape, the Google guys had the Google search engine working at Stanford. Right.\nYou know, yeah. Actually there's tons of examples where they, you know, Pierre Omaira had eBay working before he left his previous job.\n- So I really love that idea of just having a thing, a prototype that actually works before you even begin\nto remotely scale. Yeah. - By the way, it's also far easier to raise money, right? Like the ideal pitch that we receive is,\nhere's the thing that works, would you like to invest in our company or not? Like, that's so much easier than here's 30 slides with a dream, right?\nAnd then we have this concept called the DMAs, which our biology of came up with when he was with us.\nSo then there's this thing, this goes to mythology, which is, you know, there's a mythology that kind of,\nyou know, these ideas, you know, kind of arrive like magic or people kind of stumble into them. It's like eBay with the pest dispensers or something.\nThe reality usually with the big successes is that the founder has been chewing on the problem\nfor 5 or 10 years before they start the company and they often worked on it in school or they even experimented on it\nwhen they were a kid and they've been kind of training up over that period of time to be able to do the thing.\nSo they're like a true domain expert. And it sort of sounds like mom, I'm an apple pie, which is yeah,\nyou wanna be a domain expert in what you're doing, but you would, you know, the mythology is so strong of like, oh, I just like had this idea in the shower right now I'm doing it.\nLike it's generally not that. - No, because it's, well, maybe in the shower we had the exact product\nimplementation details, but yeah, usually you're gonna be for like years if not decades\nthinking about like everything around that.\n- Well we call it the DMAs because the DMAs basically is like, there's all these permutations,\nlike for any idea, there's like all these different permutations, who should the customer be? What shape forms should the product have\nand how should we take it to market and all these things. And so the really smart founders have thought\nthrough all these scenarios by the time they go out to raise money and they have like detailed answers on every one of those fronts\nbecause they put so much thought into it. The sort of more haphazard founders haven't thought\nabout any of that. And it's the detailed ones who tend to do much better. - So how do you know when to take a leap\nif you have a cushy job or happy life? - I mean the best reason is just 'cause you can't tolerate not doing it right?\nLike this is the kind of thing where if you have to be advised into doing it, you probably shouldn't do it. And so it's probably the opposite,\nwhich is you just have such a burning sense of this has to be done, I have to do this, I have no choice. - What if it's gonna lead to a lot of pain?\n- It's gonna lead to a lot of pain. I think that's. - What if it means losing sort of social relationships\nand damaging your relationship with loved ones and all that kind of stuff.\n- Yeah, look, so like, it's gonna put you in a social tunnel for sure, right? So you're gonna, like, you know, there's this game you can play on Twitter,\nwhich is you can do any whiff of the idea that there's basically any such thing as work life balance and that people should actually work hard\nand everybody gets mad. But like, the truth is like all the successful founders are working 80 hour weeks and they're working, you know, they form very,\nvery strong social bonds with the people they work with. They tend to lose a lot of friends on the outside or put those friendships on ice.\nLike that's just the nature of the thing, you know, for most people that's worth the trade off. You know, the advantage, you know,\nmaybe younger founders have is maybe they have less, you know, maybe they're not, you know, for example, if they're not married yet or don't have kids yet, that's an easier thing to bite off.\n- Can you be an older founder? - Yeah. You definitely can. Yeah. Yeah. Many of the most successful founders are second, third, fourth time founders.\nThey're in their thirties, forties, fifties. The good news with being an older founder is, you know, more and you, you know, a lot more about what to do,\nwhich is very helpful. The problem is, okay, now you've got like a spouse and a family and kids and like, you've gotta go to the baseball game and like,\nyou can't go to the base, you know, and so it's. - [Lex] Life is full of difficult choices.\n- Yes. - Marc Andreessen, you've written a blog post on what you've been up to. You wrote this in October, 2022,\n"}
{"pod": "Lex Fridman Podcast", "input": "How to learn", "output": "\"Mostly I try to learn a lot. For example, the political events of 2014 to 2016 make clear to me\nthat I didn't understand politics at all referencing maybe some of this book here.\nSo I deliberately withdrew from political engagement and fundraising and instead read my way back into history\nand as far to the political left and political right as I could.\" So just high level question,\nwhat's your approach to learning? - Yeah, so it's basically, I would say, I'm an AutoID direct, so it's sort of goes,\nit's going down the rabbit holes. So it's a combination. I kind of allude to it in that, in that quote, it's a combination of breadth and depth.\nAnd so I tend to, yeah, I tend to, I go broad by the nature of what I do, I go broad, but then I tend to go deep in a rabbit hole for a while,\nread everything I can and then come out of it. And I might not revisit that rabbit hole for, you know, another decade. - And in that blog post that I recommend\npeople go check out, you actually list a bunch of different books that you recommend on different topics on the American left,\non the American right. It's just a lot of really good stuff. The best explanation for the current structure\nof our society and politics. You give to recommendations, four books on the Spanish Civil War, six books on deep history of the American right\ncomprehensive biographies. These of Adolf Hitler, one of which I read can recommend six books on the deep\nhistory of the American left. So the American right, American left looking at the history to give you the context\nbiography of later Lennon, two of them on the French Revolution. I actually,\nI have never read a biography on Lennon maybe that would be useful. Everything's been so Marc's focused.\n- The Sebastian biography of Lennon is extraordinary. - [Lex] Victor Sebestyen. Okay. - Blow your mind. Yeah.\n- [Lex] So it's still useful to read. - It's incredible. Yeah, it's incredible. I actually think it's the single best book on the Soviet Union. - So that the perspective of Lennon,\nit might be the best way to look at the Soviet Union versus Stalin versus Marx versus, very interesting.\nSo two books on fascism and anti-fascism by the same author,\nPaul Gottfried, brilliant book on the nature of mass movements and collective psychology, the definitive work on intellectual life under\ntotalitarianism, the Captive Mind, the definitive worked on the practical life under totalitarianism.\nThere's a bunch. There's a bunch. And the single best book, first of all, the list here is just incredible.\nBut you say the single best book I have found on who we are and how we got here is the Ancient City\nby Numa Dennis Fustel De Coulanges. I like it.\nWhat did you learn about who we are as a human civilization from that book? - Yeah, so this is a fascinating book.\nThis one's free, it's a free, by the way, it's a book in the 1860s. You can download it or you can buy printouts up prints of it.\nBut it was this guy who was a professor at the savant in the 1860s and he was apparently a savant on antiquity\non Greek and Roman antiquity and the reason I say that is because his sources are 100%\noriginal Greek and Roman sources. So he wrote a basically history of western civilization from, on the order of 4,000 years ago\nto basically the present times entirely working on fresh original Greek and Roman sources.\nAnd what he was specifically trying to do was he was trying to reconstruct from the stories of the Greeks and the Romans,\nhe was trying to reconstruct what life in the west was like before the Greeks and the Romans, which was in the civilization known\nas the Indo Europeans. And the short answer is, and this is sort of 4,000,\nyou know, 2000 BC to, you know, sort of 500 BC kind of that 1500 year stretch for civilization developed.\nAnd his conclusion was basically cults. They were basically cults and civilization was,\nor organized into cults. And the intensity of the cults was like a million fold beyond anything\nthat we would recognize today. Like it was a level of all encompassing belief\nand an action around religion that was at a level of extremeness\nthat we wouldn't even recognize it and so specifically he tells the story of basically\nthere were three levels of cults. There was the family cult, the tribal cult, and then the city cult as society scaled up.\nAnd then each cult was a joint cult of family gods, which were ancestor gods.\nAnd then nature gods and then your bonding into a family, a tribe or a city was based on your adherence\nto that religion. People who were not of your family, tribe, city, worship,\ndifferent gods, which gave you not just the right with or responsibility to kill them on site. - [Lex] So they were serious about their cults.\n- Hardcore, by the way, shocking development. I did not realize this zero concept of individual rights.\nLike even even up through the Greeks, and even in the Romans, they didn't have, have the concept of individual rights. Like the idea that as an individual you have like\nsome rights just like, nope. Right? And you look back and you're just like, wow, that's just like cr like fascist in a degree\nthat we wouldn't recognize today. But it's like, well, they were living under extreme pressure for survival.\nAnd you, and you know, the theory goes, you could not have people running around making claims, individual rights when you're just trying to get\nlike your tribe through the winter, right? Like you need like hardcore command and control. And actually what if through modern political lens,\nthose cults were basically both fascist and communist. They were fascist in terms of social control,\nand then they were communist in terms of economics. - But you think that's fundamentally that like pull towards\ncults is within us. - Well, so my conclusion from this book,\nso the way we naturally think about the world we live in today is like, we basically have such an improved version of everything\nthat came before us, right? Like, we have basically, we've figured out all these things around morality and ethics and democracy and all these things.\nAnd like, they were basically stupid and retrograde and we're like smart and sophisticated. And we've improved all this after reading that book,\nI now believe in many ways the opposite, which is no, actually we are still running in that original model.\nWe're just running in an incredibly diluted version of it. So we're still running, basically in cults.\nIt's just our cults are at like a thousandth or a millionth, the level of intensity, right? And so our, so just as to take religions, you know,\nthe modern experience of a Christian in our time, even somebody who considers him a devout Christian,\nis just a shadow of the level of intensity of somebody who belonged to a religion back in that period. And then by the way, we have cons.\nIt goes back to our AI discussion. We then sort of endlessly create new cults.\nLike we're trying to fill the void, right? And the void is a void of bonding. - [Lex] Okay. - Living in their era. Like everybody living today,\ntransporting that era would view it as just like, completely intolerable in terms of like the loss of freedom and the level of basically of fascist control.\nHowever, every single person in that era, and he really stresses this. They knew exactly where they stood.\nThey knew exactly where they belonged. They knew exactly what their purpose was. They knew exactly what they needed to do every day. They knew exactly why they were doing it.\nThey had total certainty about their place in the universe. - So the question of meaning, the question of purpose was very distinctly,\nclearly defined for them. - Absolutely overwhelmingly undisputably undeniably.\n- As we turn the volume down on the cultism-- - [Marc] Yes. - We start to, the search for meaning starts getting harder and harder.\n- Yes. 'cause we don't have that. We are ungrounded. We are uncentered and we all feel it. Right? And that's why we reach for, you know,\nit's why we still reach for religion. It's why we reach for, you know, we people start to take on, you know, let's say, you know,\na faith in science maybe beyond where they should put it. You know and by the way, like, sports teams are like a, you know, they're like a tiny little version of a cult.\nAnd you know, apple keynotes are a tiny little version of a cult. Right. And, you know, political, you know.\nAnd there's cult, you know, there's full-blown cults on both sides of the political spectrum right now. Right. You know, operating in plain stuff.\n- But still not full blown compared as to what it was. - Compared to what it used to. I mean, we would today consider full blown, but like, yes,\nthey're at like, I don't know, a hundred thousandth or something of the intensity of what people had back then. So, we live in a world today that in many ways is more\nadvanced and moral and so forth. And it's certainly a lot nicer, much nicer world to live in. But we live in a world that's like very washed out.\nIt's like everything has become very colorless and gray as compared to how people used to experience things. Which is I think why we're so prone to reach for drama.\n'Cause there's something in us that's deeply evolved where we want that back. - And I wonder where it's all headed as we turn the volume\ndown more and more. What advice would you give to young folks today in high school and college?\n"}
{"pod": "Lex Fridman Podcast", "input": "Advice for young people", "output": "How to be successful in their career? How to be successful in their life? - Yeah. So the tools that are available today, I mean,\nare just like, I sometimes, you know, bore, I sometimes bore, you know, kids by describing like what it was like to go look up\na book, you know, to try to like discover a fact in, you know, in the old days, the 1970s, 1980s, to go to the library and the card catalog\nand the whole thing. You go through all that work and then the book is checked out and you have to wait two weeks and like to be in a world,\nnot only where you can get the answer to any question, but also the world now, you know, the AI world where you've got like the assistant\nthat will help you do anything, help you teach, learn anything, like your ability both to learn and also to produce is just like, I don't know,\na million fold beyond what it used to be. I have a blog post I've been wanting to write, which I call where are the hyper-productive people?\nLike-- - [Lex] That's a good question, right? - Like with these tools, like there should be authors that are writing like hundreds\nor thousands of like, outstanding books. - Well, with the authors there's a consumption question too, but yeah. Well, maybe not, maybe not.\nYou're right. But, so the tools are much more powerful. Getting much more powerful. - Artists, musicians. Right.\nWhy aren't musicians producing a thousand times the number of songs, right? Like what, like the tools are spectacular.\n- So, what's the explanation? And by way of advice, like,\nis motivation starting to be turned down a little bit? Or what? - I think it might be distraction.\n- [Lex] Distraction. - It's so easy to just sit and consume that I think people get distracted from production. But if you wanted to, you know,\nas a young person, if you wanted to really stand out, you could get on a, like a hyper productivity curve very early on.\nThere's a great, you know, this story, there's a great story in Roman history of plenty of the elder who was this legendary statesman,\ndied in the Vesuvius eruption trying to rescue his friends. But he was famous both for being basically being a polymath, but also being an author.\nAnd he wrote apparently like hundreds of books, most of us had been lost. But he like wrote all these encyclopedias and he literally\nlike would be reading and writing all day long no matter what else was going on. And so he would like travel with like four slaves.\nAnd two of them were responsible for reading to him, and two of them were responsible for taking dictation. And so like, he'd be going cross country and like,\nliterally he would be writing books like all the time. And apparently they were spectacular. There's only a few that have survived,\nbut apparently they were amazing. - There's a lot of value to being somebody who finds focus in this life. - Yeah. Like and there are examples, like there are,\nyou know, there's this guy, judge, what's his name? Posner, who wrote like 40 books and was also a great federal judge.\nYou know, there's our friend Balaji, I think is like this, he's one of these, you know, where his output is just prodigious.\nAnd so it's like, yeah, I mean, with these tools, why not? And I kind of think we're at this interesting kind of freeze frame moment where like this,\nthese tools are now in everybody's hands and everybody's just kind of staring at them trying to figure out what to do. The new tools. - We have discovered fire.\n- [Marc] Yeah. - And trying to figure out how to use it to cook. - [Marc] Yeah. Right. - You told Tim Ferriss that the perfect day is caffeine\n"}
{"pod": "Lex Fridman Podcast", "input": "Balance and happiness", "output": "for 10 hours and alcohol for four hours. You didn't think I'd be mentioning this, did you?\nIt balances everything out perfectly as you said. So, perfect. So let me ask,\nwhat's the secret to balance and maybe to happiness in life? - I don't believe in balance,\nso I'm the wrong person to ask that. - Can you elaborate why you don't believe in balance? - I mean, I maybe it's just, and I look, I think people,\nI think people are wired differently. So, I think it's hard to generalize this kind of thing, but I am much happier and more satisfied\nwhen I'm fully committed to something. So I'm very much in favor of all in of imbalance. - Imbalance. And that applies to work,\nto life, to everything. - Yeah. No, no. I happen to have whatever twist of personality traits lead\nthat in non-destructive dimensions in including the fact that I've actually, I now no longer do the ten-four plan. I stopped drinking.\nI do the caffeine, but not the alcohol. So there's something in my personality where I whatever mal-adaption I have is inclining me\ntowards productive things, not unproductive things. - So you're one of the wealthiest people in the world.\nWhat's the relationship between wealth and happiness? Money and happiness.\n- So I think happiness, I don't think happiness is the thing.\n- To strive for. - I think satisfaction is the thing. - That just sounds like happiness, but turned down a bit.\n- No deeper. So happiness is, you know, a walk in the woods at sunset, an ice cream cone, a kiss,\nthe first ice cream cone is great. The thousandth ice cream cone, not so much.\nAt some point the walks in the woods get boring. - What's the distinction between happiness and satisfaction?\n- I think satisfaction is a deeper thing, which is like having found a purpose and fulfilling it, being useful.\n- So just something that permeates all your days, just this general contentment of being useful.\n- That I'm fully satisfying my faculties, that I'm fully delivering, right? On the gifts that I've been given, that I'm, you know,\nnet making the world better, that I'm contributing to the people around me, right. And that I can look back and say, wow, that was hard,\nbut it was worth it. Think generally, it seems to lead people in a better state than pursuit of pleasure, pursuit of quote unquote happiness.\n- Does money have anything to do with that? - I think the founders and the founding fathers in the US threw this off kilter when they used the phrase pursuit\nof happiness. I think they should have said. - [Lex] Pursuit of satisfaction. - They said, pursuit of satisfaction. We might live in a better world today.\n- Well, they, you know, they could have elaborated on a lot of things right in the box. - [Marc] They could have tweaked the second amendment.\n- I think they were smarter than they realized. They said, you know we're gonna make it ambiguous and let these humans figure out the rest,\nthese tribal cult-like humans figure out the rest.\nBut money empowers that. - So I think, and I think there, I mean, look, I think Elon is, I don't think I'm even a great example,\nbut I think Elon would be the great example of this, which is like, you know, look, he's a guy who from every, every day of his life, from the day he started making money at all,\nhe just plows into the next thing. And so I think, I think money is definitely an enabler for satisfaction.\nWay money applied to happiness leads people down very dark paths. Very destructive avenues.\nMoney applied to satisfaction, I think could be, is a real tool. I always, by the way, I was like, you know,\nElon is the case study for behavior. But the other thing that I always really made me think is Larry Page was asked one time\nwhat his approach to philanthropy was. And he said, oh, I'm just, my philanthropic plan is just give all the money to Elon. (both laugh)\n- Well, let me actually ask you about Elon. You've interacted with quite\na lot of successful engineers and business people. What do you think is special about Elon?\nWe talked about Steve Jobs. What do you think is special about him as a leader?\nAs an innovator? - Yeah. So the core of it is he's back to the future. So he is doing the most leading-edge things in the world,\nbut with a really deeply old-school approach. And so to find comparisons to Elon, you need to go to like Henry Ford and Thomas Watson\nand Howard Hughes and Andrew Carnegie, right. Leland Stanford, John Rockefeller, right.\nYou need to go to what were called the bourgeois capitalists, like the hardcore business owner operators\nwho basically built, you know, basically built industrialized society, Vanderbilt.\nAnd it's a level of hands-on commitment and depth in the business,\ncoupled with an absolute priority towards truth and towards,\nhow to put it, science and technology town to first principles that is just like absolute,\nis just like unbelievably absolute. He really is ideal that he's only ever talking to engineers. Like he does not tolerate.\nHe has less tolerance than anybody I've ever met. He wants ground truth on every single topic.\nAnd he runs his businesses directly day-to-day, devoted to getting to ground truth in every single topic.\n- So you think it was a good decision for him to buy Twitter?\n- I have developed a view in life to not second guess Elon Musk, I know this is gonna sound great, crazy and unfounded, but.\n- Well, I mean, he's got a quite a track record. - I mean, look, the car was a crazy, I mean, the car was,\nI mean, look. - He's done a lot of things that seem crazy. - Starting a new car company in the United States of America. The last time somebody really tried to do that was\nthe 1950s and it was called Tucker Automotive. And it was such a disaster. They made a movie about what a disaster it was,\nand then rockets like, who does that? Like, there's obviously no way to start a new rocket company.\nLike those days are over. And then to do those at the same time. So after he pulled those two off, like, okay, fine.\nLike, this is one of my areas of like, whatever opinions I had about that, that is just like, okay, clearly are not relevant.\nLike this is you just, you at some point you just like bet on the person. - And in general, I wish more people would lean on celebrating and supporting\nversus deriding and destroying. - Oh yeah. I mean, look, he drives resentment. Like it's a resentment.\nLike he is a magnet for resentment. Like his critics are the most miserable, like,\nresentful people in the world. Like it's almost a perfect match of like the most idealized, you know, technologist, you know,\nof the century coupled with like, just his critics are just bitter as can be. And I mean, it's sort of very darkly comic to watch.\n- Well, he fuels the fire of that by being on Twitter at times.\nAnd which is fascinating to watch the drama of human civilization, given our cult roots just fully on fire.\n- [Marc] He's running a cult. - You could say that. - [Marc] Very successfully. - So now that our cults have gone and we searched\n"}
{"pod": "Lex Fridman Podcast", "input": "Meaning of life", "output": "for meaning, what do you think is the meaning of this whole thing? What's the meaning of life Marc Andreessen? - I don't know the answer to that. I think the meaning\nof the closest I get to it is what I said about satisfaction.\nSo it's basically like, okay, we were given what we have, like we should basically do our best. - What's the role of love in that mix?\n- I mean, like, what's the point of life if you're without love, like, yeah. - So love is a big part of that satisfaction.\n- Yeah. And look like taking care of people is like a wonderful thing. Like it, you know, mentality, you know, there are pathological forms of taking care of people,\nbut there's also a very fundamental, you know, kind of aspect of taking care of people. Like, for example, I happen to be somebody who believes that capitalism\nand taking care of people are actually, they're actually the same thing. Somebody once said, capitalism is how you take care of people you don't know.\nRight, right. And so like, yeah, I think it's like deeply woven into the whole thing, you know, there's a long conversation\nto be had about that, but yeah. - Yeah. Creating products that are used by millions of people and bring them joy\nin smaller, big ways. And then capitalism kind of enables that, encourages that.\n- David Friedman says, there's only three ways to get somebody to do something for somebody else. Love, money and force.\nAnd love and money are better.\n- [Lex] Yeah. Of course. That's a good ordering. I think. - We should bet on those. - Try love first. If that doesn't work, then money.\n- [Marc] Yes. - And then force. Well, don't even try that one. Marc, you're an incredible person. I've been a huge fan.\nI'm glad to finally got a chance to talk. I'm a fan of everything you do, everything you do, including on Twitter.\nIt's a huge honor to meet you, to talk with you. Thanks again for doing this. - Awesome. Thank you, Lex.\n- Thanks for listening to this conversation with Marc Andreessen. To support this podcast, please check out our sponsors in the description.\nAnd now let me leave you with some words from Marc Andreessen himself. \"The world is a very malleable place.\nIf you know what you want and you go for it, with maximum energy and drive and passion,\nthe world will often reconfigure itself around you much more quickly and easily than you would think.\"\nThank you for listening and hope to see you next time.\n"}

{"pod": "Lex Fridman Podcast", "input": "Introduction", "output": "- I think it's possible that physics has exploits and we should be trying to find them. Arranging some kind of a crazy quantum mechanical system\nthat somehow gives you buffer overflow, somehow gives you a rounding error in the floating point. Synthetic intelligence is kind of like\nthe next stage of development. And I dunno where it leads to, at some point\nI suspect the universe is some kind of a puzzle. These synthetic AIs will uncover that puzzle and solve it.\n- The following is a conversation with Andrej Karpathy, previously the director of AI at Tesla.\nAnd before that, at OpenAi and Stanford. He is one of the greatest scientists, engineers,\nand educators in the history of artificial intelligence. This is the Lex Fridman Podcast.\nTo support it, please check out our sponsors. And now, dear friends, here's Andrej Karpathy.\n"}
{"pod": "Lex Fridman Podcast", "input": "Neural networks", "output": "What is a neural network and why does it seem to do such a surprisingly good job of learning?\n- What is a neural network? It's a mathematical abstraction of the brain.\nI would say that's how it was originally developed. At the end of the day, it's a mathematical expression and it's a fairly simple mathematical expression\nwhen you get down to it. It's basically a sequence of meter multipliers,\nwhichever really dot products mathematically and some nonlinearity is thrown in. And so it's a very simple mathematical expression\nand it's got knobs in it. - Many knobs. - Many knobs. And these knobs are loosely related to basically\nthe synapses in your brain. They're trainable. They're modifiable. And so the idea is we need to find the setting of the knobs that makes the neural net\ndo whatever you want it to do, like classify images and so on. And so there's not too much mystery I would say in it.\nYou might think that, basically, you don't want to endow it with too much meaning with respect to the brain and how it works.\nIt's really just a complicated mathematical expression with knobs. And those knobs need a proper setting for it to do something desirable.\n- Yeah. But poetry is just the collection of letters with spaces, but it can make us feel a certain way.\nAnd in that same way, when you get a large number of knobs together, whether it's inside the brain or inside a computer,\nthey seem to surprise us with their power. - Yeah. I think that's fair.\nSo basically, I think I'm underselling it by a lot because you definitely do get very surprising emergent behaviors out of these neural nets\nwhen they're large enough and trained on complicated enough problems. Like say, for example, the next-word prediction\nin a massive dataset from the internet. And then these neural nets take on pretty surprising magical properties.\nYeah, I think it's kind of interesting how much you can get out of even very simple mathematical formalism. - When your brain right now is talking,\nis it doing next-word prediction or is it doing something more interesting? - Well, it's definitely some kind of a generative model\nthat's GPT like and prompted by you. - [Lex] Yes. - So you're giving me a prompt\nand I'm kind of like responding to it in a generative way. - And by yourself perhaps a little bit, like are you adding extra prompts from your own memory\ninside your head or no? - Well, it definitely feels like you're referencing some kind of a declarative structure\nof memory and so on. And then you're putting that together with your prompt\nand giving away some answers. - How much of what you just said has been said by you before.\n- Nothing, basically right? - No, but if you actually look at all the words you've ever said in your life and you do a search,\nyou'll probably have said a lot of the same words in the same order before. - Yeah.\nCould be. I mean, I'm using phrases that are common, et cetera, but I'm remixing it into a pretty unique sentence\nat the end of the day. But you're right, definitely, there's like a ton of remixing.\n- It's like Magnus Carlson said I'm rated 2,900, whatever, which is pretty decent.\nI think you're talking very, you're not giving enough credit to neural nets here.\nWhat's your best intuition about this emergent behavior? - I mean, it's kind of interesting\nbecause I'm simultaneously underselling them, but I also feel like there's an element to which I'm over-\nit's actually kind of incredible that you can get so much emergent magical behavior out of them despite them being so simple mathematically.\nSo I think those are two surprising statements that are juxtaposed together.\nAnd I think, basically, what it is, is we are actually fairly good at optimizing these neural nets. And when you give them a hard enough problem,\nthey are forced to learn very interesting solutions in the optimization. And those solutions basically have these emergent properties\nthat are very interesting. - There's wisdom and knowledge in the knobs.\n- [Andrej] Yes. - And so this representation that's in the knobs does it make sense to you intuitively, that a large number of knobs can hold a representation\nthat captures some deep wisdom about the data it has looked at. It's a lot of knobs.\n- It's a lot of knobs. And somehow, so speaking concretely, one of the neural nets\nthat people are very excited about right now are GPTs, which are basically just next-word prediction networks.\nSo you consume a sequence of words from the internet and you try to predict the next word.\nAnd once you train these on a large enough data set,\nyou can basically prompt these neural nets in arbitrary ways and you can ask them to solve problems. And they will.\nSo you can just tell them, you can make it look like you're trying to solve some kind of a mathematical problem.\nAnd they will continue what they think is the solution based on what they've seen on the internet. And very often those solutions\nlook very remarkably consistent. Look correct, potentially even. - Do you still think about the brain side of it?\nSo as neural nets as an abstraction, a mathematical abstraction of the brain, do you still draw wisdom\nfrom the biological neural networks or even the bigger question.\nSo you're a big fan of biology and biological computation. What impressive thing is biology doing to you\n"}
{"pod": "Lex Fridman Podcast", "input": "Biology", "output": "that computers are not yet, that gap? - I would say I'm definitely on,\nI'm much more hesitant with the analogies to the brain than I think you would see potentially in the field.\nAnd I feel like certainly, the way neural networks started is everything stemmed from inspiration by the brain.\nBut at the end of the day, the artifacts that you get after training, they are arrived at by a very different optimization process\nthan the optimization process that gave rise to the brain. And so I think of it as a very complicated alien artifact.\nIt's something different. - [Lex] The brain? - Oh no, sorry. The neural nest that we're training. - [Lex] Okay. - They are a complicated alien artifact.\nI do not make analogies to the brain because I think the optimization process that gave rise to it is very different from the brain.\nSo there was no multi-agent, self-play setup and evolution.\nIt was an optimization that is basically what amounts to a compression objective on a mass amount of data.\n- Okay. So artificial neural networks are doing compression and biological neural networks-\n- [Andrej] Are trying to survive. - Are not really doing anything, they're an agent in a multi-agent, self-play system\nthat's been running for a very, very long time. - Yes. That said, evolution has found that it is very useful\nto predict and have a predictive model in the brain. And so, I think our brain utilizes something\nthat looks like that as a part of it, but it has a lot more catches and gizmos and value functions and ancient nuclei\nthat are all trying to like make it survive and reproduce and everything else. - And the whole thing through embryogenesis is built\nfrom a single-cell. I mean, it's just the code is inside the DNA and it just builds it up like the entire organism\nwith arms- - [Andrej] It's definitely crazy. - And the head and legs. - [Andrej] Yes. - And it does it pretty well.\n- [Andrej] It should not be possible. - So there's some learning going on. There's some kind of computation\ngoing through that building process. I mean, I don't know where, if you were just to look\nat the entirety of history of life on earth, where do you think is the most interesting invention?\nIs it the origin of life itself? Is it just jumping to Eukaryotes?\nIs it mammals? Is it humans themselves, Homo sapiens? The origin of intelligence or highly complex intelligence?\nOr is it all just a continuation of the same kind of process? - Certainly, I would say it's an extremely remarkable story\nthat I'm only briefly learning about recently all the way from, actually, you almost have to start\nat the formation of earth and all of its conditions and the entire solar system and how everything is arranged with Jupiter and moon and the habitable zone and everything.\nAnd then you have an active earth that's turning over material and then you start with a biogenesis and everything.\nAnd so it's all a pretty remarkable story. I'm not sure that I can pick a single unique piece of it\nthat I find most interesting. I guess for me, as an artificial intelligence researcher,\nit's probably the last piece. We have lots of animals that are not building technological society but we do.\nAnd it seems to have happened very quickly. It seems to have happened very recently. And something very interesting happened there\nthat I don't fully understand. I almost understand everything else I think intuitively, but I don't understand exactly that part\nand how quick it was. - Both explanations would be interesting. One is that this is just a continuation\nof the same kind of process. There's nothing special about humans. Deeply understanding that would be very interesting\nthat we think of ourselves as special. But it was obvious, it was already written in the code\nthat you would have greater and greater intelligence emerging. And then the other explanation,\nwhich is something truly special happened, something like a rare event, whether it's like crazy rare event like a \"Space Odyssey\",\nwhat would it be? See if you say like the invention of fire or as Richard Rankin says, the beta males deciding\na clever way to kill the alpha males by collaborating. So just optimizing the collaboration, the multi-agent,\naspect of the multi-agent and that really being constrained on resources and trying to survive the collaboration aspect\nis what created the complex intelligence. But it seems like it's a natural algorithm to the evolution process.\n- [Andrej] Yeah. - What could possibly be a magical thing that happened, like a rare thing that would say that humans are actually,\nhuman-level intelligence is actually a really rare thing in the universe?\n- Yeah, I'm hesitant to say that it is rare by the way, but it definitely seems like it's like a punctuated equilibrium where you have\nlots of exploration and then you have certain leaps, sparse leaps in between. So of course, like origin of life would be one,\nDNA, sex, Eukaryotic life, the endosymbiosis event\nwhere the archon ate little bacteria, just the whole thing. And then of course, emergence of consciousness and so on.\nSo it seems like definitely there are sparse events where massive amount of progress was made. But yeah, it's kind of hard to pick one.\n- So you don't think humans are unique? To that I ask you how many intelligent alien civilizations\n"}
{"pod": "Lex Fridman Podcast", "input": "Aliens", "output": "do you think are out there and is their intelligence different or similar to ours?\n- Yeah, I've been preoccupied with this question quite a bit recently. Basically, the Fermi paradox and just thinking through.\nAnd the reason actually that I am very interested in the origin of life is fundamentally trying to understand\nhow common it is that there are technological societies out there in space.\nAnd the more I study it, the more I think that\nthere should be quite a few, quite a lot. - Why haven't we heard from them? 'Cause I agree with you. It feels like, I just don't see why\nwhat we did here on earth is so difficult to do. - Yeah. And especially when you get into the details of it. I used to think origin of life was very,\nit was this magical rare event. But then you read books like for example Nick Lane,\n\"The Vital Question\", \"Life Ascending\", et cetera. And he really gets in and he really makes you believe\nthat this is not that rare. - Basic chemistry. - You have an active earth and you have your alkaline vents and you have lots of alkaline waters mixing\nwhere there is a devotion and you have your proton gradients and you have these little porous pockets of these alkaline vents that concentrate chemistry.\nAnd basically, as he steps through all of these little pieces, you start to understand that actually this is not that crazy.\nYou could see this happen on other systems and he really takes you from just a geology\nto primitive life. And he makes it feel like this is actually pretty plausible. And also like the origin of life was actually fairly fast\nafter formation of earth, if I remember correctly, just a few hundred million years or something like that after basically when it was possible, life actually arose.\nAnd so that makes me feel like that is not the constraint, that is not the limiting variable and that life should actually be fairly common.\nAnd then where the drop-offs are is very interesting to think about.\nI currently think that there's no major drop-offs basically. - [Lex] Yeah. - And so there should be quite a lot of life. And basically, where that brings me to then\nis the only way to reconcile the fact that we haven't found anyone and so on is that we can't see them, we can't observe them.\n- Just a quick brief comment, Nick Lane and a lot of biologists I talk to, they really seem to think that the jump from bacteria\nto more complex organisms is the hardest jump. - [Andrej] The Eukaryotic life, basically. - Yeah.\nI get it. They're much more knowledgeable than me about the intricacies of biology.\nBut that seems crazy 'cause how many single-cell organisms are there?\nAnd how much time you have surely it's not that difficult. And a billion years is not even that long\nof a time really, just all these bacteria under constrained resources battling it out.\nI'm sure they can invent more complex. I don't understand. It's like how to move from a \"Hello, World!\" program\nto invent a function or something like that. I don't- - Yeah.\n- Yeah, so I'm with you. I just feel like I don't see any, if the origin of life, that would be my intuition, that's the hardest thing.\nBut if that's not the hardest thing 'cause it happened so quickly, then it's gotta be everywhere and yeah, maybe we're just too dumb to see it.\n- Well, it's just we don't have really good mechanisms for seeing this life.\nSo I'm not an expert just to preface this but just from what- - On aliens? I wanna meet an expert on alien intelligence\nand how to communicate. - I'm very suspicious of our ability to find these intelligences out there and to find these earths like radio waves,\nfor example, are terrible. Their power drops off as basically 1 over R-squared. So I remember reading that our current radio waves\nwould not be, the ones that we are broadcasting, would not be measurable by our devices today only like,\nwas it like one 10th of a light year away? Not even, basically, tiny distance because you really need like a targeted transmission\nof massive power directed somewhere for this to be picked up on long distances.\nAnd so I just think that our ability to measure is not amazing. I think there's probably other civilizations out there.\nAnd then the big question is why don't they build one man probes and why don't they interstellar travel across the entire galaxy?\nAnd my current answer is, it's probably interstellar travel is really hard. You have the interstellar medium if you wanna move\nat close to speed of light, you're going to be encountering bullets along the way because even like tiny hydrogen atoms\nand little particles of dust have massive kinetic energy at those speeds.\nAnd so, basically, you need some kind of shielding, you have all the cosmic radiation, it's just brutal out there.\nIt's really hard. And so my thinking is maybe interstellar travel is just extremely hard. You have to learn slow.\n- Like billions of years to build hard? It feels like we're not a billion years away\nfrom doing that. - It just might be that it's very, you have to go very slowly potentially, as an example, through space.\n- Right. As opposed to close to the speed of light. - Yeah. So I'm suspicious basically of our ability to measure life and I'm suspicious of the ability to just permeate\nall of space in the galaxy or across galaxies. And that's the only way that I can currently see away around it.\n- Yeah, it's kind of mind-blowing to think that there's trillions of intelligent alien civilizations out there\nslowly traveling through space. - [Andrej] Maybe. - To meet each other. And some of them meet, some of them go to war,\nsome of them collaborate. - Or they're all just independent. They're all just like little pockets.\nI don't know. - Well, statistically if there's trillions of them,\nsurely some of them, some of the pockets are close enough together. - Some of them happen to be close. Yeah. - And close enough to see each other.\nSee, once you see something that is definitely complex life, if we see something.\n- [Andrej] Yeah. - We're probably going to be intensely aggressively motivated to figure out what the hell that is and try to meet them.\nBut what would be your first instinct, to try to, at a generational-level, meet them or defend against them?\nOr what would be your instinct as a president of the United States and a scientist?\nI don't know which hat you prefer in this question. - Yeah, I think the question, it's really hard.\nI will say like for example, for us, we have lots of primitive life forms on earth next to us.\nWe have all kinds of ants and everything else and we share a space with them and we are hesitant to impact on them and we're trying to protect them\nby default, because they are amazing, interesting dynamical systems that took a long time to evolve. And they are interesting and special\nand I don't know that you wanna destroy that by default.\nAnd so I like complex dynamical systems that took a lot of time to evolve.\nI think I'd like to preserve it if I can afford to.\nAnd I'd like to think that the same would be true about the galactic resources and that they would think\nthat we're kind of incredible interesting story that took time, it took a few billing years to unravel\nand you don't want to just destroy it. - I could see two aliens talking about earth right now and saying I'm a big fan of complex dynamical systems.\nSo I think it was a value to preserve these and who basically are a video game they watch\nor show, a TV show that they watch. - Yeah. I think you would need like a very good reason I think to destroy it.\nWhy don't we destroy these end farms and so on? It's because we're not actually really in direct competition with them right now.\nWe do it accidentally and so on, but there's plenty of resources. And so why would you destroy something\nthat is so interesting and precious? - Well, from a scientific perspective you might probe it. - [Andrej] Yeah.\n- You might interact with it lightly. - Exactly. You might wanna learn something from it. Right. - So I wonder, there could be certain physical phenomena\nthat we think is a physical phenomena, but it's actually interacting with us to poke the finger and see what happens.\n- Yeah. I think it should be very interesting to scientists, other alien scientists, what happened here\nand what we're seeing today is a snapshot, basically, it's a result of a huge amount of computation\nof over billion years or something like that. - It could have been initiated by aliens.\nThis could be a computer running a program. Okay. If you had the power to do this wouldn't you-\nOkay, for sure. At least I would, I would pick an earth-like planet\nthat has the conditions, base my understanding of the chemistry prerequisites for life. And I would seed it with life and run it, right?\n- [Andrej] Yeah. - Wouldn't you 100% do that and observe it and then protect? - [Andrej] Yeah. - I mean that's not just a hell of a good TV show.\nIt's a good scientific experiment. - [Andrej] Yeah. - And it's physical simulation.\nRight. Maybe, evolution is the most, actually running it,\nis the most efficient way to understand computation or to compute stuff.\n- Or to understand life or what life looks like and what branches it can take. - It does make me kind of feel weird\nthat we're part of a science experiment, but maybe everything's a science experiment,\ndoes that change anything for us, if we're a science experiment? - [Andrej] I don't know.\n- Two descendants of apes talking about being inside of a science experiment. - I'm suspicious of this idea of a deliberate panspermia\nas you described it, sort of. - Yes. - I don't see a divine intervention in some way in the historical record right now.\nI do feel like the story in these books, like Nick Lane's books and so on, sort of makes sense and it makes sense how life arose\non earth uniquely. And yeah, I don't need to reach for more exotic explanations right now.\n- Sure. But NPCs inside a video game, don't observe any divine intervention either.\nWe might just be all NPCs running a kind of code. - Maybe eventually they will, currently, NPCs are really dumb.\nBut once they're running GPTs, maybe they will be like, \"Hey, this is really suspicious. What the hell?\"\n"}
{"pod": "Lex Fridman Podcast", "input": "Universe", "output": "- So you famously Tweeted, \"It looks like if you bombard earth with photons\nfor a while, you can emit a Roadster.\" So if like in \"Hitchhiker's Guide to the Galaxy\",\nwe would summarize the story of earth. So in that book it's mostly harmless.\nWhat do you think is all the possible stories, a paragraph long or sentence long\nthat earth could be summarized as, once it's done it's computation?\nSo all the possible full, if earth is a book, right? - Yeah.\n- Probably there has to be an ending. I mean there's going to be an end to earth and it could end in all kinds of ways. It can end soon.\nIt can end later. - [Andrej] Yeah. - What do you think are the possible stories? - Well definitely, there seems to be, yeah, you're sort of,\nit's pretty incredible that these self-replicating systems will basically arise from the dynamics\nand then they perpetuate themselves and become more complex and eventually, become conscious and build a society.\nAnd I feel like in some sense it's a deterministic wave\nthat just happens on any sufficiently well-arranged system like earth.\nAnd so I feel like there's a certain sense of inevitability in it and it's really beautiful.\n- And it ends somehow, right? So it's a chemically diverse environment\nwhere complex dynamical systems can evolve and become more, further, and further complex.\nBut then there's a certain, what is it? There's certain terminating conditions.\n- Yeah. I dunno what the terminating conditions are, but definitely, there's a trend line of something and we're part of that story. And where does that, where does it go?\nSo, we're famously described often as a biological boot loader for AIs and that's because humans,\nI mean, we're an incredible biological system and we're capable of computation and love and so on,\nbut we're extremely inefficient as well. We're talking to each other through audio. It's just embarrassing honestly\nthat we're manipulating like seven symbols, serially, we're using vocal chords.\nIt's all happening over multiple seconds. - [Lex] Yeah. - It's just embarrassing when you step down to the frequencies at which computers operate\nor are able to cooperate on. And so basically, it does seem like synthetic intelligences\nare the next stage of development. And I dunno where it leads to, at some point I suspect\nthe universe is some kind of a puzzle and these synthetic AIs will uncover that puzzle\nand solve it. - And then what happens after, right?\n'Cause if you just like fast forward earth, many billions of years, it's quiet and then it's turmoil,\nyou see city lights and stuff like that. And then what happens at the end? Is it a, or is it a calming, is it explosion?\nIs it like earth open like a giant. 'Cause you said emit Roadsters. Will it start emitting a giant number of satellites?\n- Yeah. Some kind of a crazy explosion. And we're living, we're stepping through a explosion\nand we're living day-to-day and it doesn't look like it. But it's actually, I saw a very cool animation of earth\nand life on earth and, basically, nothing happens for a long time. And then the last like two seconds, basically cities and everything and just,\nand the lower orbit just gets cluttered and just the whole thing happens in the last two seconds and you're like, \"This is exploding. This is a state of explosion.\"\n- Yeah, yeah. If you play it a normal speed. - [Andrej] Yeah. - It'll just look like an explosion. - It's a firecracker.\nWe're living in a firecracker. - Where it's going to start emitting all kinds of interesting things. - [Andrej] Yeah.\n- And then, so explosion doesn't- it might actually look like a little explosion with lights and fire and energy emitted,\nall that kind of stuff. But when you look inside the details of the explosion, there's actual complexity happening where there's like,\nyeah, human life or some kind of life. - We hope it's not a destructive firecracker. It's kind of like a constructive firecracker.\n- [Lex] All right. So given that. - I think- - [Lex] Hilarious discussion. - It is really interesting to think about what the puzzle of the universe is.\nDid the creator of the universe give us a message? For example in the book \"Contact\", Carl Sagan,\nthere's a message for any civilization in the digits\nin the expansion of Pi and base 11, eventually, which is kind of an interesting thought. Maybe we're supposed to be giving a message to our creator,\nmaybe we're supposed to somehow create some kind of a quantum mechanical system that alerts them to our intelligent presence here.\n'Cause if you think about it from their perspective, it's just say like quantum field theory, massive cellular automaton-like thing.\nAnd how do you even notice that we exist? You might not even be able to pick us up in that simulation.\nAnd so how do you prove that you exist, that you're intelligent, and that you're part of the universe?\n- So this is like a touring test for intelligence from earth. - [Andrej] Yeah. - I mean maybe this is like trying to complete\nthe next word in a sentence. This is a complicated way of that. earth is basically sending a message back.\n- Yeah. The puzzle is basically alerting the creator that we exist. - [Lex] Yeah. - Or maybe the puzzle is just to just break out\nof the system and just stick it to the creator in some way. Basically, like if you're playing a video game,\nyou can somehow find an exploit and find a way to execute on the host machine in arbitrary code.\nFor example, I believe someone got a game of Mario to play pong just by exploiting it\nand then basically writing code and being able to execute\narbitrary code in the game. And so maybe we should be, maybe that's the puzzle is that we should find a way to exploit it.\nSo, I think like some of these synthetic AIs will eventually find the universe to be some kind of a puzzle and then solve it in some way.\nAnd that's kind of like the end game somehow. - Do you often think about it as a simulation?\nSo as are the universe being a kind of computation that might have bugs and exploits?\n- Yes. Yeah, I think so. - [Lex] Is that what physics is, essentially? - I think it's possible that physics has exploits\nand we should be trying to find them. Arranging some kind of a crazy quantum mechanical system that somehow gives you buffer overflow\nsomehow gives you a rounding error and the floating point. - Yeah, that's right.\nAnd more and more sophisticated exploits, those are jokes, but that could be actually very close to reality.\n- Yeah. We'll find some way to extract infinite energy. For example, when you train reinforcement learning agents\nin physical simulations and you ask them to say, run quickly on the flat ground, they'll end up doing\nall kinds of weird things in part of that optimization, right? They'll get on their back leg and they'll slide across the floor.\nAnd it's because the optimization, the enforcement learning optimization on that agent has figured out a way to extract infinite energy\nfrom the friction forces and, basically, their poor implementation. And they found a way to generate infinite energy\nand just slide across the surface. And it's not what you expected, it's sort of like a perverse solution.\nAnd so maybe we can find something like that. Maybe we can be that little dog in this physical simulation.\n- That cracks or escapes the intended consequences of the physics that the universe came up with.\n- [Andrej] Yeah. - We'll figure out some kind of shortcut to some weirdness. - [Andrej] Yeah. - And then, oh man, but see the problem with that weirdness\nis the first person to discover the weirdness, like sliding on the back legs, that's all we're gonna do.\n- [Andrej] Yeah. - It's very quickly become everybody does that thing. So the paperclip maximizer is a ridiculous idea,\nbut that very well could be what then we'll just all switch to that 'cause it's so fun.\n- Well, no person will discover it, I think by the way, I think it's going to have to be some kind of a super-intelligent AGI of a third generation.\nWe're building the first-generation AGI, maybe. - Third generation.\nYeah. So the boot loader for an AI, that AI will be a boot loader for another AI.\n- [Andrej] Better Ai. Yeah. - And then there's no way for us to introspect what that might even.\n- I think it's very likely that these things, for example, say you have these AGIs, it's very likely for example, they will be completely inert.\nI like these kinds of sci-fi books sometimes where these things are just completely inert, they don't interact with anything.\nAnd I find that kind of beautiful because they've probably figured out the meta-game\nof the universe in some way, potentially. They're doing something completely beyond our imagination\nand they don't interact with simple chemical life forms. Why would you do that?\nSo I find those kinds of ideas compelling. - What's their source of fun? What are they doing?\nWhat's the source of pleasure? - Well, probably puzzle-solving in the universe? - But inert, so can you define what it means inert?\nSo they escape the interaction with physical reality? - They will appear inert to us, as in\nthey will behave in some very strange way to us because they're beyond, they're playing the meta-game.\nAnd the meta-game is probably say, like arranging quantum mechanical systems in some very weird ways to extract infinite energy,\nsolve the digital expansion of Pi to whatever amount, they will build their own little fusion reactors\nor something crazy. They're doing something beyond comprehension and not understandable to us and actually brilliant under the hood.\n- What if quantum mechanics itself is the system and we're just thinking it's physics\nbut we're really parasites on or not parasite. We're not really hurting physics,\nwe're just living on this organism and we're like trying to understand it.\nBut really it is an organism and with a deep, deep intelligence maybe physics itself is the organism\nthat's doing the super interesting thing and we're just like one little thing. - [Andrej] Yeah. - Ant sitting on top of it trying to get energy from it.\n- Yeah. We're just like these particles in the wave that I feel like is mostly deterministic and takes universe from some kind of a big bang\nto some kind of a super-intelligent replicator, some kind of a stable point in the universe\ngiven these laws of physics. - You don't think, as Einstein said, God doesn't play dice?\nSo you think it's mostly deterministic? There's no randomness in the thing? - I think it's deterministic. Oh, there's tons of, well, I'm gonna be careful\nwith randomness. - [Lex] Pseudo-random? - Yeah, I don't like random. I think maybe the laws of physics are deterministic.\nYeah, I think they're deterministic. - You just got really uncomfortable with the question. Do you have anxiety about whether the universe\nis random or not? Is it a source? - [Andrej] There's no randomness, no.\n- You said you like \"Good Will Hunting\". It's not your fault Andrej. It's not your fault, man.\nSo you don't like the randomness? - Yeah, I think it's unsettling. I think it's a deterministic system.\nI think that things that look random, like say the collapse of the wave function, et cetera, I think they're actually deterministic,\njust entanglement and so on and some kind of a multiverse theory something, something. - Okay.\nSo why does it feel like we have a free will? Like if I raise this hand, I chose to do this now.\nThat doesn't feel like a deterministic thing. It feels like I'm making a choice. - [Andrej] It feels like it.\n- Okay. So it's all feelings. It's just feelings. - [Andrej] Yeah. So when our RL agent is making a choice is that,\nit's not really making a choice, the choice was already there. - Yeah. You're interpreting the choice and you're creating a narrative\nfor having made it. - Yeah. And now we're talking about the narrative, it's very meta. Looking back, what is the most beautiful\n"}
{"pod": "Lex Fridman Podcast", "input": "Transformers", "output": "or surprising idea in deep learning or AI in general that you've come across?\nYou've seen this field explode and grow in interesting ways. Just what cool ideas, like what made you sit back and go\nhmm, big or small? - Well, the one that I've been thinking about recently\nthe most probably is the transformer architecture.\nSo basically, neural networks have a lot of architectures that were trendy have come and gone\nfor different sensory modalities. Like for vision, audio, text, you would process them with different-looking neural nets.\nAnd recently, we've seen this convergence towards one architecture, the transformer and you can feed it video, or you can feed it images,\nor speech or text and it just gobbles it up. And it's a bit of a general-purpose computer\nthat is also trainable and very efficient to run in our hardware. And so this paper came out in 2016, I wanna say.\n- [Lex] \"Attention is all you need\". - \"Attention is all you need\". - You criticized the paper title in retrospect that it wasn't, it didn't foresee the bigness\nof the impact that it was going to have. - Yeah. I'm not sure if the authors were aware of the impact that that paper would go on to have.\nProbably they weren't but I think they were aware of some of the motivations and design decisions behind the transformer and they chose not to, I think,\nexpand on it in that way in the paper. And so I think they had an idea that there was more\nthan just the surface of just like, oh, we're just doing translation and here's a better architecture. You're not just doing translation. This is like a really cool differentiable, optimizable,\nefficient computer that you've proposed. And maybe they didn't have all of that foresight but I think it's really interesting.\n- Isn't it funny, sorry to interrupt, that that title is memeable, that they went\nfor such a profound idea. I don't think anyone used that kind of title before, right?\n- \"Attention is all you need\"? Yeah. It's like a meme or something, basically. - Yeah. Isn't it funny that when, maybe if it was\na more serious title it wouldn't have the impact. - Honestly, yeah, there is an element of me that honestly agrees with you and prefers it this way.\n- [Lex] Yes. - If it was too grand it would over-promise and then under-deliver potentially.\nSo you want to just meme your way to greatness? - That should be a T-shirt.\nSo you Tweeted, \"The Transformer is a magnificent neural network architecture because it is a general-purpose\ndifferentiable computer. It is simultaneously expressive in the forward pass, optimizable via back-propagation gradient dissent,\nand efficient high parallelism compute graph.\" Can you discuss some of those details,\nExpressive, optimizable, efficient? - [Andrej] Yeah. - From memory or in general, whatever comes to your heart.\n- You want to have a general-purpose computer that you can train on arbitrary problems like say the task of next-work prediction\nor detecting if there's a cat in a image or something like that. And you want to train this computer so you want to set its weights.\nAnd I think there's number of design criteria that overlap in the transformer simultaneously\nthat made it very successful. And I think the authors were deliberately trying to\nmake this really powerful architecture. And so basically, it's very powerful in the forward pass\nbecause it's able to express very general computation as something that looks like message passing.\nYou have nodes and they all store vectors and these nodes get to basically look at each other,\neach other's vectors and they get to communicate and basically, nodes get to broadcast,\n\"Hey, I'm looking for certain things.\" And then other nodes get to broadcast, \"Hey, these are the things I have.\" Those are the keys and the values.\n- So it's not just attention. - Yeah, exactly. Transformer is much more than just the attention component. It's got many pieces, architectural that went into it,\nthe residual connection, the way it's arranged, there's a multilayer perceptron and they are the way it's stacked and so on.\nBut basically, there's a message-passing scheme where nodes get to look at each other, decide what's interesting, and then update each other.\nAnd so I think when you get to the details of it, I think it's a very expressive function\nso it can express lots of different types of algorithms in a forward pass. Not only that but the way it's designed with the residual connections, layer normalizations,\nthe Softmax, attention, and everything, it's also optimizable. This is a really big deal because there's lots of computers\nthat are powerful that you can't optimize or that are not easy to optimize using the techniques that we have, which is back-propagation and gradient descent,\nthese are first-order methods, very simple optimizers really. And so you also need it to be optimizable.\nAnd then lastly, you want it to run efficiently in our hardware. Our hardware is a massive throughput machine like GPUs,\nthey prefer lots of parallelism. So you don't want to do lots of sequential operations, you want to do a lot of operations serially\nand the transformer is designed with that in mind as well. And so it's designed for our hardware and is designed to both be very expressive\nin a forward pass, but also very optimizable in the backward pass. - And you said that the residual connection support,\nan ability to learn short algorithms fast and first and then gradually extend them longer during training.\n- [Andrej] Yeah. - What's the idea of learning short algorithms? - Right. Think of it as a, so basically a transformer\nis a series of blocks, right? And these blocks have attention and a little multilayer perceptron,\nand so you go off into a block and you come back to this residual pathway and then you go off and you come back and then you have\na number of layers arranged sequentially. And so the way to look at it I think is because of the residual pathway in the backward pass,\nthe gradients sort of flow along it uninterrupted because addition distributes the gradient equally\nto all of its branches. So the gradient from the supervision at the top just floats directly to the first layer.\nAnd all these residual connections are arranged so that in the beginning, during initialization, they contribute nothing to the residual pathway.\nSo what it looks like is, imagine the transformer is like a Python function, like a def,\nand you get to do various lines of code. Say you have a hundred layers-deep transformer,\ntypically they would be much shorter, say 20. So you have 20 lines of code then you can do something in them. And so think of, during the optimization\nbasically what it looks like is first you optimize the first line of code, and then the second line of code can kick in, and the third line of code can kick in.\nAnd I feel like because of the residual pathway and the dynamics of the optimization, you can sort of learn a very short algorithm\nthat gets the approximate answer, but then the other layers can sort of kick in and start to create a contribution. And at the end of it you're optimizing over an algorithm\nthat is 20 lines of code. Except these lines of code are very complex because it's an entire block of a transformer.\nYou can do a lot in there. Well, what's really interesting is that this transformer architecture actually has been remarkably resilient.\nBasically, the transformer that came out in 2016 is the transformer you would use today except you reshuffle some of the layer norms.\nThe layer normalizations have been reshuffled to a prenorm formulation and so it's been remarkably stable\nbut there's a lot of bells and whistles that people have attached on it and try to improve it. I do think that basically, it's a big step\nin simultaneously optimizing for lots of properties of a desirable neural network architecture. And I think people have been trying to change it\nbut it's proven remarkably resilient. But I do think that there should be even better architectures potentially.\n- But you admire the resilience here? - [Andrej] Yeah. - There's something profound about this architecture\nthat leads to resilience. - [Andrej] Yeah. - So maybe everything can be turned into a problem\nthat transformers can solve. - Currently, definitely looks like the transformers taking over AI and you can feed basically\narbitrary problems into it and it's a general differentiable computer and it's extremely powerful. And this conversions in AI has been really interesting\nto watch for me personally. - What else do you think could be discovered here about transformers?\nLike what surprising thing or is it a stable, out in a stable place?\nIs there something interesting we might discover about transformers? Like aha moments, maybe has to do with memory,\nmaybe knowledge representation, that kind of stuff. - Definitely, the zeitgeist today is just pushing,\nbasically, right now the zeitgeist is do not touch the transformer. - [Lex] Yeah. - Touch everything else. - [Lex] Yes.\n- So people are scaling up the data sets, making them much, much bigger. They're working on the evaluation, making the evaluation much, much bigger. And they're basically keeping the architecture unchanged.\nAnd that's how we've, that's the last five years of progress in AI. - What do you think about one flavor of it,\n"}
{"pod": "Lex Fridman Podcast", "input": "Language models", "output": "which is language models? Have you been surprised, has your imagination\nbeen captivated by, you mentioned GPT and all the bigger, and bigger, and bigger language models\nand what are the limits of those models do you think?\nSo just for the task of natural language. - Basically, the way GPT is trained, right, is you've just download a massive amount of text data\nfrom the internet and you try to predict the next word in a sequence, roughly speaking you're predicting\nlittle word chunks but roughly speaking that's it. And what's been really interesting to watch is\nbasically, it's a language model. Language models have actually existed for a very long time. There's papers on language modeling from 2003, even earlier.\n- Can you explain in that case, what a language model is? - Yeah, so language model, just basically the rough idea\nis just predicting the next word in a sequence, roughly speaking. So there's a paper from, for example, Bengio and the team\nfrom 2003, where for the first time they were using a neural network to take say like three or five words\nand predict the next word. And they're doing this on much smaller data sets and the neural net is not a transformer,\nit's a multilayer perceptron but it's the first time that a neural network has been applied in that setting.\nBut even before neural networks there were language models except they were using n-gram models.\nSo n-gram models are just count-based models. So if you try to take two words and predict a third one,\nyou just count up how many times you've seen any two-word combinations and what came next.\nAnd what you predict as coming next is just what you've seen the most of in the training set. And so language modeling has been around for a long time.\nNeural networks have done language modeling for a long time. So really what's new or interesting or exciting\nis just realizing that when you scale it up with a powerful enough neural net, a transformer,\nyou have all these emergent properties where basically what happens is if you have a large enough data set of text,\nyou are in the task of predicting the next word. You are multitasking a huge amount of different kinds of problems.\nYou are multitasking, understanding of chemistry, physics, human nature, lots of things are clustered\nin that objective. It's a very simple objective but actually, you have to understand a lot about the world to make that prediction. - You just said the U word understanding, are you,\nin terms of chemistry, and physics, and so on, what do you feel like it's doing? Is it searching for the right context in,\nwhat is the actual process happening here? - Yeah, so basically, it gets a thousand words\nand it's trying to predict a thousand and first. And in order to do that very, very well over the entire data set available on the internet,\nyou actually have to basically understand the context of what's going on in there.\n- [Lex] Yeah. - And it's a sufficiently hard problem that if you have a powerful enough computer,\nlike a transformer, you end up with interesting solutions. And you can ask it to do all kinds of things\nand it shows a lot of emergent properties like in-context learning, that was the big deal with GPT\nand the original paper when they published it, is that you can just prompt it in various ways and ask it to do various things\nand it will just kind of complete the sentence. But in the process of just completing the sentence it's actually solving all really interesting problems\nthat we care about. - Do you think it's doing something like understanding, like when we use the word understanding for us humans?\n- I think it's doing some understanding, in its weights it understands I think a lot about the world and it has to in order to predict the next word\nin a sequence. - So it's trained on the data from the internet.\nWhat do you think about this approach in terms of data sets, of using data from the internet?\nDo you think the internet has enough structured data to teach AI about human civilization?\n- Yeah, so I think the internet has a huge amount of data. I'm not sure if it's a complete enough set. I dunno that text is enough for having\na sufficiently powerful AGI as an outcome. - Of course, there is audio, and video, and images,\nand all that kind of stuff. - Yeah. So text by itself I'm a little bit suspicious about, there's a ton of things we don't put in text, in writing\njust because they're obvious to us about how the world works and the physics of it and that things fall. We don't put that stuff in text because why would you,\nwe share that understanding. And so text is a communication medium between humans and it's not a all-encompassing medium of knowledge\nabout the world. But as you pointed out, we do have video, and we have images, and we have audio. And so I think that definitely helps a lot.\nBut we haven't trained models sufficiently across all those modalities yet.\nSo I think that's what a lot of people are interested in. - But I wonder what that shared understanding of what we might call common sense\nhas to be learned, inferred in order to complete the sentence correctly.\nSo maybe the fact that it's implied on the internet the model's gonna have to learn that\nnot by reading about it, by inferring it in the representation. So common sense, just like we,\nI don't think we learn common sense, like nobody says, tells us explicitly, we just figure it all out\nby interacting with the world. - [Andrej] Right. - And so here's a model of reading about the way people interact with the world.\nIt might have to infer that. I wonder. - [Andrej] Yeah. - You briefly worked on a project called World of Bits,\ntraining an RL system to take actions on the internet versus just consuming the internet like we talked about.\n- [Andrej] Yeah. - Do you think there's a future for that kind of system interacting with the internet to help the learning?\n- Yes. I think that's probably the final frontier for a lot of these models, so as you mentioned,\nwhen I was at OpenAI, I was working on this project World of Bits and basically, it was the idea of giving neural networks access to a keyboard and a mouse.\nAnd the idea is that- - What could possibly go wrong? - So basically, you perceive the input of the screen pixels\nand basically, the state of the computer is visualized for human consumption in images of the web browser\nand stuff like that. And then you give the neural network the ability to press keyboards and use the mouse and we're trying to get it to, for example,\ncomplete bookings and interact with user interfaces. And- - What'd you learn from that experience?\nLike what was some fun stuff? 'Cause, that's a super cool idea. - [Andrej] Yeah. - I mean it's like, yeah, I mean\nthe step between observer to actor. - [Andrej] Yeah. - Is a super fascinating step. - Yeah.\nWell, it's the universal interface in the digital realm, I would say. And there's a universal interface in the physical realm,\nwhich in my mind is a humanoid form factor kind of thing. We can later talk about optimist and so on, but I feel like they're a similar philosophy in some way\nwhere the physical world is designed for the human form and the digital world is designed for the human form\nof seeing the screen and using keyboard and mouse. And so it's the universal interface\nthat can basically command the digital infrastructure we've built up for ourselves. And so it feels like a very powerful interface to command\nand to build on top of. Now, to your question as to what I learned from that, it's interesting because the World of Bits\nwas basically too early I think at OpenAI, at the time. This is around 2015 or so.\nAnd the zeitgeist at that time was very different in AI from the zeitgeist today. At the time everyone was super excited\nabout reinforcement learning from scratch. This is the time of the Atari paper where neural networks were playing Atari games\nand beating humans in some cases, AlphaGo, and so on. So everyone's very excited about training neural networks from scratch,\nusing reinforcement learning directly. It turns out that reinforcement learning is extremely inefficient way of training neural networks\nbecause you're taking all these actions and all these observations and you get some sparse rewards once in a while.\nSo you do all this stuff based on all these inputs and once in a while you're told you did a good thing,\nyou did a bad thing and it's just an extremely hard problem, you can't learn from that. You can burn a forest and you can brute force through it.\nAnd we saw that I think with Go and Dota and so on, and it does work, but it's extremely inefficient\nand not how you want to approach problems, practically speaking. And so that's the approach that at the time we also took to World of Bits.\nWe would have an agent initialize randomly, so he would keyboard mash, and mouse mash, and try to make a booking.\nAnd it just revealed the insanity of that approach very quickly, where you have to stumble by the correct booking\nin order to get a reward of you did it correctly. And you're never gonna stumble by it by chance at random.\n- So even with a simple web interface there's too many options. - There's just too many options and it's two spars of a reward signal.\nAnd you're starting from scratch at the time and so you don't know how to read, you don't understand pictures, images, buttons.\nYou don't understand what it means to make a booking. But now what's happened is it is time to revisit that\nand OpenAi is interested in this, companies like Adept are interested in this, and so on.\nAnd the idea is coming back because the interface is very powerful but now you're not training an agent from scratch.\nYou are taking the GPT as an initialization. So GPT is pre-trained on all of text\nand it understands what's a booking, it understands what's a submit, it understands quite a bit more.\nAnd so it already has those representations. They are very powerful and that makes all the training significantly more efficient\nand makes the problem tractable. - Should the interaction be the way humans see it, with the buttons and the language,\nor should it be with the HTML, JavaScript, and the CSS? - [Andrej] Yeah. - What do you think is the better?\n- So today all this interaction is mostly on the level of HTML, CSS, and so on. That's done because of computational constraints.\nBut I think ultimately, everything is designed for human visual consumption and so at the end of the day\nthere's all the additional information is in the layout of the webpage, and what's next to you, and what's a red background, and all this kind of stuff.\nAnd what it looks like visually. So I think that's the final frontier is we are taking in pixels and we're giving out keyboard,\nmouse commands, but I think it's impractical still today. - Do you worry about bots on the internet given these ideas,\n"}
{"pod": "Lex Fridman Podcast", "input": "Bots", "output": "given how exciting they are? Do you worry about bots on Twitter being not the stupid bots that we see now with the crypto bots,\nbut the bots that might be out there actually that we don't see, that they're interacting in interesting ways.\nSo this kind of system feels like it should be able to pass the, I'm not a robot click button, whatever.\nDo you actually understand how that test works? I don't quite, there's a checkbox or whatever\nthat you click. - [Andrej] Yeah. - It's presumably tracking. - [Andrej] Oh, I see. - Like mouse movement and the timing and so on.\n- [Andrej] Yeah. - So exactly this kind of system we're talking about should be able to pass that. So yeah.\nWhat do you feel about bots that are language models\nplus have some interactability and are able to Tweet and reply and so on? Do you worry about that world?\n- Yeah, I think it's always been a bit of an arms race between the attack and the defense,\nso the attack will get stronger but the defense will get stronger as well. Our ability to detect that. - How do you defend, how do you detect,\nhow do you know that your Karpathy account on Twitter is human?\nHow would you approach that, like if people were to claim, how would you defend yourself in the court of law\nthat I'm a human, this account is human? - Yeah, at some point I think it might be,\nI think society will evolve a little bit. We might start signing, digitally signing some of our correspondence or things that we create.\nRight now it's not necessary but maybe in the future, it might be. I do think that we are going towards the world\nwhere we share the digital space with AIs. - [Lex] Synthetic beings.\n- Yeah. And they will get much better and they will share our digital realm and they'll eventually share our physical realm as well.\nIt's much harder but that's kind of like the world we're going towards. And most of them will be benign and helpful\nand some of them will be malicious. And it's going to be an arms race trying to detect them. - So, I mean the worst isn't the AIs,\nthe worst is the AIs pretending to be human. So, I don't know if it's always malicious.\nThere's obviously a lot of malicious applications, but it could also be if I was an AI\nI would try very hard to pretend to be human because we're in a human world. - [Andrej] Yeah.\n- I wouldn't get any respect as an AI. - [Andrej] Yeah. - I wanna get some love and respect. - I don't think the problem is intractable.\nPeople are thinking about the proof of personhood. - [Lex] Yes. - And we might start digitally signing our stuff\nand we might all end up having like, yeah, basically some solution for proof of personhood.\nIt doesn't seem to me intractable, it's just something that we haven't had to do until now. But I think once the need really starts to emerge,\nwhich is soon, I think people will think about it much more. - But that too will be a race because obviously\nyou can probably spoof or fake the proof of personhood.\nSo you have to try to figure out how to- - [Andrej] Probably. - I mean it's weird that we have social security numbers,\nand passports, and stuff. It seems like it's harder to fake stuff\nin the physical space. But in the digital space, it just feels like it's gonna be very tricky.\nVery tricky to out, 'cause it seems to be pretty low cost to fake stuff.\nWhat are you gonna put an AI in jail for trying to use a fake personhood proof?\nI mean, okay, fine, you'll put a lot of AIs in jail, but there'll be more AIs, like exponentially more.\nThe cost of creating a bot is very low unless there's some kind of way to track accurately.\nLike you're not allowed to create any program without tying yourself to that program.\nAny program that runs on the internet, you'll be able to trace every single human programming\nthat was involved with that program. - [Andrej] Right. Yeah. Maybe you have to start declaring when, we have to start drawing those boundaries\nand keeping track of, okay, what are digital entities versus human entities and what is the ownership\nof human entities and digital entities and something like that.\nI don't know but I think I'm optimistic that this is possible and in some sense\nwe're currently in the worst time of it because all these bots suddenly have become very capable\nbut we don't have defenses yet built up as a society but I think that doesn't seem to me intractable, it's just something that we have to deal with.\n- It seems weird that the Twitter bot, like really crappy Twitter bots, are so numerous.\n- [Andrej] Yes. - So I presume that the engineers at Twitter are very good.\nSo it seems like what I would infer from that is it seems like a hard problem.\nThey're probably catching, alright, if I were to sort of steel-man the case, it's a hard problem and there's a huge cost\nto false positive to removing a post by somebody\nthat's not a bot, that creates a very bad user experience. So they're very cautious about removing.\nAnd maybe the bots are really good at learning what gets removed and not such that they can stay ahead\nof the removal process very quickly. - My impression of it honestly, is there's a lot of longing for it.\nI mean. - [Lex] Yeah. - It's not subtle, is my impression of it. It's not subtle.\n- But you have, yeah, that's my impression as well. But it feels like maybe you're seeing\nthe tip of the iceberg, maybe the number of bots is in the trillions and you have to like, just it's a constant assault of bots\nand you, I don't know, you have to steel-man the case. 'Cause the bots I'm seeing are pretty like obvious.\nI could write a few lines of code that catch these bots. - Yeah. I mean definitely, there's a lot of longing for it. But I will say I agree that if you are a sophisticated actor\nyou could probably create a pretty good bot right now using tools like GPTs because it's a language model.\nYou can generate faces that look quite good now and you can do this at scale.\nAnd so I think, yeah, it's quite plausible and it's going to be hard to defend. - There was a Google engineer that claimed\n"}
{"pod": "Lex Fridman Podcast", "input": "Google's LaMDA", "output": "that the LaMDA was sentient. Do you think there's any inkling of truth to what he felt?\nAnd more importantly, to me at least, do you think language models will achieve sentience or the illusion of sentience soonish?\n- Yeah. To me, it's a little bit of a canary in a coal mine moment. Honestly, a little bit because,\nso this engineer spoke to a chatbot at Google and became convinced that this bot is sentient.\n- He asked it some existential philosophical questions. - And it gave reasonable answers and looked real and so on.\nSo to me, it's a, he wasn't sufficiently trying\nto stress the system I think and exposing the truth of it as it is today.\nBut I think this will be increasingly harder over time. So yeah, I think more and more people will basically become,\nyeah, I think there will be more people like that over time as this gets better. - Like form an emotional connection to an AI?\n- Yeah. Perfectly plausible in my mind. I think these AIs are actually quite good at human connection, human emotion.\nA ton of text on the internet is about humans, and connection, and love, and so on.\nSo I think they have a very good understanding in some sense of how people speak to each other about this.\nAnd they're very capable of creating a lot of that kind of text.\nThere's a lot of like sci-fi from fifties and sixties that imagined AIs in a very different way. They are calculating, cold, Vulkan-like machines.\nThat's not what we're getting today. We're getting pretty emotional AIs that actually are very competent and capable\nof generating plausible-sounding text with respect to all these topics. - See I'm really hopeful about AI systems\nthat are companions that help you grow, develop as a human being, help you maximize long-term happiness.\nBut I'm also very worried about AI systems that figure out from the internet that humans get attracted to drama.\nAnd so these would just be like shit-talking AIs that just constantly, did you hear? They'll do gossip, they'll try to plant seeds\nof suspicion to other humans that you love and trust. And just kind of mess with people\n'cause that's going to get a lot of attention. So drama, maximize drama. - [Andrej] Yeah. - On the path to maximizing engagement\nand us humans will feed into that machine. - [Andrej] Yeah. - And it'll be a giant drama shit storm-\nSo I'm worried about that. So as the objective function really defines the way\nthat human civilization progresses with AIs in it. - Yeah. I think right now, at least today, it's not correct to really think of them\nas goal-seeking agents that want to do something. They have no long-term memory or anything,\na good approximation of it is you get a thousand words and you're trying to predict a thousand of them first and then you continue feeding it in\nand you are free to prompt it in whatever way you want. So in text. So you say okay you are a psychologist and you are very good\nand you love humans and here's the conversation between you and another human, human column something, you something,\nand then it just continues the pattern and suddenly you're having a conversation with a fake psychologist who's trying to help you.\nAnd so it's still kind of a the realm of a tool, people can prompt it in arbitrary ways and it can create really incredible text\nbut it doesn't have long-term goals over long periods of time. So it doesn't look that way right now.\n- Yeah. But you can do short-term goals that have long-term effects. - [Andrej] Yeah. - So if my prompting short-term goal\nis to get Andrej Karpathy to respond to me on Twitter when I, I think AI might, that's the goal,\nbut it might figure out that talking shit to you, it would be the best in a highly sophisticated interesting way.\n- [Andrej] Right. - And then you build up a relationship when you respond once and then over time, it gets to not be sophisticated\nand just talk shit, and okay, maybe you won't get to Andrej\nbut it might get to another celebrity, it might get into other big accounts. - [Andrej] Yeah.\n- So with just that simple goal, get them to respond. - [Andrej] Yeah. - Maximize the probability of actual response.\n- Yeah. I mean you could prompt a powerful model like this with its opinion about how to do\nany possible thing you're interested in. - [Lex] Yes. - And they're kind of on track to become these oracles, I could think of it that way.\nThey are oracles currently it's just text but they will have calculators, they will have access to Google search, they will have all kinds of gadgets and gizmos.\nThey will be able to operate the internet and find different information and yeah,\nin some sense that's kinda like currently what it looks like in terms of the development. - Do you think it'll be an improvement eventually\nover what Google is for access to human knowledge?\nIt'll be a more effective search engine to access human knowledge? - I think there's definite scope in building a better search engine today.\nAnd I think Google, they have all the tools, all the people, they have everything they need. They have all the possible pieces, they have people training transformers at scale,\nthey have all the data. It's just not obvious if they are capable as an organization to innovate on their search engine right now\nand if they don't someone else will. There's absolute scope for building a significantly better search engine built on these tools.\n- It's so interesting a large company where the search, there's already an infrastructure, it works,\nads brings out a lot of money. So where structurally inside a company is their motivation to pivot.\n- [Andrej] Yeah. - To say we're going to build a new search engine. - [Andrej] Yep. - That's really hard. - So it's usually going to come from a startup, right?\n- Yeah or some other more competent organization. So I don't know.\nSo currently for example, maybe Bing has another shot at it, as an example. - [Lex] There you go, Microsoft Edge\nas we're talking offline. - It's really interesting because search engines\nused to be about okay here's some query, here's web pages that look like the stuff that you have.\nBut you could just directly go to answer and then have supporting evidence. And these models, basically, they've read all the texts\nand they've read all the web pages. And so sometimes when you see yourself going over to search results and getting a sense of the average answer\nto whatever you're interested in, that just directly comes out, you don't have to do that work.\nSo they're kind of like- Yeah, I think they have a way to of distilling all that knowledge into some level of insight, basically.\n- Do you think of prompting as a teaching and learning, like this whole process?\nLike another layer? 'Cause maybe that's what humans are, you already have that background model\nand then the world is prompting you. - Yeah, exactly. I think the way we are programming these computers now,\nlike GPTs, is converging to how you program humans. I mean, how do I program humans via prompt?\nI go to people and I prompt them to do things, I prompt them for information. And so natural language prompt is how we program humans\nand we're starting to program computers directly in that interface. It's pretty remarkable honestly. - So you've spoken a lot about the idea of Software 2.0.\n"}
{"pod": "Lex Fridman Podcast", "input": "Software 2.0", "output": "All good ideas become cliches so quickly, like the terms, it's kind of hilarious.\nIt's like, I think Eminem once said that if he gets annoyed by a song he's written very quickly,\nthat means it's gonna be a big hit 'cause it's too catchy. But can you describe this idea\nand how you're thinking about it has evolved over the months and years since you coined it?\n- Yeah. Yeah. So I had a blog post on Software 2.0, I think several years ago now.\nAnd the reason I wrote that post is because I saw something remarkable happening\nin software development and how a lot of code was being transitioned to be written\nnot in C++ and so on, but it's written in the weights of a neural net. Basically just saying that neural nets\nare taking over software, the realm of software and taking more and more and more tasks. And at the time, I think not many people understood this\ndeeply enough that this is a big deal. This is a big transition. Neural networks were seen as one of multiple classification algorithms you might use\nfor your dataset problem on Kaggle. This is not that, this is a change in how we program computers.\nAnd I saw neural nets as this is going to take over, the way we program computers is going to change,\nit's not going to be people writing software in C++ or something like that and directly programming the software.\nIt's going to be accumulating training sets and data sets and crafting these objectives by which we train these neural nets.\nAnd at some point, there's going to be a compilation process from the dataset and the objective and the architecture specification into the binary,\nwhich is really just the neural net weights and the forward pass of the neural net\nand then you can deploy that binary. And so I was talking about that transition and that's what the post is about.\nAnd I saw this play out in a lot of fields, autopilot being one of them,\nbut also just a simple image classification. People thought originally, in the eighties and so on,\nthat they would write the algorithm for detecting a dog in an image and they had all these ideas about how the brain does it and first, we detected corners\nand then we detect lines and then we stitched them up and they were really going at it. They were thinking about how they're gonna write the algorithm\nand this is not the way you build it. And there was a smooth transition where, okay,\nfirst we thought we were gonna build everything, then we were building the features, so HOG features and things like that\nthat detect these little statistical patterns from image patches. And then there was a little bit of learning on top of it,\na support vector machine or binary classifier for cat versus dog and images on top of the features.\nSo we wrote the features but we trained the last layer, as the classifier.\nAnd then people are like, actually, let's not even design the features because we can't, honestly, we're not very good at it. So let's also learn the features.\nAnd then you end up with basically a compilation neural net where you're learning most of it. You're just specifying the architecture.\nAnd the architecture has tons of filled-in blanks, which is all the knobs and you let the optimization\nwrite most of it. And so this transition is happening across the industry everywhere. And suddenly we end up with a ton of code\nthat is written in neural net weights. And I was just pointing out that the analogy is actually pretty strong and we have a lot of developer environments\nfor Software 1.0. We have IDEs, how you work with code, how you debug code, how do you run code,\nhow do you maintain code? We have GitHub. So I was trying to make those analogies in the new realm, what is the GitHub of Software 2.0?\nTurns out it's something that looks like Hugging Face right now? And so I think some people took it seriously\nand built cool companies and many people originally attacked the post. It actually was not well received when I wrote it\nand I think maybe it has something to do with the title, but the post was not well received and I think more people have been coming around to it over time.\n- Yeah. So you were the Director of AI at Tesla where I think this idea was really implemented at scale,\nwhich is how you have engineering teams doing Software 2.0. So can you linger on that idea of,\nI think we're in the really early stages of everything you just said, which is like GitHub, IDEs,\nhow do we build engineering teams that work in Software 2.0 systems and the data collection\nand the data annotation, which is all part of that Software 2.0.\nWhat do you think is the task of programming Software 2.0? Is it debugging in the space of hyper-parameters\nor is it also debugging the space of data? - Yeah, the way by which you program the computer\nand influence its algorithm is not by writing the commands yourself.\nYou're changing mostly the data set. You're changing the loss functions\nof what the neural net is trying to do, how it's trying to predict things. But basically the data sets and the architectures of the neural net.\nAnd so in the case of the autopilot, a lot of the data sets have to do with, for example,\ndetection of objects and lane line markings and traffic lights and so on. So you accumulate massive data sets of, here's an example, here's the desired label\nand then here's roughly what the algorithm should look like. And that's a compilation neural net.\nSo the specification of the architecture is like a hint as to what the algorithm should roughly look like. And then the fill in the blanks process of optimization\nis the training process. And then you take your neural net that was trained, it gives all the right answers on your data set\nand you deploy it. - So in that case, perhaps at all machine learning cases,\nthere's a lot of tasks. So is coming up formulating a task\nfor a multi-headed neural network, is formulating a task part of the programming? - [Andrej] Yeah, pretty much so.\n- How you break down a problem into a set of tasks. - Yeah. On a high-level, I would say\nif you look at the software running in the autopilot, I give a number of talks on this topic.\nI would say originally a lot of it was written in Software 1.0, imagine lots of C++, right?\nAnd then gradually, there was a tiny neural net that was, for example, predicting given a single image,\nis there a traffic light or not? Or is there a lane line marking or not? And this neural net didn't have too much to do\nin the scope of the software, it was making tiny predictions on an individual little image and then the rest of the system stitched it up.\nSo okay, we don't have just a single camera, we have eight cameras, we actually have eight cameras over time.\nAnd so what do you do with these predictions? How do you put them together? How do you do the fusion of all that information and how do you act on it?\nAll of that was written by humans in C++. And then we decided, okay, we don't actually want\nto do all of that fusion in the C++ code because we're actually not good enough to write that algorithm. We want the neural nets to write the algorithm\nand we want to port all of that software into the 2.0 stack. And so then we actually had neural nets\nthat now take all the eight camera images simultaneously and make predictions for all of that.\nSo, and actually, they don't make predictions in the space of images.\nThey now make predictions directly in 3D and, actually, in three dimensions around the car.\nAnd now, actually, we don't manually fuse the predictions in 3D over time we don't trust ourselves\nto write that tracker. So actually, we give the neural net the information over time. So it takes these videos now and makes those predictions.\nAnd so you're just like putting more and more power into the neural net processing and at the end of it, the eventual goal is to have most of the software\npotentially be in the 2.0 end because it works significantly better.\nHumans are just not very good at writing software, basically. - So the prediction is happening in this 4D land.\n- [Andrej] Yeah. - Was three-dimensional world over time. - [Andrej] Yeah. - How do you do annotation in that world?\nSo data annotation, whether it's self-supervised or manual by humans is a big part\nof this Software 2.0 world. - I would say by far in the industry, if you're talking about the industry\nand what is the technology of what we have available? Everything is supervised learning. So you need data sets of input, desired output\nand you need lots of it. And there are three properties of it that you need. You need it to be very large,\nyou need it to be accurate, no mistakes and you need it to be diverse. You don't want to just have a lot\nof correct examples of one thing. You need to really cover the space of possibility as much as you can. And the more you can cover the space of possible inputs,\nthe better the algorithm will work at the end. Now once you have really good data sets that you're collecting, curating and cleaning,\nyou can train your neural net on top of that. So a lot of the work goes into cleaning those data sets.\nNow, as you pointed out, the question is how do you achieve a ton of-\nIf you want to basically predict in 3D, you need data in 3D to back that up. So in this video, we have eight videos\ncoming from all the cameras of the system and this is what they saw and this is the truth of what actually was around, there was this car\nand there was this car, this car, these are the lane line markings, this is the geometry of the road. There's a traffic light in this three-dimensional position,\nyou need the ground truth. And so the big question that team was solving, of course, is how do you arrive at that ground truth?\nBecause once you have a million of it and it's large, clean and diverse, then training a neural net on it works extremely well\nand you can ship that into the car. And so there's many mechanisms by which we collected that training data.\nYou can always go for human annotation, you can go for simulation as a source of ground truth, you can also go for what we call the offline tracker\nthat we've spoken about at the AI Day and so on, which is basically an automatic reconstruction process\nfor taking those videos and recovering the three-dimensional reality of what was around that car.\nSo basically, think of doing a three-dimensional reconstruction as an offline thing and then understanding that okay,\nthere's 10 seconds of video, this is what we saw and therefore here's all the lane lines, cars and so on.\nAnd then once you have that annotation, you can train neural nets to imitate it. - And how difficult is the 3D reconstruction?\n- [Andrej] It's difficult but it can be done. - So there's overlap between the cameras and you do the reconstruction\nand perhaps if there's any inaccuracy so that's caught in the annotation step. - Yes.\nThe nice thing about the annotation is that it is fully offline. You have infinite time, you have a chunk of one minute\nand you're trying to just offline in a super-computer somewhere. Figure out where were all the positions of all the cars,\nof all the people, and you have your full one minute of video from all the angles and you can run all the neural nets you want and they can be very efficient, massive neural nets,\nthey can be neural net that can't even run in the car later at test time. So they can be even more powerful neural nets than what you can eventually deploy.\nSo you can do anything you want, three-dimensional reconstruction, neural nets, anything you want just to recover that truth\nand then you supervise that truth. - What have you learned? You said no mistakes about humans doing annotation\n"}
{"pod": "Lex Fridman Podcast", "input": "Human annotation", "output": "'cause there's like a range of things they're good at\nin terms of clicking stuff on screen. How interesting is that to you of a problem of designing\nan annotator where humans are accurate, enjoy it, what are they even the metrics, are efficient,\nare productive, all that kind of stuff? - Yeah, so I grew the annotation team at Tesla from, basically, zero to a thousand while I was there.\nThat was really interesting. My background is a PhD student researcher. So growing that kind of organization was pretty crazy.\nBut yeah, I think it's extremely interesting and part of the design process very much behind the autopilot as to where you use humans.\nHumans are very good at certain kinds of annotations. They're very good, for example, at two-dimensional annotations of images. They're not good at annotating cars over time\nin three-dimensional space. Very, very hard. And so that's why we're very careful to design the tasks that are easy to do for humans\nversus things that should be left to the offline tracker. Maybe the computer will do all the triangulation and 3D construction but the human will say\nexactly these pixels of the image are car. Exactly these pixels are human. And so co-designing the data annotation pipeline\nwas very much bread and butter what I was doing daily. - Do you think there's still a lot of open problems\nin that space? Just in general annotation where the stuff the machines are good at, machines do\nand the humans do what they're good at and there's maybe some iterative process? - Right.\nI think to a very large extent, we went through a number of iterations and we learned a ton about how to create these data sets.\nI'm not seeing big open problems. Originally, when I joined I was really not sure\nhow this would turn out. - [Lex] Yeah. - But by the time I left I was much more secure and actually, we understand the philosophy\nof how to create these data sets and I was pretty comfortable with where that was at the time. - So what are strengths and limitations of cameras\n"}
{"pod": "Lex Fridman Podcast", "input": "Camera vision", "output": "for the driving task in your understanding when you formulate the driving task as a vision task\nwith eight cameras, you've seen that the entire, most of the history of the computer vision field\nwhen it has to do with neural networks. Just if you step back, what are the strengths and limitations of pixels, of using pixels to drive?\n- Yeah, pixels I think are a beautiful sensory, beautiful sensor I would say. The thing is like cameras are very, very cheap\nand they provide a ton of information, ton of bits. So it's a extremely cheap sensor for a ton of bits.\nAnd each one of these bits is a constraint on the state of the world. And so you get lots of megapixel images, very cheap\nand it just gives you all these constraints for understanding what's actually out there in the world. So vision is probably the highest bandwidth sensor.\nIt's a very high bandwidth sensor. - I love that pixels is a constraint on the world.\nIt's this highly complex, high bandwidth constraint\non the stage of the world. That's fascinating. - It's not just that, but again this real importance of it's the sensor that humans use,\ntherefore everything is designed for that sensor. - [Lex] Yeah. - The text, the writing, the flashing signs,\neverything is designed for vision and so, and you just find it everywhere. And so that's why that is the interface you want to be in\ntalking again about these universal interfaces and that's where we actually want to measure the world as well and then develop software for that sensor.\n- But there's other constraints on the state of the world that humans use to understand the world.\nI mean vision ultimately is the main one. But we're referencing our understanding of human behavior\nand some common-sense physics that could be inferred from vision, from a perception perspective.\nBut it feels like we're using some kind of reasoning to predict the world.\n- [Andrej] Yeah, hundred percent. - Not just the pixels. - I mean you have a powerful prior service for how the world evolves over time, et cetera.\nSo it's not just about the likelihood term coming up from the data itself telling you about what you are observing,\nbut also the prior term of what are the likely things to see and how do they likely move and so on.\n- And the question is how complex is the range of possibilities that might happen\nin the driving task. - [Andrej] Right. - Is that to you still an open problem of how difficult is driving, philosophically speaking?\nOf al the time you worked on driving, do you understand how hard driving is? - Yeah, driving is really hard\nbecause it has to do with the predictions of all these other agents and the theory of mind and what they're gonna do. And are they looking at you?\nWhere are they looking? What are they thinking? - [Lex] Yeah. - There's a lot that goes there at the full tail-off,\nthe expansion of the nines that we have to be comfortable with eventually the final problems are of that form. I don't think those are the problems that are very common.\nI think eventually they're important but it's really in the tail end. - In the tail end, the rare edge cases.\n- [Andrej] Yes. - From the vision perspective, what are the toughest parts of the vision problem of driving?\n- Well, basically, the sensor is extremely powerful but you still need to process that information.\nAnd so going from brightnesses of these pixel values to, hey, here are the three-dimensional world,\nis extremely hard and that's what the neural networks are fundamentally doing. And so the difficulty really is in just\ndoing an extremely good job of engineering the entire pipeline, the entire data engine,\nhaving the capacity to train these neural nets, having the ability to evaluate the system and iterate on it.\nSo I would say just doing this in production at scale is the hard part, it's an execution problem. - So the data engine but also the deployment of the system\nsuch that has low latency performance. So it has to do all these steps. - Yeah. For the neural nets specifically just making sure\neverything fits into the chip on the car. - [Lex] Yeah. - And you have a finite budget of flops that you can perform and memory bandwidth\nand other constraints and you have to make sure it flies and you can squeeze in as much computer as you can into the tiny.\n- What have you learned from that process? Because maybe that's one of the bigger, new things,\ncoming from a research background, where there's a system that has to run under heavily constrained resources.\nHas to run really fast. What insights have you learned from that?\n- Yeah, I'm not sure if there's too many insights, you're trying to create a neural net that will fit in what you have available\nand you're always trying to optimize it. And we talked a lot about it on the AI Day and, basically, the triple backflips\nthat the team is doing to make sure it all fits and utilizes the engine. So I think it's extremely good engineering\nand then there's all kinds of little insights peppered in on how to do it properly. - Let's actually zoom out\n"}
{"pod": "Lex Fridman Podcast", "input": "Tesla's Data Engine", "output": "'cause I don't think we talked about the data engine, the entirety of the layouts of this idea\nthat I think is just beautiful with humans in the loop. Can you describe the data engine?\n- Yeah, the data engine is what I call the almost biological feeling process\nby which you perfect the training sets for these neural networks.\nSo because most of the programming now is in the level of these data sets and make sure they're large, diverse and clean, basically you have a data set\nthat you think is good, you train your neural net, you deploy it, and then you observe how well it's performing\nand you're trying to always increase the quality of your data set. So you're trying to catch scenarios,\nbasically, that are, basically, rare. And it is in these scenarios that neural nets will typically struggle in\nbecause they weren't told what to do in those rare cases in the data set. But now you can close the loop because if you can now collect all those at scale,\nyou can then feed them back into the reconstruction process I described and reconstruct the truth in those cases\nand add it to the dataset. And so the whole thing ends up being a staircase of improvement of perfecting your training set\nand you have to go through deployments so that you can mine the parts that are not yet represented well on the dataset.\nSo your dataset is basically imperfect. It needs to be diverse, it has pockets that are missing and you need to pat out the pockets.\nYou can sort of think of it that way in the data. - What role do humans play in this? So what's this biological system like a human body\nmade up of cells? What role? How do you optimize the human system?\nThe multiple engineers collaborating, figuring out what to focus on, what to contribute,\nwhich task to optimize in this neural network. Who's in charge of figuring out which task needs more data?\nCan you speak to the hyperparameters, the human system? - It really just comes down to extremely good execution\nfrom an engineering team that knows what they're doing. They understand intuitively the philosophical insights underlying the data engine and the process\nby which the system improves and how to, again, delegate the strategy of the data collection\nand how that works. And then just making sure it's all extremely well executed. And that's where most of the work, it's not even the philosophizing or the research\nor the ideas of it. It's just extremely good execution is so hard when you're dealing with data at that scale. - So your role in the data engine executing well\nand it is difficult and extremely important. Is there a priority of a vision board of saying like,\nwe really need to get better at stoplights? - [Andrej] Yeah. - The prioritization of tasks?\n- [Andrej] Yes. - Is that essentially, and that comes from the data? - That comes to, a very large extent\nto what we are trying to achieve in the product roadmap. The release we're trying to get out and the feedback\nfrom the QA team where the system is struggling or not, the things we're trying to improve. - And the QA team gives some signal, some information\nin aggregate about the performance of the system in various conditions. - That's right. And then of course all of us drive it\nand we can also see it. It's really nice to work with a system that you can also experience yourself. It drives you home.\n- Is there some insight you can draw from your individual experience that you just can't quite get from an aggregate statistical analysis of data?\n- I would say so, yeah. - [Lex] It's so weird, right? - Yes. - It's not scientific in a sense\n'cause you're just one anecdotal sample. - Yeah, I think there's a ton of, it's a source of truth.\nIt's your interaction with the system. - [Lex] Yeah. - And you can see it, you can play with it, you can perturb it, you can get a sense of it,\nyou have an intuition for it. I think numbers and plots and graphs are much harder.\nIt hides a lot of- - It's like if you train a language model,\nit's a really powerful way is by you interacting with it. - [Andrej] Yeah, a hundred percent. - Start try to build up an intuition.\n- Yeah, I think Elon also, he always wanted to drive the system himself. He drives a lot and I don't wanna say almost daily.\nSo he also sees this as a source of truth, you driving the system and it performing and yeah.\n"}
{"pod": "Lex Fridman Podcast", "input": "Tesla Vision", "output": "- So what do you think? Tough questions here. So, Tesla, last year removed radar from the sensor suite\nand now just announce that it's gonna remove all ultrasonic sensors relying solely on vision,\nso camera only, does that make the perception problem harder or easier?\n- I would almost reframe the question in some way. So the thing is basically, you would think that additional sensors.\n- Wait, wait, wait, can I just interrupt? - [Andrej] Go ahead. - I wonder if a language model will ever do that if you prompt it.\nLet me reframe your question. That would be epic. That's the wrong prompt. Sorry.\n- Yeah, so it's a little bit of a wrong question because, basically, you would think that these sensors are an asset to you.\n- [Lex] Yeah. - But if you fully consider the entire product in its entirety, these sensors\nare actually potentially a liability because these sensors aren't free. They don't just appear on your car.\nSuddenly you have an entire supply chain, you have people procuring it, there can be problems with them, they may need replacement.\nThey are part of the manufacturing process. They can hold back the line in the production. You need to source them, you need to maintain them,\nyou have to have teams that ride the firmware, all of it. And then you also have to incorporate them,\ninfuse them into the system in some way. And so it actually bloats a lot of it. And I think Elon is really good at simplify, simplify,\nbest part is no part. And he always tries to throw away things that are not essential because he understands the entropy\nin organizations and an approach. And I think in this case the cost is high and you're not potentially seeing it\nif you're just a computer vision engineer and I'm just trying to improve my network and is it more useful or less useful?\nHow useful is it? And the thing is, if once you consider the full cost of a sensor, it actually is potentially a liability\nand you need to be really sure that it's giving you extremely useful information. In this case, we looked at using it or not using it\nand the delta was not massive. And so it's not useful. - Is it also bloat in the data engine,\nlike having more sensors? - Hundred percent. - Is it a distraction? - And these sensors, they can change over time.\nFor example, you can have one type of say radar, you can have other type of radar. They change over time. Now suddenly you need to worry about it.\nNow suddenly you have a column in your sequel light telling you, oh, what sensor type was it? And they all have different distributions\nand then they contribute noise and entropy into everything\nand they bloat stuff. And also organizationally, it's been really fascinating to me that it can be very distracting.\nIf all you wanna get to work is vision, all the resources are on it and you're building out a data engine\nand you're actually making forward progress because that is the sensor with the most bandwidth, the most constraints on the world.\nAnd you're investing fully into that. And you can make that extremely good. You have only a finite amount of sort of spend of focus\nacross different facets of the system. - And this reminds me of Rich Sutton, \"The Bitter Lesson\"\nthat just seems like simplifying the system. - [Andrej] Yeah. - In the long run. And of course, you don't know what the long run is\nand it seems to be always the right solution. - Yeah. Yes. - In that case, it was for RL but it seems to apply generally\nacross all systems that do computation. - [Andrej] Yeah. - So what do you think about the LiDAR as a crutch debate?\nThe battle between point clouds and pixels? - Yeah, I think this debate is always slightly confusing\nto me because it seems like the actual debate should be about do you have the fleet or not. That's the really important thing\nabout whether you can achieve a really good functioning of an AI system at this scale. - [Lex] So data collection systems.\n- Yeah. Do you have a fleet or not is significantly more important whether you have LiDAR or not. It's just another sensor.\nAnd yeah, I think similar to the radar discussion, basically, yeah, I don't think it,\nit basically doesn't offer extra information. It's extremely costly.\nIt has all kinds of problems. You have to worry about it, you have to calibrate it, et cetera. It creates bloat and entropy. You have to be really sure that you need this sensor.\nIn this case, I basically don't think you need it. And I think honestly, I will make a stronger statement. I think some of the other companies who are using it\nare probably going to drop it. - Yeah. So you have to consider the sensor in the full,\nin considering can you build a big fleet that collects a lot of data and can you integrate that sensor with that data,\nand that sensor into a data engine that's able to quickly find different parts of the data\nthat then continuously improves whatever the model that you're using. - Yeah. Another way to look at it is like, vision is necessary\nin a sense that the world is designed for human visual consumption. So you need vision, it's necessary.\nAnd then also it is sufficient because it has all the information that you need for driving.\nAnd humans obviously use vision to drive. So it's both necessary and sufficient. So you want to focus resources and you have to be really sure\nif you're going to bring in other sensors. You could add sensors to infinity, at some point you need to draw the line.\nAnd I think in this case, you have to really consider the full cost of any one sensor that you're adopting,\nand do you really need it? And I think the answer, in this case, is no. - So what do you think about the idea\nthat the other companies are forming high-resolution maps and constraining heavily the geographic regions\nin which they operate? Is that approach, in your view, not going to scale over time\nto the entirety of the United States? - [Andrej] Yeah. I think- - It'll take too long- - As you've mentioned like they pre-map all the environments\nand they need to refresh the map and they have a perfect centimeter-level-accuracy map of everywhere they're gonna drive.\nIt's crazy. How are you going to, when we're talking about autonomy actually changing the world, we're talking about\nthe deployment on the global scale of autonomous systems for transportation.\nAnd if you need to maintain a centimeter-accurate map for earth or for many cities and keep them updated,\nit's a huge dependency that you're taking on, a huge dependency. It's a massive, massive dependency\nand now you need to ask yourself, do you really need it? And humans don't need it, right?\nSo it's very useful to have a low-level map of like, okay, the connectivity of your road, you know that there's a fork coming up.\nWhen you drive in an environment, you have that high-level understanding. It's like a small Google map and Tesla uses Google map,\nsimilar resolution information in its system, but it will not pre-map environments\nto centimeter-level accuracy. It's a crutch, it's a distraction, it causes entropy, and it diffuses the team,\nit dilutes the team and you're not focusing on what's actually necessary, which is a computer vision problem.\n"}
{"pod": "Lex Fridman Podcast", "input": "Elon Musk", "output": "- What did you learn about machine learning, about engineering, about life, about yourself\nas one human being from working with Elon Musk? - I think the most I've learned is about\nhow to run organizations efficiently and how to create efficient organizations\nand how to fight entropy in an organization. - So human engineering in the fight against entropy.\n- Yeah, I think Elon is a very efficient warrior in the fight against entropy in organizations.\n- What does entropy in an organization look like exactly? - It's process. It's process and it's-\n- Inefficiencies in the form meetings and that kind of stuff? - Yeah. Meetings, he hates meetings, he keeps telling people\nto skip meetings if they're not useful. He basically runs the world's biggest startups,\nI would say, Tesla, SpaceX are the world's biggest startups. Tesla actually is multiple startups,\nI think it's better to look at it that way. And so I think he's extremely good at that.\nAnd yeah, he is a very good intuition for streamlining process. He's making everything efficient. Best part is no part, simplifying,\nfocusing, and just kind of removing barriers, moving very quickly, making big moves.\nAll this is very startupy sort of seeming things but at scale. - So strong drive to simplify.\n- [Andrej] Yeah. - From your perspective, I mean, that also probably applies to just designing systems\nand machine learning, and otherwise. - Yeah. - [Lex] like simplify, simplify. - Yes. - What do you think is the secret to maintaining\nthe startup culture in a company that grows? Is there, can you introspect that?\n- I do think he needs someone in a powerful position with a big hammer like Elon who's the cheerleader\nfor that idea, and ruthlessly pursues it. If no one has a big enough hammer,\neverything turns into committees, democracy within the company, process,\ntalking to stakeholders, decision-making, Just everything just crumbles. - [Lex] Yeah. - If you have a big person who is also really smart\nand has a big hammer, things move quickly. - So you said your favorite scene in \"Interstellar\"\nis the intense docking scene with the AI and Cooper talking, saying, \"Cooper, what are you doing?\nDocking. It's not possible. No, it's necessary.\" Such a good line, by the way, just so many questions there.\nWhy an AI in that scene presumably\nis supposed to be able to compute a lot more than the human is saying it's not optimal, why are the human,\nI mean that's a movie, but shouldn't the AI know much better than the human?\nAnyway, what do you think is the value of setting seemingly impossible goals?\nSo like our initial intuition, which seems like something that you have taken on\nthat Elon espouses that where the initial intuition of the community might say this is very difficult\nand then you take it on anyway, with a crazy deadline. You, just from a human engineering perspective,\nhave you seen the value of that? - I wouldn't say that setting impossible goals exactly\nis a good idea but I think setting very ambitious goals is a good idea. I think there's a, what I call sublinear scaling\nof difficulty, which means that 10x problems are not 10x hard. Usually, 10x harder problem is like two or three x\nharder to execute on. Because if you wanna actually, like if you wanna improve a system by 10%, it costs some amount of work.\nAnd if you wanna 10x improve the system, it doesn't cost you know, a 100x amount of the work. And it's because you fundamentally change the approach.\nAnd if you start with that constraint, then some approaches are obviously dumb and not going to work and it forces you to reevaluate.\nAnd I think it's a very interesting way of approaching problem-solving. - But it requires a weird kind of thinking.\nIt's just going back to your PhD days. It's like how do you think which ideas\nin the machine learning community are solvable? - [Andrej] Yes.\n- It requires, what is that? I mean there's the cliche of first principles thinking but it requires to basically ignore\nwhat the community is saying. 'Cause doesn't a community, doesn't a community in science\nusually draw lines of what is and isn't possible? - [Andrej] Right. - And it's very hard to break out of that\nwithout going crazy. - Yeah. I mean I think a good example here is the deep learning revolution in some sense\nbecause you could be in computer vision at that time, during the deep learning revolution of 2012 and so on.\nYou could be improving a computer vision stack by 10% or it can just be saying actually all this is useless\nand how do I do 10x better computer vision? Well, it's not probably by tuning a HOG feature detector,\nI need a different approach. I need something that is scalable. Going back to Richard Suttons\nand understanding the philosophy of the Bitter Lesson and then being like actually, I need a much more scalable system,\nlike a neural network that in principle works. And then having some deep believers that can actually\nexecute on that mission, make it work. So that's the 10x solution.\n"}
{"pod": "Lex Fridman Podcast", "input": "Autonomous driving", "output": "- What do you think is the timeline to solve the problem of autonomous driving? That's still in part an open question.\n- Yeah, I think the tough thing with timelines of self-driving obviously, is that no one has created self-driving.\n- [Lex] Yeah. - So it's not like, what do you think is a timeline to build this bridge? Well, we've built a million bridges before,\nhere's how long that takes. No one has built autonomy, it's not obvious.\nSome parts turn out to be much easier than others. So it's really hard to forecast. You do your best based on trend lines and so on\nand based on intuition. But that's why fundamentally it's just really hard to forecast this. No one has- - So even still like being inside of it,\nit's hard to- - Yes. Some things turn out to be much harder and some things turned out to be much easier.\n- Do you try to avoid making forecasts? 'Cause Elon doesn't avoid them, right?\nAnd heads of car companies in the past have not avoided it either. Ford and other places have made predictions\nthat we're gonna solve level-four driving by 2020, 2021, whatever.\nAnd they all backtrack on that prediction. As an AI person, do you feel yourself privately\nmake predictions or do they get in the way of your actual ability to think about a thing?\n- Yeah, I would say what's easy to say is that this problem is tractable and that's an easy prediction to make.\nIt's tractable- - So it's solvable? - It's going to work. Yes. It's just really hard. Some things turned out to be harder and somethings turn out to be easier.\nBut it definitely feels tractable and it feels like, at least the team at Tesla, which is what I saw internally,\nis definitely on track to that. - How do you form a strong representation\nthat allows you to make a prediction about tractability? So you're the leader a lot of humans,\nyou have to say this is actually possible. - Yeah.\n- How do you build up that intuition? It doesn't have to be even driving, it could be other tasks. - [Andrej] Right. - It could be, what difficult tasks did you work on\nin your life? I mean classification, achieving certain, just an image at certain level\nof superhuman-level performance. - Yeah, expert intuition. It's just intuition, it's belief.\n- So just like thinking about it long enough, like studying, looking at sample data, like you said, driving.\nMy intuition is really flawed on this. I don't have a good intuition about tractability. It could be anything.\nIt could be solvable. The driving task could be simplified\ninto something quite trivial. Like the solution to the problem would be quite trivial.\nAnd at scale, more and more cars driving perfectly might make the problem much easier.\nThe more cars you have driving, like people learn how to drive correctly, not correctly, but in a way that's more optimal for heterogeneous system\nof autonomous, and semi-autonomous, and manually driven cars, that could change stuff. Then again, also I've spent a ridiculous number of hours\njust staring at pedestrians crossing streets, thinking about humans. And it feels like the way we use our eye contact,\nit sends really strong signals and there's certain quirks and edge cases of behavior.\nAnd of course, a lot of the fatalities that happen have to do with drunk driving,\nboth on the pedestrian side and the driver's side. So there's that problem of driving at night and all that kind of.\n- [Andrej] Yeah. - So I wonder, it's like the space of possible solution into autonomous driving includes so many human factor issues\nthat it's almost impossible to predict. There could be super clean, nice solutions.\n- Yeah. I would say definitely, to use a game analogy, there's some fog of war, but you definitely also see\nthe frontier of improvement and you can measure historically how much you've made progress. And I think for example, at least what I've seen\nin roughly five years at Tesla. When I joined it barely kept lane on the highway.\nI think going up from Palo Alto to SF was like three or four interventions. Anytime the road would do anything geometrically\nor turn too much it would just not work. And so going from that to like a pretty competent system in five years and seeing what happens also under the hood\nand what the scale which the team is operating now with respect to data, and compute, and everything else\nis just massive progress. - So you're climbing a mountain and it's fog\nbut you're making a lot of progress. - It's Fog. You're making progress and you see what the next directions are and you're looking at some of the remaining challenges\nand they're not perturbing you, and they're not changing your philosophy, and you're not contorting yourself.\nYou're like, actually, these are the things that we still need to do. - Yeah, it's the fundamental components of solving the problem seem to be there,\nfrom the data engine, to the compute, to the compute on the car, to the compute for the training, all that kind of stuff.\n- [Andrej] Yes. - Over the years you've been at Tesla, you've done a lot of amazing breakthrough ideas\n"}
{"pod": "Lex Fridman Podcast", "input": "Leaving Tesla", "output": "and engineering all of it from the data engine to the human side, all of it.\nCan you speak to why you chose to leave Tesla? - Basically, as I described, I think over time\nduring those five years I've kind of gotten myself into a little bit of a managerial position.\nMost of my days were meetings, and growing the organization, and making decisions about,\nhigh-level strategic decisions about the team and what it should be working on, and so on. And it's kind of like a corporate executive role.\nAnd I can do it. I think I'm okay at it. But it's not like fundamentally what I enjoy. And so I think when I joined,\nthere was no computer vision team because Tesla was just going from the transition of using MobilEye, a third-party vendor, for all of its computer vision\nto having to build its computer vision system. So when I showed up, there were two people training deep neural networks.\nAnd they were training them at a computer at their legs, like down, there was a work.\n- There was some kind of basic classification task. - Yeah. And so I like grew that into what I think\nis a fairly respectable deep learning team, a massive computer cluster, a very good data annotation organization.\nAnd I was very happy with where that was. It became quite autonomous and so I stepped away\nand I'm very excited to do much more technical things again. Yeah. And kind of like we focus on AGI.\n- What was that soul searching like? 'Cause you took a little time off, I think, how many mushrooms did you take?\nNo, I'm just kidding. I mean, what was going through your mind? The human lifetime is finite.\n- [Andrej] Yeah. - You did a few incredible things. You're one of the best teachers of AI in the world.\nYou're one of the best. And I mean that in the best possible way. You're one of the best tinkerers in the AI world.\nMeaning like understanding the fundamentals of how something works by building it from scratch\nand playing with the basic intuitions. It's like Einstein, Fineman, were all really good at this kind of stuff.\nLike small example of a thing, to play with it, to try to understand it. So that, and obviously now with Tesla,\nyou helped build a team of machine learning\nengineers and a system that actually accomplishes something in the real-world. So given all that, what was the soul searching like?\n- Well, it was hard because obviously, I love the company a lot, and I love Elon, I love Tesla,\nso it was hard to leave. I love the team, basically. But yeah, I think I actually,\nI really potentially interested in revisiting it, maybe coming back at some point, working in Optimus,\nworking in AGI at Tesla. I think Tesla's going to do incredible things. It's basically a massive large-scale robotics\nkind of company with a ton of in-house talent for doing real incredible things. And I think human robots are going to be amazing.\nI think autonomous transportation is going to be amazing. All this is happening at Tesla. So I think it's just a really amazing organization.\nSo being part of it and helping it along I think was very, basically, I enjoyed that a lot. Yeah, it was basically difficult for those reasons\nbecause I love the company. But I'm happy to potentially at some point come back for act two.\nBut I felt like at this stage I built the team, it felt autonomous and I became a manager\nand I wanted to do a lot more technical stuff. I wanted to learn stuff. I wanted to teach stuff. And I just felt like it was a good time\nfor a change of pace a little bit. - What do you think is the best movie sequel\nof all time speaking of part two? 'Cause most of 'em suck. - Movie sequels? - Movie sequels, yeah.\nAnd you Tweet about movies. So just a tiny tangent, what's a favorite movie sequel?\n\"Godfather Part II\"? Are you a fan of \"Godfather\"? 'Cause you didn't even Tweet or mention \"The Godfather\".\n- Yeah, I don't love that movie. I know it has a- - We're gonna edit that out. We're gonna edit out the hate towards \"The Godfather\".\nHow dare you disrespect? - I think I will make a strong statement. I don't know why but I basically don't like any movie\nbefore 1995, something like that. - Didn't you mention \"Terminator 2\".\n- Okay. Okay. That's like a, \"Terminator 2\" was a little bit later. 1990...\n- No, I think \"Terminator 2\" was in the eighties. - And I like \"Terminator\" one as well, So, okay. So a few exceptions but by and large\nfor some reason, I don't like movies before 1995 or something. They feel very slow.\nThe camera is like zoomed out. It's boring, it's kind of naive, it's kind of weird. - And also Terminator was very much ahead of its time.\n- Yes. And \"The Godfather\", there's like no AGI.\n- I mean but you have, \"Good Will Hunting\" was one of the movies you mentioned and that doesn't have any AGI either.\nI guess it has mathematics. - Yeah, I guess occasionally, I do enjoy movies that don't feature. - Or like \"Anchorman\" that has no, that's.\n- \"Anchorman\" is so good. - I don't understand, speaking of AGI,\n'cause I don't understand why Will Ferrell is so funny. It doesn't make sense. It doesn't compute.\nThere's just something about him. And he's a singular human. 'Cause, you don't get that many comedies these days.\nAnd I wonder if it has to do about the culture or the Machine of Hollywood or does it have to do with\njust we got lucky with certain people in comedy that came together, 'cause he is a singular human. - Yeah, yeah.\nI love his movies. - That was a ridiculous tangent, I apologize. But you mentioned humanoid robots.\n"}
{"pod": "Lex Fridman Podcast", "input": "Tesla's Optimus", "output": "So what do you think about Optimus, about Tesla Bot? Do you think we'll have robots in the factory\nand in the home in 10, 20, 30, 40, 50 years? - Yeah. I think it's a very hard project.\nI think it's going to take a while, but who else is going to build human robots at scale? - [Lex] Yeah.\n- And I think it is a very good form factor to go after because like I mentioned the world is designed for humanoid form factor. These things would be able to operate our machines.\nThey would be able to sit down in chairs, potentially even drive cars. Basically, the world is designed for humans,\nthat's the form factor you want to invest into and make work over time. I think, there's another school of thought which is,\nokay, pick a problem and design a robot to it. But actually, designing a robot and getting a whole data engine and everything behind it to work\nis actually an incredibly hard problem. So it makes sense to go after general interfaces that, okay, they are not perfect for any one given task,\nbut they actually have the generality of just with a prompt, with English, able to do something across.\nAnd so I think it makes a lot of sense to go after a general interface in the physical world.\nAnd I think it's a very difficult project. It's going to take time, but I've seen no other company\nthat can execute on that vision. I think it's going to be amazing. Basically, physical labor, if you think transportation\nis a large market, try physical labor. It's insane. - But it's not just physical labor, to me,\nthe thing that's also exciting is the social robotics. So the relationship we'll have on different levels\nwith those robots. - Yeah. - That's why I was really excited to see Optimus.\nPeople have criticized me for the excitement, but I've worked with a lot of research labs\nthat do humanoid-legged robots, Boston Dynamics, Unitree.\nThere's a lot of companies that do legged robots, but that's the elegance of the movement\nis a tiny, tiny part of the big picture. So the two big exciting things to me about Tesla\ndoing humanoid or any legged robots is clearly integrating into the data engine.\nSo the data engine aspect, so the actual intelligence for the perception and the control and the planning\nand all that kind of stuff. Integrating into this huge, the fleet that you mentioned. Right. And then speaking of fleet, the second thing is\nthe mass manufacturers just knowing culturally driving towards a simple robot\nthat's cheap to produce at scale. - [Andrej] Yeah. - And doing that well, having experience to do that well, that changes everything.\nThat's why that's a very different culture and style than Boston Dynamics. Who by the way, those robots are just-\nThe way they move, it'll be a very long time before Tesla could achieve the smoothness of movement.\nBut that's not what it's about. It's about the entirety of the system.\nLike we talked about the data engine and the fleet. - [Andrej] Right. - And that's super exciting, even the initial sort of models.\nBut that too was really surprising that in a few months you can get a pro a prototype.\n- Yep. And the reason that happened very quickly is, as you alluded to, there's a ton of copy-paste from what's happening in the autopilot.\nA lot. The amount of expertise that came out of the woodworks at Tesla for building the human robot was incredible to see.\nBasically, Elon said at one point we're doing this and then next day, basically, all these CAD models\nstarted to appear and people talk about the supply chain and manufacturing. - [Lex] Yeah. - And people showed up with Screwdrivers and everything\nthe other day and started to like put together the body. And I was like, whoa. All these people exist at Tesla.\nAnd fundamentally building a car is actually not that different from building a robot. And that is true not just for the hardware pieces.\nAnd also let's not forget hardware, not just for a demo, but manufacturing of that hardware at scale\nis a whole different thing. But for software as well, basically, this robot currently thinks it's a car.\n- It's gonna have a midlife crisis at some point. - It thinks it's a car. Some of the earlier demos, actually, we were talking about\npotentially doing them outside in the parking lot because that's where all of the computer vision was working out of the box.\n- [Lex] That's Funny. - Instead of inside. But all the operating system, everything just copy-pastes,\ncomputer vision mostly copy-paste. I mean you have to retrain the neural nets, but the approach and everything and data engine and offline trackers and the way we go about\nthe occupancy tracker and so on. Everything copy-paste, you just need to retrain the neural nets. And then the planning control, of course,\nhas to change quite a bit, but there's a ton of copy-paste from what's happening at Tesla. And if you were to go with goal of like, okay,\nlet's build a million human robots and you're not Tesla, that's a lot to ask, if you're at Tesla,\nit's actually like, that's not that crazy. - And then the follow-up question is then how difficult, just like with driving,\nhow difficult is the manipulation task? - [Andrej] Yep. - Such that it can have an impact at scale? I think depending on the context,\nthe really nice thing about robotics is that, unless you do a manufacturer and that kind of stuff,\nis there is more room for error? - [Andrej] Yep. - Driving is so safety-critical and also time critical,\na robot is allowed to move slower, which is nice. - Yes. I think it's going to take a long time.\nBut the way you want to structure the development is you need to say, okay, it's going to take a long time. How can I set up the product development roadmap\nso that I'm making revenue along the way? I'm not setting myself up for a zero-one-loss function where it doesn't work until it works.\nYou don't wanna be in that position. You want to make it useful almost immediately. And then you want to slowly deploy it and-\n- [Lex] At scale, hopefully. - At scale and you want to set up your data engine, your improvement loops, the telemetry, the evaluation,\nthe harness and everything. And you want to improve the product over time, incrementally. And you're making revenue along the way.\nThat's extremely important because otherwise, you cannot build these large undertakings, just don't make sense economically.\nAnd also from the point of view of the team working on it, they need the dopamine along the way. They're not just going to make a promise\nabout this being useful. This is going to change the world in 10 years when it works. This is not where you want to be.\nYou want to be in a place like I think autopilot today where it's offering increased safety and convenience of driving today.\nPeople pay for it, people like it, people purchase it. And then you also have the greater mission that you're working towards.\n- And you see that. So the dopamine for the team, that was the source of happiness? - Yes, hundred percent, you're deploying this.\nPeople like it, people drive it, people pay for it, they care about it. There's all these YouTube videos, your grandma drives it.\nShe gives you feedback. People like it, people engage with it. You engage with it. Huge. - Do people that drive Teslas recognize you\nand give you love? Like, hey thanks for this nice feature that it's doing.\n- Yeah, I think the tricky thing is some people really love you, some people, unfortunately, you're working on something that you think is extremely valuable, useful, et cetera,\nsome people do hate you. There's a lot of people who hate me and the team and the whole project.\nAnd I think- - Are they Tesla drivers? - Many cases they're not, actually. - Yeah.\nThat actually makes me sad about humans or the current ways that humans interact.\nI think that's actually fixable. I think humans want to be good to each other. I think Twitter and social media is part of the mechanism\nthat actually somehow makes the negativity more viral that it doesn't deserve,\ndisproportionately add a viral boost of negativity.\nBut I wish people would just get excited about, so suppress some of the jealousy,\nsome of the ego and just get excited for others. And then there's a karma aspect to that. You get excited for others, they'll get excited for you.\nSame thing in academia, if you're not careful, there is a dynamical system there. If you think of in silos and get jealous\nof somebody else being successful that actually perhaps counterintuitively\nleads the less productivity of you as a community and you individually. I feel like if you keep celebrating others,\nthat actually makes you more successful. - [Andrej] Yeah. - And I think people haven't, depending on the industry,\nhaven't quite learned that yet. - Yeah. Some people are also very negative and very vocal. So they're very prominently featured.\nBut actually, there's a ton of people who are cheerleaders, but they're silent cheerleaders. And when you talk to people just in the world,\nthey will all tell you it's amazing, it's great. Especially like people who understand how difficult it is to get this stuff working. People who have built products and makers and entrepreneurs,\nmaking this work and changing something is incredibly hard. Those people are more likely to cheerlead you.\n- Well, one of the things that makes me sad is some folks in the robotics community don't do the cheerleading and they should\n'cause they know how difficult it is. Well, they actually sometimes don't know how difficult it is to create a product at scale.\nRight? - [Andrej] Yep. - They actually deploy in the real-world. A lot of the development of robots and AI systems\nis done on very specific small benchmarks and as opposed to real-world additions.\n- Yes. Yeah. I think it's really hard to work on robotics in academic setting. - Or AI systems that apply in the real-world.\n"}
{"pod": "Lex Fridman Podcast", "input": "ImageNet", "output": "You've criticized, you flourished, and loved\nfor time the ImageNet, the famed ImageNet dataset and have recently had some words of criticism\nthat the academic research ML community gives a little too much love still to the ImageNet\nor those kinds of benchmarks. Can you speak to the strengths and weaknesses of data sets\nused in machine learning research? - Actually, I don't know that I recall the specific instance\nwhere I was unhappy or criticizing ImageNet. I think ImageNet has been extremely valuable.\nIt was basically a benchmark that allowed the deep learning community to demonstrate\nthat deep neural nets actually work. - [Lex] Yes. - There's a massive value in that.\nSo I think ImageNet was useful, but basically, it's become a bit of an EMNIST at this point. So EMNIST is like little 28 by 28 grayscale digits.\nThat's kind of a joke data set that everyone just crushes. - There's still papers written on EMNIST though, right?\nLike strong papers? - [Andrej] Yeah. - Like papers that focus on like how do we learn with a small amount of data, that kinda stuff.\n- Yeah. Yeah, I could see that being helpful but not in mainline computer vision research anymore, of course. - I think the way I've heard you just somewhere,\nmaybe I'm just imagining things, but I think you said like ImageNet was a huge contribution to the community for a long time\nand now it's time to move past those kinds of- - Well, ImageNet has been crushed. I mean, the error rates are, yeah,\nwe're getting like 90% accuracy in 1000 classification way prediction\nand I've seen those images and this is like really high, that's really good.\nIf I remember correctly, the top five error rate is now like 1% or something. - Given your experience with a gigantic real-world data set,\nwould you like to see benchmarks move into certain directions that the research community uses? - Unfortunately, I don't think academics\ncurrently have the next ImageNet. We've obviously, I think we've crushed EMNIST. We've basically crushed ImageNet\nand there's no next-big benchmark that the entire community rallies behind and uses\nfor further development of these networks. - Oh, yeah. I wonder what it takes for a dataset to captivate the imagination of everybody.\nLike where they all get behind it. That could also need a leader, right?\n- [Andrej] Yeah. - Somebody with popularity. I mean that, yeah, why did ImageNet takeoff?\nIs it just the accident of history? - It was the right amount of difficult, it was the right amount of difficult and simple\nand interesting enough it was the right time for that kind of a data set.\n- Question from Reddit. What are your thoughts on the role that synthetic data\n"}
{"pod": "Lex Fridman Podcast", "input": "Data", "output": "and game engines will play in the future of neural net model development? - I think as neural nets converge to humans,\nthe value of simulation to neural nets will be similar to value of simulation to humans.\nSo people use simulation because they can learn something in that kind of a system and without having\nto actually experience it. - But you're referring to the simulation we do in our head? Isn't that what thinking is?\n- Oh no, sorry. Simulation, I mean like video games or other forms of simulation for various professionals.\n- Well, so let me push back on that 'cause maybe there's simulation that we do in our heads, like simulate if I do this, what do I think will happen?\n- [Andrej] Okay. That's like internal simulation. - Yeah, internal. Isn't that what we're doing? Assuming before we act. - Oh, yeah.\nBut that's independent from the use of simulation in the sense of computer games, or using simulation for training set creation, or something.\n- Is it independent or is it just loosely correlated? 'Cause isn't that useful to do counterfactual\nor edge case simulation to what happens if there's a nuclear war?\nWhat happens if there's, like those kinds of things? - Yeah. That's a different simulation from Unreal Engine.\nThat's how I interpreted the question. - Ah, so like simulation of the average case?\nWhat's Unreal Engine? What do you mean by Unreal Engine? So simulating a world.\n- [Andrej] Yeah. - The physics of that world, Why is that different? 'Cause you also can add behavior to that world\nand you could try all kinds of stuff, right? You could throw all kinds of weird things into it.\n- [Andrej] Yeah. - Unreal Engine is not just about simulating, I mean I guess it is about simulating the physics of the world,\nit's also doing something with that. - Yeah. The graphics, the physics, and the agents\nthat you put into the environment and stuff like that. Yeah. - I feel like you said that it's not that important,\nI guess, for the future of AI development. Is that correct, to interpret you that way? - Well, I think, humans use simulators\nand they find them useful and so computers will use simulators and find them useful. - Okay, so you're saying it's not,\nI don't use simulators very often. I play a video game every once in a while but I don't think I derive any wisdom\nabout my own existence from those video games. It's a momentary escape from reality\nversus a source of wisdom about reality. So I think that's a very polite way of saying\nsimulation is not that useful. - Yeah. Maybe not. I don't see it as a fundamental, really important part\nof training neural nets currently. But I think as neural nets become more and more powerful,\nI think you will need fewer examples to train additional behaviors. And simulation is, of course, there's a domain gap\nin a simulation that's not the real-world, it's slightly something different. But with a powerful enough neural net\nyou need the domain gap can be bigger I think because neural net will understand that even though it's not the real-world,\nit has all this high-level structure that I'm supposed to learn from. - So the neural net will actually, yeah,\nit will be able to leverage the synthetic data better? - [Andrej] Yes.\n- By closing the gap but understanding in which ways this is not real data? - [Andrej] Exactly.\n- Reddit do better questions next time. That was a question. No, I'm just kidding. All right, so is it possible, do you think,\nspeaking of EMNIST to construct neural nets and training processes that require very little data.\nSo we've been talking about huge data sets like the internet for training. - [Andrej] Yeah. - I mean one way to say that is like you said,\nthe querying itself is another level of training I guess and that requires a little data.\n- [Andrej] Yeah. - But do you see any value in doing research\nand going down the direction of can we use very little data to construct a knowledge base?\n- A hundred percent. I just think at some point you need a massive data set and then when you pre-train your massive neural net\nand get something that is like a GPT or something, then you're able to be very efficient\nat training any arbitrary new task. So a lot of these GPTs you can do tasks\nlike sentiment analysis, or translation, or so on, just by being prompted with very few examples. Here's the kind of thing I want you to do.\nLike here's an input sentence, here's the translation into German, input sentence, translation to German, input sentence, blank, and the neural net\nwill complete the translation to German just by looking at the example you've provided. And so that's an example of a very few shot learning\nin the activations of the neural net, instead of the weights of the neural net. And so I think basically just like humans,\nneural nets will become very data efficient at learning any other new task. But at some point, you need a massive data set\nto pre-train your network. - I do get that. And probably, we humans have something like that.\nDo we have something like that? Do we have a passive in the background,\nbackground model constructing thing that just runs all the time in a self-supervised way?\nWe're not conscious of it? - I think humans definitely, I mean obviously, we learn a lot during our lifespan,\nbut also we have a ton of hardware that helps us, the initialization coming from evolution.\nAnd so I think that's also a really big component. A lot of people in the field, I think they just talk about the amounts of like seconds\nthat a person has lived, pretending that this is a tabula rasa, a zero initialization of a neural net.\nAnd it's not. You can look at a lot of animals for example, zebras. Zebras get born, and they see, and they can run,\nthere's zero training data in their lifespan. They can just do that. So somehow, I have no idea how, evolution has found a way\nto encode these algorithms and these neural net initializations that are extremely good into ATCGs.\nAnd I have no idea how this works, but apparently, it's possible because here's proof by existence.\n- There's something magical about going from a single-cell to an organism that is born\nto the first few years of life. I like the idea that the reason we don't remember anything about the first few years of our life\nis that it's a really painful process. Like it's a very difficult challenging training process.\n- [Andrej] Yeah. - Like intellectually and maybe, yeah, I mean I don't, why don't we remember any of that?\nThat might be some crazy training going on and maybe that's the background model training\nthat is very painful. - [Andrej] Yeah. - And so it's best for the system once it's trained\nnot to remember how it was constructed. - I think it's just like the hardware for long-term memory is just not fully developed.\n- [Lex] Sure. - I feel like the first few years of infants, it's not actually like learning, it's brain maturing.\n- [Lex] Yeah. - We're born premature and there's a theory along those lines because of the birth canal\nand the swelling of the brain. And so we're born premature and then the first few years we're just, the brain's maturing\nand then there's some learning eventually. It's my current view on it. - What do you think, do you think neural nets\ncan have long-term memory? Like that approach is something like humans?\nDo you think there needs to be another meta-architecture on top of it to add something like a knowledge base\nthat learns facts about the world and all that kind of stuff? - Yes, but I don't know to what extent it will be explicitly constructed.\nIt might take on intuitive forms where you are telling the GPT, hey, you have a declarative memory bank\nto which you can store and retrieve data from and whenever you encounter some information that you find useful just save it to your memory bank.\nAnd here's an example of something you have retrieved and here's how you say it and here's how you load from it. You just say, load whatever, you teach it in text,\nin English and then it might learn to use a memory bank from that. - Oh, so the neural net is the architecture\nfor the background model, the base thing and then everything else is just on top of it. - It's not just a text, right?\nYou're giving it gadgets and gizmos. So you're teaching it some kind of a special language by which it can save arbitrary information\nand retrieve it at a later time. - [Lex] Yeah. - And you're telling about these special tokens and how to arrange them to use these interfaces.\nIt's like, hey, you can use a calculator, here's how you use it. Just do five three plus four one equals\nand when equals is there, a calculator will actually read out the answer and you don't have to calculate it yourself\nand you just tell it in English, this might actually work. - Do you think in that sense Gato is interesting,\nthe DeepMind system that it's not just new language but actually throws it all in the same pile,\nimages, actions, all that kind of stuff. That's basically what we're moving towards.\n- Yeah, I think so. So Gato is very much a kitchen sink of an approach to reinforcement learning in lots of different environments\nwith a single fixed transformer model. Right? I think it's a very early result in that realm.\nBut I think, yeah, it's along the lines of what I think things will eventually look like. - Right. So this is the early days of a system\nthat eventually will look like this, from a Rich Sutton perspective. - Yeah. I'm not a super huge fan of, I think all these interfaces\nthat like look very different. I would want everything to be normalized into the same API.\nSo for example, screen pixels, very same API instead of having like different world environments that have very different physics and joint configurations\nand appearances and whatever. And you're having some kind of special tokens for different games that you can plug.\nI'd rather just normalize everything to a single interface so it looks the same to the neural net if that makes sense.\n- So it's all gonna be pixel-based Pong in the end? - [Andrej] I think so.\n- Okay. Let me ask you about your own personal life.\n"}
{"pod": "Lex Fridman Podcast", "input": "Day in the life", "output": "A lot of people wanna know you're one of the most productive and brilliant people in the history of AI. What is a productive day in the life\nof Andrej Karpathy look like? What time do you wake up? 'Cause imagine some kind of dance between\nthe average productive day and a perfect productive day. So the perfect productive day is the thing we strive towards\nand the average is kind of what it converges to, given all the mistakes and human eventualities and so on.\n- [Andrej] Yep. - So what time did you wake up? Are you a morning person? - I'm not a morning person. I'm a night owl, for sure.\n- Is it stable or not? - It's semi-stable like eight or nine or something like that.\nDuring my PhD, it was even later, I used to go to sleep usually at 3:00 AM, I think the AM hours are precious\nand a very interesting time to work because everyone is asleep. At 8:00 AM or 7:00 AM the east coast is awake.\nSo there's already activity, there's already some text messages, whatever. There's stuff happening. You can go on some news website\nand there's stuff happening, it's distracting. At 3:00 AM everything is totally quiet and so you're not gonna be bothered\nand you have solid chunks of time to do work. So I like those periods, night owl by default.\nAnd then I think productive time, basically, what I like to do is you need to build\nsome momentum on the problem without too much distraction and you need to load your ram, your working memory\nwith that problem. And then you need to be obsessed with it when you're taking shower, when you're falling asleep,\nyou need to be obsessed with the problem and it's fully in your memory and you're ready to wake up and work on it right there. - So is this in a scale temporal scales of a single day\nor a couple of days a week, a month? - Yeah. So I can't talk about one day, basically, in isolation because it's a whole process.\nWhen I wanna get productive in the problem, I feel like I need a span of a few days where I can really get in on that problem\nand I don't wanna be interrupted and I'm going to just be completely obsessed with that problem. And that's where I do most of my good work, I would say.\n- You've done a bunch of cool, like little projects in a very short amount of time, very quickly, so that requires you just focusing on it.\n- Yeah, basically, I need to load my working memory with the problem and I need to be productive because there's always a huge fixed cost\nto approaching any problem. I was struggling with this for example at Tesla because I want to work on small side project, but okay,\nyou first need to figure out, oh, okay, I need to associate into my cluster, I need to bring up a VS Code editor so I can work on this.\nI ran into some stupid error because of some reason. You're not at a point where you can be just productive right away.\nYou are facing barriers. And so it's about really removing all of that barrier\nand you're able to go into the problem and you have the full problem loaded in your memory. - And somehow avoiding distractions of all different forms.\n- [Andrej] Yes. - Like news stories, emails, but also distractions\nfrom other interesting projects that you previously worked on or currently working on and so on. You just wanna really focus your mind.\n- Yeah. And I mean I can take some time off for distractions and in between, but I think it can't be too much.\nMost of your day is sort of spent on that problem. And then, I drink coffee, I have my morning routine,\nI look at some news, Twitter, Hacker News, Wall Street Journal, et cetera. It's great.\n- So basically, you wake up, you have some coffee, are you trying to get to work as quickly as possible? Do you take in this diet of what the hell's happening\nin the world first? - I do find it interesting to know about the world. I don't know that it's useful or good,\nbut it is part of my routine right now. So I do read through a bunch of news articles and I wanna be informed and I'm suspicious of it.\nI'm suspicious of the practice, but currently, that's where I am. - Oh, you mean suspicious about the positive effect?\n- [Andrej] Yeah. - Of that practice on your productivity and your well-being? - My well-being, psychologically, yeah.\n- And also on your ability to deeply understand the world because there's a bunch of sources of information\nyou're not really focused on deeply integrating it. - Yeah, it's a little bit distracting. Yeah. - In terms of a perfectly productive day\nfor how long of a stretch of time in one session do you try to work and focus on a thing?\nIs it a couple hours, is it one hour, is it 30 minutes? Is it 10 minutes? - I can probably go a small few hours\nand then I need some breaks in between for food and stuff and yeah.\nBut I think, it's still really hard to accumulate hours. I was using a tracker that told me exactly how much time\nI spent coding any one day. And even on a very productive day, I still spent only six or eight hours.\n- [Lex] Yeah. - And it's just because there's so much padding, commute, talking to people, food, et cetera.\nThere's a cost of life just living and sustaining and homeostasis and just maintaining yourself\nas a human is very high. - And there seems to be a desire within the human mind\nto participate in society that creates that padding. - [Andrej] Yeah. - 'Cause the most productive days I've ever had\nis just completely from start to finish is tuning out everything. - [Andrej] Yep. - And just sitting there and then you could do more\nthan six in eight hours. - Yep. - Is there some wisdom about what gives you strength to do tough days of long focus?\n- Yeah, just whenever I get obsessed about a problem, something just needs to work. Something just needs to exist. - It needs to exist.\nSo you're able to deal with bugs and programming issues and technical issues and design decisions\nthat turn out to be the wrong ones. You're able to think through all of that given that you want a thing to exist. - Yeah, it needs to exist.\nAnd then I think to me also a big factor is, are other humans are going to appreciate it? Are they going to like it?\nThat's a big part of my motivation. If I'm helping humans and they seem happy, they say nice things, they Tweet about it or whatever,\nthat gives me pleasure because I'm doing something useful. - So you do see yourself sharing it with the world?\nWith GitHub, with the blog post or through videos? - Yeah, I was thinking about it like, suppose I did all these things but did not share them.\nI don't think I would have the same amount of motivation that I can build up. - You enjoy the feeling of other people gaining value\nand happiness from the stuff you've created. - [Andrej] Yeah. - What about diet?\nI saw you played with intermittent fasting. Do you fast? Does that help? - I play with everything.\n- With the things you played, what's been most beneficial to your ability to mentally focus on a thing\nand just mental productivity and happiness? You still fast? - Yeah.\nI still fast but I do intermittent fasting but really what it means at the end of the day is I skip breakfast. - [Lex] Yeah. - So I do 18/6 roughly by default\nwhen I'm in my steady state, if I'm traveling or doing something else I will break the rules. But in my steady state, I do 18/6.\nSo I eat only from 12:00 to 6:00. Not a hard rule and I break it often, but that's my default. And then, yeah, I've done a bunch of random experiments\nfor the most part right now where I've been for the last year and a half I wanna say is I'm plant-based or plant-forward.\nI heard plant-forward, it sounds better. - [Lex] What does that mean exactly? - I don't actually know what the difference is, but it sounds better in my mind. But it just means I prefer plant-based food and-\n- Raw or cooked. - I prefer cooked and plant-based. - So plant-based, forgive me,\nI don't actually know how wide the category of plant entails. - Well, plant-based just means\nthat you're not militant about it and you can flex and you just prefer to eat plants and you're not making,\nyou're not trying to influence other people. And you come to someone's house party and they serve you a steak that they're really proud of,\nyou will eat it. - Yes. Right. You're not judgmental. That's beautiful. I mean, I'm the flip side of that,\nbut I'm very sort of flexible. Have you tried doing one meal a day? - I have accidentally but not consistently,\nbut I've accidentally had that. I don't like it. I think it makes me feel not good. It's too much of a hit.\n- [Lex] Yeah. - And so currently I have about two meals a day, 12:00 and 6:00, probably. - I do that nonstop.\nI'm doing it now. I do one meal a day. - [Andrej] Okay. - It's interesting. It's an interesting feeling.\nHave you ever fasted longer than a day? - Yeah, I've done a bunch of water fasts. 'Cause I was curious what happens. - [Lex] What happens, anything interesting?\n- Yeah, I would say so. I mean, what's interesting is that you're hungry for two days and then starting day three or so,\nyou're not hungry. It's such a weird feeling because you haven't eaten in a few days and you're not hungry.\n- Yeah, isn't that weird? - [Andrej] It's really weird. - One of the many weird things about human biology. - [Andrej] Yeah.\n- It figures something out, it finds another source of energy or something like that. Or relaxes the system.\nI don't know how it works. - Yeah, the body is like, \"You're hungry, you're hungry.\" And then it just gives up. It's like, \"Okay, I guess we're fasting now.\" There's nothing.\nAnd then it's just focuses on trying to make you not hungry and not feel the damage of that and trying to give you\nsome space to figure out the food situation. - So are you still to this day most productive at night?\n- I would say I am, but it is really hard to maintain my PhD schedule.\nEspecially, when I was say working at Tesla and so on. It's a non-starter. But even now, people want to meet for various events.\nSociety lives in a certain period of time. - [Lex] Yeah. - And you have to work with that. - It's hard to do a social thing\nand then after that return and do work. - Yeah. It's just really hard.\n- That's why I try, when I do social thing, I try not to do too much drinking so I can return and continue doing work.\n- [Andrej] Yeah. - But at Tesla is there conversions, not Tesla,\nbut any company, is there a convergence to always a schedule or is that how humans behave when they collaborate?\nI need to learn about this? - [Andrej] Yeah. - Do they try to keep a consistent schedule where you're all awake at the same time? - I mean, I do try to create a routine\nand I try to create a steady state in which I'm comfortable in. So I have a morning routine, I have a day routine.\nI try to keep things to a steady state and things are predictable and then your body just sticks to that.\nAnd if you try to stress that a little too much, it will create, when you're traveling and you're dealing with jet lag, you're not able to really ascend to where you need to go.\n- Yeah. Yeah. That's weird too about us humans with the habits and stuff. What are your thoughts on work-life balance\nthroughout a human lifetime? So Tesla in part was known for pushing people\nto their limits, in terms of what they're able to do, in terms of what they're trying to do,\nin terms of how much they work, all that kind of stuff. - Yeah, I mean I will say Tesla gets a little too much bad rep for this\nbecause what's happening is Tesla, it's a bursty environment. So I would say the baseline,\nmy only point of reference is Google where I've interned three times and I saw what it's like inside Google and DeepMind,\nI would say the baseline is higher than that. But then there's a punctual equilibrium where once in a while there's a fire\nand people work really hard and so it's spiky and bursty and then all the stories get collected-\n- [Lex] Above the bursts. Yeah. - And then it gives the appearance of total insanity. But actually, it's just a bit more intense environment\nand there are fires and sprints and so I think definitely though I would say\nit's a more intense environment than something you would get at Google. - But in your personal, forget all of that, just in your own personal life,\nwhat do you think about the happiness of a human being? A brilliant person like yourself.\nabout finding a balance between work and life or is such a thing not a good thought experiment?\n- Yeah, I think balance is good but I also love to have sprints that are out of distribution\nand that's when I think I've been pretty creative as well.\n- So sprints out of distribution means that most of the time you have a quote-unquote balance.\n- I have balance most of the time and I like being obsessed with something once in a while. - Once in a while is what, once a week,\nonce a month, once a year? - Yeah. Probably I'd like say once a month or something. Yeah. - And that's when we get and you get Git-Repo for market.\n- Yeah. That's when you're like really care about a problem, it must exist. This will be awesome. You're obsessed with it and now you can't just do it\non that day, you need to pay the fixed cost of getting into the groove. - [Lex] Yeah. - And then you need to stay there for a while\nand then society will come and they will try to mess with you and they will try to distract you. - [Lex] Yeah. - Yeah.\nThe worst thing is a person who's like, \"I just need five minutes of your time.\" - [Lex] Yeah. - The cost of that is not five minutes.\n- [Lex] Yes. - And society needs to change how it thinks about just five minutes of your time.\n- Right. It's never just one minute, just 30. Just a quick thing. - [Andrej] What's the big deal?\nWhy are you being, so? - Yeah, no. What's your computer setup?\nWhat's like the perfect- Are you somebody that's flexible to no matter what laptop, four screens?\n- [Andrej] Yeah. - Or do you prefer a certain setup that you're most productive with?\n- I guess the one that I'm familiar with is one large screen, 27-inch and my laptop on the side.\n- What operating system? - I do MaX, that's my primary. - For all tasks? - I would say OS X.\nBut when you're working on deep-learning, everything is Linux, you're SSH into a cluster and you're working remotely. - But what about the actual development?\nLike using the IDE? - Yeah. You would use, I think a good way is you just run VS Code,\nmy favorite editor right now on your Mac. But you are actually, you have a remote folder through SSH.\nSo the actual files that you're manipulating are on a cluster somewhere else. - So what's the best IDE, VS Code?\n"}
{"pod": "Lex Fridman Podcast", "input": "Best IDE", "output": "What else do people use? So I use Emax, still. - That's old school.\n- It may be cool, I don't know if it's maximum productivity. So what do you recommend in terms of editors?\nYou worked with a lot of software engineers, editors for Python, C++, machine learning applications.\n- I think the current answer is VS Code, currently, I believe that's the best IDE.\nIt's got a huge amount of extensions. It has GitHub Copilot integration,\nwhich I think is very valuable. - What do you think about the Copilot integration? I got to talk a bunch with Guido van Rossum\nwho's the creator of Python and he loves Copilot, he programs a lot with it.\n- [Andrej] Yeah. - Do you? - Yeah, I use Copilot. I love it. And it's free for me but I would pay for it.\nYeah. I think it's very good. And the utility that I found with it was, I would say there's a learning curve\nand you need to figure out when it's helpful and when to pay attention to its outputs and when it's not going to be helpful\nwhere you should not pay attention to it. Because if you're just reading its suggestions all the time, it's not a good way of interacting with it.\nBut I think I was able to sort of mold myself to it. I find it's very helpful, number one, in copy-paste\nand replace some parts. So when the pattern is clear, it's really good at completing the pattern.\nAnd number two, sometimes it suggests APIs that I'm not aware of. So it tells you about something that you didn't know.\n- And that's an opportunity to discover a new thing. - It's an opportunity to. So I would never take Copilot code as given.\nI almost always copy-paste into a Google search and you see what this function is doing and then you're like, \"Oh, that's actually exactly\nwhat I need.\" Thank you, Copilot. So you learn something. - So it's in part of search engine, in part maybe getting the exact syntax correctly\nthat once you see it, it's that MPR thing. Once you see it, you know it's correct.\n- [Andrej] Yes, exactly. Exactly. - You, yourself can struggle. - [Andrej] You can verify. - You can verify efficiently but you can't generate efficiently.\n- And Copilot really, I mean it's autopilot for programming. Right? And currently is doing the link following\nwhich is the simple copy-paste and sometimes suggest, but over time it's going to become more and more autonomous.\nAnd so the same thing will play out in not just coding but actually across many, many different things probably.\n- But coding is an important one, right? - [Andrej] Very. - Like writing programs. - [Andrej] Yeah. - How do you see the future of that developing\nthe program synthesis, like being able to write programs that are more and more complicated? 'Cause right now it's human-supervised in interesting ways.\n- [Andrej] Yes. - It feels like the transition will be very painful. - My mental model for it is the same thing will happen\nas with the autopilot. So currently, he's doing lane following, he is doing some simple stuff, and eventually,\nwe'll be doing autonomy and people will have to intervene less and less. And those could be like testing mechanisms.\nIf it writes a function and that function looks pretty damn correct. But how do you know it's correct\n'cause you're like getting lazier and lazier as a programmer, your ability to, 'cause like little bugs\nbut I guess it won't make little mistakes. - No it will, Copilot will make off by one subtle bug.\nIt has done that to me. - But do you think future systems will or is it really the off by one\nis actually a fundamental challenge of programming. - In that case it wasn't fundamental and I think things can improve but yeah,\nI think humans have to supervise. I am nervous about people not supervising what comes out and what happens to, for example,\nthe proliferation of bugs in all of our systems. I'm nervous about that but I think there will probably be\nsome other Copilots for bug finding and stuff like that, at some point. 'Cause there'll be a lot more automation for-\n- Oh man, a Copilot that generates a compiler,\none that does a linter. - [Andrej] Yes. - One that does like a type checker. - Yeah.\nIt's a committee of a GPT sort of like- - And then there'll be like a manager for the committee. - [Andrej] Yeah.\n- And then there'll be somebody that says, a new version of this is needed. We need to regenerate it. - Yeah. There were 10 GPTs that were forwarded\nand gave 50 suggestions. Another one looked at it and picked a few that they like, a bug one looked at it\nand it was like, it's probably a bug, they got re-ranked by some other thing and then a final ensemble GPT comes in\nand is like, okay, given everything you guys have told me, this is probably the next token. - You know the feeling is the number of programmers\nin the world has been growing and growing very quickly. - [Andrej] Yeah. - Do you think it's possible that it'll actually level out and drop to a very low number in this kind of world?\n'Cause then you'll be doing Software 2.0 programming and you'll be doing this generation\nof Copilot-type systems programming. But you won't be doing the old school\nSoftware 1.0 programming. - I don't currently think that they're just going to replace human programmers.\nI'm so hesitant saying stuff like this, right? - Yeah. Because this is gonna be replayed in five years and no,\nit's going to show that like this is where we thought, because I agree with you but I think we might be very surprised, right?\nWhat's your sense of where we stand with language models? Does it feel like the beginning, or the middle, or the end? - The beginning, a hundred percent.\nI think the big question in my mind is for sure GPT will be able to program quite well, competently and so on. - [Lex] Yeah.\n- How do you steer the system? You still have to provide some guidance to what you actually are looking for. And so how do you steer it and how do you say,\nhow do you talk to it? How do you audit it and verify that what it's done is correct\nand how do you work with this? And it's as much not just an AI problem but a UI, UX problem.\n- [Lex] Yeah. - So beautiful fertile ground for so much interesting work\nfor VS Code++ where you're not just, it's not just human programming anymore. It's amazing. - Yeah.\nSo you're interacting with the system so not just one prompt but it's iterative prompting. - [Andrej] Yeah.\n- You're trying to figure out, having a conversation with the system. - [Andrej] Yeah. - That actually, I mean to me that's super exciting to have a conversation with the program I'm writing.\n- Yeah. Yeah. Maybe at some point you're just conversing with it. It's like, okay, here's what I wanna do, actually this variable.\nMaybe it's not even that low-level as a variable, but. - You can also imagine like can you translate\nthis to C++ and back to Python and back to? - Yeah, that already kind of exists in some way. - No, but just like doing it as part\nof the program experience. Like I think I'd like to write this function in C++\nor you just keep changing from different programs 'cause of the different syntax,\nmaybe I want to convert this into a functional language. - [Andrej] Yeah. - And so you get to become multilingual as a programmer\nand dance back and forth efficiently. - Yeah. I mean I think the UI, UX of it though is still very hard to think through.\n- [Lex] Yeah. - Because it's not just about writing code on a page. You have an entire developer environment, you have a bunch of hardware on it,\nyou have some environmental variables, you have some scripts that are running in a Chrome job. There's a lot going on to working with computers\nand how do these systems set up environment flags, and work across multiple machines,\nand set up screen sessions, and automate different processes. like how all that works and is auditable by humans and so on\nis like massive question at the moment. - You've built arxiv-sanity. What is arxiv and what is the future\n"}
{"pod": "Lex Fridman Podcast", "input": "arXiv", "output": "of academic research publishing that you would like to see? - So arxiv is this pre-print server.\nSo if you have a paper you can submit it for publication to journals or conferences and then wait six months\nand then maybe get a decision pass or fail, or you can just upload it to arxiv and then people can Tweet about it three minutes later.\nAnd then everyone sees it, everyone reads it, and everyone can profit from it in their own little ways. - And you can cite it and it has an official look to it.\nIt feels like a publication process. - [Andrej] Yeah. - It feels different than if you just put in a blog post.\n- Oh, yeah. Yeah. I mean it's a paper and usually the bar is higher for something that you would expect on arxiv\nas opposed to something you would see in a blog post. - Well, the culture created the bar 'cause you could probably post\na pretty crappy paper or an arxiv. - [Andrej] Yes. - So what's that make you feel like, what's that make you feel about peer review?\nSo rigorous peer review by two, three experts versus the peer review of the community right\nas it's written? - Yeah. Basically, I think the community is very well able to peer-review things very quickly on Twitter.\nAnd I think maybe it just has to do something with AI machine learning field specifically though, I feel like things are more easily auditable\nand the verification is easier potentially than the verification somewhere else.\nSo it's like, you can think of these scientific publications as little block-chains where everyone's building on each other's work\nand citing each other and you sort of have AI, which is this much faster and loose blockchain,\nbut then you have, and any one individual entry is very cheap to make.\nAnd then you have other fields where maybe that model doesn't make as much sense. And so I think in AI at least\nthings are pretty easily verifiable. And so that's why when people upload papers, they have a really good idea and so on.\nPeople can try it out the next day and they can be the final arbiter of whether it works or not on their problem.\nAnd the whole thing just moves significantly faster. So I feel like academia still has a place, sorry, this conference, journal process still has a place,\nbut it's sort of it lags behind I think, and it's a bit more maybe higher quality process.\nBut it's not the place where you will discover cutting-edge work anymore. - [Lex] Yeah. - It used to be the case when I was starting my PhD\nthat you go to conferences and journals and you discuss all the latest research. Now when you go to a conference or a journal,\nno one discusses anything that's there because it's already like three generations ago, irrelevant. - Yes.\nWhich makes me sad about like DeepMind for example, where they still publish in nature and these big prestigious, I mean there's still value,\nI suppose to the prestige that comes with these big venues. - [Andrej] Yeah. - But the result is that they'll announce\nsome breakthrough performance and it'll take like a year to actually publish the details.\nI mean, and those details, if they were published immediately would inspire the community to move in certain directions, would they?\n- Yeah. It would speed up the rest of the community, but I don't know to what extent that's part of their objective function also.\n- That's true. So it's not just the prestige. A little bit of the delay is part. - Yeah, they certainly, DeepMind specifically,\nhas been working in the regime of having slightly higher quality basically process\nand latency and publishing those papers that way. - Another question from Reddit.\nDo you or have you suffered from imposter syndrome, being the director of AI Tesla, being this person\nwhen you're at Stanford where the world looks at you as the expert in AI to teach the world\nabout machine learning. - When I was leaving Tesla after five years, I spent a ton of time in meeting rooms\nand I would read papers. In the beginning, when I joined Tesla, I was writing code and then I was writing less and less code, and I was reading code and then I was reading\nless and less code. And so this is just a natural progression that happens I think. And definitely, I would say near the tail end,\nthat's when it starts to hit you a bit more. That you're supposed to be an expert but actually, the source of truth is the code\nthat people are writing, the GitHub and the actual code itself. And you're not as familiar with that as you used to be.\nAnd so I would say maybe there's some insecurity there. - Yeah, that's actually pretty profound, that a lot of the insecurity has to do\nwith not writing the code in the computer science space 'cause that is the truth. That right there.\n- The code is the source of truth. The papers and everything else, it's a high-level summary. I don't, yeah, just a high-level summary,\nbut at the end of the day you have to read code. It's impossible to translate all that code into actual paper form.\nSo when things come out, especially when they have a source code available, that's my favorite place to go. - So like I said, you're one of the greatest teachers\n"}
{"pod": "Lex Fridman Podcast", "input": "Advice for beginners", "output": "of machine learning AI ever from CS231n to today,\nwhat advice would you give to beginners interested in getting into machine learning? - Beginners are often focused on what to do\nand I think the focus should be more how much you do. So I am a believer on the high-level, in this 10,000 hours concept where you just have to\njust pick the things where you can spend time and you care about and you're interested in. You literally have to put in 10,000 hours of work.\nIt doesn't even matter as much where you put it, you'll iterate and you'll improve and you'll waste some time.\nI dunno if there's a better way. You need to put in 10,000 hours. But I think it's actually really nice 'cause I feel like there's some sense of determinism\nabout being an expert at a thing if you spend 10,000 hours. you can literally pick an arbitrary thing\nand I think if you spend 10,000 hours of deliberate effort and work, you actually will become an expert at it.\nAnd so I think it's like a nice thought. And so basically I would focus more on\nare you spending 10,000 hours? That's what I would focus on. - And then thinking about what kind of mechanisms maximize\nyour likelihood of getting to 10,000 hours. - [Andrej] Yes, exactly. - Which for us silly humans means probably forming\na daily habit of every single day actually doing thing. - Whatever helps you. So I do think to a large extent\nit's a psychological problem for yourself. - [Lex] Yeah. - One other thing that I think is helpful for the psychology of it,\nis many times people compare themselves to others in the area, I think this very harmful. Only compare yourself to you from some time ago.\nLike say a year ago, are you better than you a year ago? This is the only way to think.\nAnd I think then you can see your progress and it's very motivating. - That's so interesting. That focus on the quantity of hours.\n'Cause I think a lot of people in the beginner stage but actually throughout get paralyzed by the choice.\n- [Andrej] Yeah. - Like which one do I pick this path or this path? - [Andrej] Yeah. - They'll literally get paralyzed by which IDE to use?\n- Well, they're worried, yeah, they'll worried about all these things. But the thing is, you will waste time doing something wrong.\n- [Lex] Yes. - You will eventually figure out it's not right. You will accumulate scar tissue and next time you'll grow stronger\nbecause next time you'll have the scar tissue, and next time you'll learn from it. And now next time you come to a similar situation\nyou'll be like, oh, I messed up. I've spent a lot of time working on things that never materialized into anything\nand I have all that scar tissue and I have some intuitions about what was useful, what wasn't useful, how things turned out.\nSo all those mistakes were not dead work. So I just think they should just focus on working.\nWhat have you done, what have you done last week? - That's a good question actually\nto ask for a lot of things, not just machine learning. It's a good way to cut the, I forgot the term we use,\nbut the fluff, the blubber, whatever the inefficiencies in life.\nWhat do you love about teaching? You seem to find yourself often in the, drawn to teaching.\nYou're very good at it but you're also drawn to it. - Yeah, I mean I don't think I love teaching. I love happy humans and happy humans like when I teach.\n- Yes. - I wouldn't say I hate teaching, I tolerate teaching. - [Lex] Yes. - But it's not like the act of teaching that I like,\nit's that I have something, I'm actually okay at it.\n- [Lex] Yes. - I'm okay at teaching and people appreciate it a lot. - [Lex] Yeah. - And so I'm just happy to try to be helpful\nand teaching itself is not like the most, I mean it can be really annoying, frustrating.\nI was working on a bunch of lectures just now. I was reminded back to my days of 231n just how much work it is to create some of these materials\nand make them good. The amount of iteration and thought and you go down blind alleys and just how much you change it.\nSo creating something good in terms of educational value is really hard and it's not fun.\n- It's difficult. So people should definitely go watch your new stuff you put out. There are lectures where you're actually building the thing,\nlike you said, \"The code is truth.\" So discussing back-propagation by building it,\nby looking through and just the whole thing. - [Andrej] Yeah. - So how difficult is that to prepare for? I think that's a really powerful way to teach.\nDid you have to prepare for that or are you just live thinking through it? - I will typically do like say three takes\nand then I take the better take. So I do multiple takes and I take some of the better takes and then I just build out a lecture that way.\nSometimes I have to delete 30 minutes of content. - [Lex] Yeah. - Because it just went down the alley that I didn't like too much. So there's about a bunch of iteration\nand it probably takes me somewhere around 10 hours to create one hour of content. - To get one hour.\nIt's interesting. I mean is it difficult to go back to the basics? Do you draw a lot of wisdom from going back to the basics?\n- Yeah, going back to backropagation, loss functions, where they come from. And one thing I like about teaching a lot honestly is\nit definitely strengthens your understanding. So it's not a purely altruistic activity, it's a way to learn.\nIf you have to explain something to someone, you realize you have gaps in knowledge.\nAnd so I even surprised myself in those lectures like, well, the result will obviously look like this\nand then the result doesn't look like it. And I'm like, okay, I thought I understood this. - Yeah.\nWell, that's why it's really cool, they literally code, you run it in the notebook and it gives you a result\nand you're like, oh, wow. - [Andrej] Yes. - And like actual numbers, actual input, actual code. - Yeah.\nIt's not mathematical symbols, et cetera. The source of truth is the code. It's not slides, it's just like let's build it.\n- It's beautiful. You're a rare human in that sense. What advice would you give to researchers\ntrying to develop and publish an idea that have a big impact in the world of AI?\nSo maybe undergrads, maybe early-graduate students. - Yeah.\nI mean I would say they definitely have to be a little bit more strategic than I had to be as a PhD student because of the way AI is evolving,\nit's going the way of physics. Where in physics you used to be able to do experiments on your bench-top and everything was great\nand you could make progress and now you have to work in like LHC or like CERN and so AI\nis going in that direction as well. So there's certain kinds of things that's just not possible to do on the bench-top anymore.\nAnd I think that didn't used to be the case at the time. - Do you still think that there's like GAN type papers\nto be written where like very simple idea. - [Andrej] Yes. - That requires just one computer\nto illustrate a simple example? - I mean one example that's been very influential recently is diffusion models, diffusion models are amazing.\nDiffusion models are six years old. For the longest time, people were ignoring them as far as I can tell.\nAnd they're an amazing generative model, especially in images and so stable diffusion and so on,\nit's all diffusion-based. Diffusion is new, it was not there and it came from, well, it came from Google but a researcher\ncould have come up with it. In fact, some of the first, actually no, those came from Google as well.\nBut a researcher could come up with that in an academic institution. - Yeah. What do you find most fascinating about diffusion models?\nSo from the societal impact of the technical architecture. - What I like about diffusion is it works so well.\n- Is that surprising to you? The amount of the variety, almost the novelty of the synthetic data it's generating?\n- Yeah, so the stable diffusion images are incredible. It's the speed of improvement in generating images\nhas been insane. We went very quickly from generating tiny digits to tiny faces and it all looked messed up.\nAnd now we have stable diffusion and that happened very quickly. There's a lot that academia can still contribute. For example, FlashAttention is a very efficient kernel\nfor running the attention operation inside the transformer that came from academic environment.\nIt's a very clever way to structure the kernel, that's the calculation. So it doesn't materialize the attention matrix.\nAnd so, I think there's still like lots of things to contribute but you have to be just more strategic. - Do you think neural networks could be made to reason?\n- Yes. - Do you think they already reason? - Yes. - [Lex] What's your definition of reasoning?\n- Information processing. - So in the way that humans think through a problem\nand come up with novel ideas, it feels like a reasoning.\n- Yeah. - So the novelty, I don't wanna say but auto-distribution ideas, you think it's possible?\n- Yes. And I think we're seeing that already in the current neural nets. You're able to remix the training set information\ninto true generalization in some sense. - That doesn't appear- - It doesn't appear verbatim in the training set.\nYou're doing something interesting algorithmically, you're manipulating some symbols and you're coming up with some correct unique answer\nin a new setting. - What would illustrate to you, holy shit,\nthis thing is definitely thinking? - To me thinking or reasoning is just information processing and generalization.\nAnd I think the neural nets already do that today. - So being able to perceive the world or perceive the, whatever the inputs are\nand to make predictions based on that or actions based on that's reasoning?\n- Yeah. You're giving correct answers in novel settings by manipulating information.\nYou've learned the correct algorithm, you're not doing just some kind of a lookup table and nearest neighbor search. Something like that.\n"}
{"pod": "Lex Fridman Podcast", "input": "Artificial general intelligence", "output": "- Let me ask you about AGI. What are some moonshot ideas you think might make significant progress towards AGI\nand maybe another way is, what are the big blockers that we're missing now? - So basically, I am fairly bullish on our ability\nto build AGIs, basically automated systems that we can interact with that are very human-like\nand we can interact with them in a digital realm or a physical realm. Currently, it seems most of the models\nthat do these magical tasks are in a text realm.\nI think, as I mentioned, I'm suspicious that text realm is not enough to actually build full understanding\nof the world. I do actually think you need to go into pixels and understand the physical world and how it works.\nSo I do think that we need to extend these models to consume images and videos and train on a lot more data\nthat is multimodal in that way. - Do you think you need to touch the world to understand it also? - Well, that's the big open question\nI would say in my mind, is if you also require the embodiment and the ability to interact with the world,\nrun experiments and have a data of that form, then you need to go to Optimus or something like that.\n- [Lex] Yeah. - And so I would say Optimus in some way is like a hedge\nin AGI because it seems to me that it's possible that just having data from the internet is not enough.\nIf that is the case, then Optimus may lead to AGI. Because Optimus would, to me,\nthere's nothing beyond Optimus. You have like this humanoid form factor that can actually do stuff in the world. You can have millions of them\ninteracting with humans and so on. And if that doesn't give a rise to AGI at some point,\nI'm not sure what will. So from a completeness perspective, I think that's a really good platform\nbut it's a much more harder platform because you are dealing with atoms and you need to actually build these things\nand integrate them into society. So I think that path takes longer but it's much more certain.\nAnd then there's a path of the internet and just training these compression models effectively on trying to compress all the internet.\nAnd that might also give these agents as well. - Compress the internet but also interact with the internet.\n- [Andrej] Yeah. - So it's not obvious to me. In fact, I suspect you can reach AGI\nwithout ever entering the physical world, which is a little bit more concerning\nbecause that results in it happening faster.\nSo it just feels like we're in boiling water. We won't know as it's happening.\nI would like to, I'm not afraid of AGI, I'm excited about it. There's always concerns\nbut I would like to know when it happens. - [Andrej] Yeah. - And have like hints about when it happens,\nlike a year from now it will happen, that kind of thing. - [Andrej] Yeah. - I just feel like in the digital realm it just might happen.\n- Yeah. I think all we have available to us because no one has built AGI again, so all we have available to us is,\nis there enough fertile ground on the periphery? I would say, yes. And we have the progress so far, which has been very rapid and there are next steps\nthat are available. And so I would say, yeah, it's quite likely that we'll be interacting with digital entities.\n- How will you know that somebody has built AGI? - I think it's going to be a slow incremental transition.\nIt's going to be product-based and focused. It's going to be GitHub Copilot going better. And then GPTs helping you write and then these oracles\nthat you can go to with mathematical problems. I think we're on a verge of being able to ask very complex questions in chemistry, physics,\nmath of these oracles and have them complete solutions. - So AGI to use primarily focused on intelligence\nso consciousness doesn't enter into it.\n- So in my mind, consciousness is not a special thing you will figure out and bolt on. I think it's an emergent phenomenon of a large enough\nand complex enough generative model sort of. So if you have a complex enough world model\nthat understands the world, then it also understands its predicament in the world as being a language model,\nwhich to me is a form of consciousness or self-awareness. - So in order to understand the world deeply\nyou probably have to integrate yourself into the world. - [Andrej] Yeah. - And in order to interact with humans and other living beings,\nconsciousness is a very useful tool. - Yeah. I think consciousness is like a modeling insight.\n- Modeling insight. - Yeah. You have a powerful enough model of understanding the world that you actually understand\nthat you are an entity in it. - Yeah. But there's also this, perhaps just a narrative we tell ourselves, it feels like something\nto experience the world, the hard problem of consciousness. - [Andrej] Yeah. - But that could be just a narrative that we tell ourselves.\n- Yeah. I don't think we'll, yeah, I think it will emerge. I think it's going to be something very boring. We'll be talking to these digital AIs,\nthey will claim they're conscious, they will appear conscious, they will do all the things that you would expect of other humans\nand it's going to just be a stalemate. - I think there will be a lot of actual fascinating ethical questions,\nlike supreme court level questions of whether you're allowed to turn off a conscious AI,\nif you're allowed to build a conscious AI, maybe there would have to be the same kind of debates\nthat you have around, sorry to bring up a political topic, but abortion, which is the deeper question with abortion\nis what is life? And the deep question with AI is also,\nwhat is life and what is conscious? - [Andrej] Right. - And I think that'll be very fascinating\nto bring up, it might become illegal to build systems that are capable of such level of intelligence\nthat consciousness would emerge and therefore the capacity to suffer would emerge. And a system that says, no, please don't kill me.\n- Well, that's what the LaMDA chatbot already told this Google engineer, right?\nIt was talking about not wanting to die or so on. - So that might become illegal to do that.\n- [Andrej] Right. - 'Cause otherwise, you might have a lot of creatures\nthat don't want to die and they will- - [Andrej] You can just spawn infinity of them on a cluster.\n- And then that might lead to horrible consequences. 'Cause then there might be a lot of people that secretly love murder\nand they'll start practicing murder on those systems. I mean there's just, to me all of this stuff just brings\na beautiful mirror to the human condition and human nature and we get to explore it. - [Andrej] Yes.\n- And that's what like the best of the supreme court of all the different debates we have about ideas\nof what it means to be human, we get to those deep questions that we've been asking throughout human history.\nThere's always been the other in human history. We're the good guys and that's the bad guys\nand we're going to throughout human history, let's murder the bad guys. And the same will probably happen with robots.\nIt'll be the other at first. And then we'll get to ask questions, that what does it mean to be alive? What does it mean to be conscious?\n- Yep. And I think there's some canary in the coal mines even with what we have today. And for example, there's these waifus\nthat you can work with and some people are trying to, this company's going to shut down, but this person really loved their waifu\nand is trying to like port it somewhere else. And it's not possible. And I think definitely people will have feelings\ntowards these systems because in some sense they are like a mirror of humanity\nbecause they are like a big average of humanity. - [Lex] Yeah. - In a way that it's trained.\n- But that average, we can actually watch. It's nice to be able to interact\nwith the big average of humanity. - [Andrej] Yeah. - And do a search query on it. - Yeah. Yeah.\nIt's very fascinating. And we can also of course, also shape it. It's not just a pure average. We can mess with the training data,\nwe can mess with the objective, we can fine-tune them in various ways. So we have some impact on what those systems look like.\n- If you want to achieve AGI and you could have a conversation with her\nand ask her, talk about anything, maybe ask her a question. What kind of stuff would you ask?\n- I would've some practical questions in my mind like do I or my loved ones really have to die?\nWhat can we do about that? - Do you think it will answer clearly or would it answer poetically?\n- I would expect it to give solutions. I would expect it to be like, well, I've read all of these textbooks and I know all these things\nthat you've produced and it seems to me like here are the experiments that I think it would be useful to run next. And here are some gene therapies\nthat I think would be helpful, and here are the kinds of experiments that you should run. - Okay, let's go with this thought experiment.\nOkay. Imagine that mortality is actually\na prerequisite for happiness. So if we become immortal,\nwe'll actually become deeply unhappy and the model is able to know that. So what is it supposed to tell you?\nA stupid human about it? Yes, you can become a mortal but you'll become deeply unhappy. If the AGI system is trying to empathize with you human,\nwhat is it supposed to tell you. That yes, you don't have to die but you're really not gonna like it?\nIs it gonna be deeply honest? There's an \"Interstellar\", what is it the AI says like humans want 90% honesty.\nSo you have to pick how honest do I want to answer these practical questions? - Yeah. I love AI \"Interstellar\" by the way.\nI think it's like such a sidekick to the entire story but at the same time, it's really interesting.\n- It's kind of limited in certain ways, right? - Yeah, it's limited and I think that's totally fine by the way.\nI think it's fine and plausible to have a limited and imperfect AGIs.\n- Is that a feature almost? - As an example, it has a fixed amount of compute on its physical body.\nAnd it might just be that even though you can have a super amazing mega brain, super-intelligent AI,\nyou also can have less intelligent AI that you can deploy in a power-efficient way.\nAnd then they're not perfect, they might make mistakes. - No, I meant more like say you had infinite compute\nand it's still good to make mistakes sometimes. In order to integrate yourself. Like, what is it?\nGoing back to \"Goodwill Hunting\", Robin Williams character says the human imperfections, that's good stuff, right?\nWe don't want perfect, we want flaws in part to form connections with each other.\n'Cause it feels like something you can attach your feelings to, the flaws.\nIn that same way you want an AI that's flawed. I don't know. I feel like perfection is cold.\n- [Andrej] Okay, yeah. - But that's not AGI. But see AGI would need to be intelligent enough\nto give answers to humans that humans don't understand. And I think perfect is something humans can't understand\nbecause even science doesn't give perfect answers. There's always gaps and mysteries and I don't know,\nI don't know if humans want perfect. - Yeah, I could imagine just having a conversation\nwith this oracle entity as you'd imagine them and yeah, maybe it can tell you about,\nbased on my analysis of human condition, you might not want this and here are some of the things that might-\n- But every dumb human will say, yeah, yeah, yeah, yeah, trust me, give me the truth, I can handle it.\n- But that's the beauty, like people can choose. - But then, it's the old marshmallow test\nwith the kids and so on, I feel like too many people can't handle the truth, probably including myself.\nDeep truth to the human condition. I don't know if I can handle it. What if there's some dark stuff?\nWhat if we are an alien science experiment and it realizes that. What if it hacked, I mean?\n- I mean, this is \"The Matrix\" all over again. - \"The Matrix\", I don't know, what would I talk about?\nI don't even, yeah, probably I will go with the safer scientific questions at first\nthat have nothing to do with my own personal life. - [Andrej] Yeah. - Immortality just like about physics and so on.\n- [Andrej] Yeah. - To build up see where it's at or maybe see if it has a sense of humor.\nThat's another question. Presumably in order to, if it understands humans deeply,\nwould it able to generate humor.\n- Yeah. I think that's actually a wonderful benchmark almost, like is it able, I think that's a really good point, basically.\n- [Lex] To make you laugh. - Yeah. If it's able to be a very effective standup comedian that is doing something very interesting computationally.\nI think being funny is extremely hard. - Yeah, because it's hard in a way like a touring test,\nthe original intent of the touring test is hard because you have to convince humans and that's why comedians talk about this,\nlike this is deeply honest. 'Cause if people can't help but laugh and if they don't laugh that means you're not funny,\nif they laugh, it's funny. - Yeah. And you're showing, you need a lot of knowledge to create humor about like you mentioned\nhuman condition and so on. And then you need to be clever with it. - You mentioned a few movies, you Tweeted, \"Movies that I've seen five-plus times\n"}
{"pod": "Lex Fridman Podcast", "input": "Movies", "output": "but am ready and willing to keep watching: 'Interstellar', 'Gladiator', 'Contact', 'Goodwill Hunting',\n'The Matrix', 'Lord of the Rings', all three, 'Avatar', 'Fifth Element',\" and so on, it goes on, \"'Terminator 2'.\"\n\"Mean Girls\" I'm not gonna ask about that one. - \"Mean Girls\" is great.\n- What are some that jump out to you in your memory that you love and why?\nYou mentioned \"The Matrix\" as a computer person, why do you love \"The Matrix\"?\n- There's so many properties that make it beautiful and interesting. So there's all these philosophical questions but then there's also AGIs, and there's simulation,\nand it's cool, and there's the black. - [Lex] The look of it, the feel of it.\n- Yeah. The look of it, the feel of it, the action, the bullet time. It was just like innovating in so many ways.\n- And then \"Goodwill Hunting\". Why do you like that one? - Yeah, I really like this tortured genius character\nwho's grappling with whether or not he has any responsibility or what to do\nwith this gift that he was given or how to think about the whole thing and- - But there's also a dance between the genius\nand the personal, like what it means to love another human being. - Yeah.\nThere's a lot of themes there. It's just a beautiful movie. - And then the fatherly figure, the mentor and the psychiatrist.\n- It really messes with you. There's some movies that just like really mess with you\non a deep level. - Do you relate to that movie at all? - No. - It's not your fault Andrej, as I said.\n\"Lord of the Rings\", that's self-explanatory. \"Terminator 2\", which is interesting,\nyou rewatch that a lot. Is that better than Terminator one? You don't like Arnold as he comes back?\n- I do like Terminator one as well. I like \"Terminator 2\" a little bit more. But in terms of its surface properties.\n- Do you think Skynet is at all a possibility? - Yes. - Like the actual autonomous weapon system kind of thing?\nDo you worry about that stuff? So AI being used for war? - I a hundred percent worry about it.\nAnd so the, I mean, some of these fears of AGIs and how this will plan out, I mean these will be\nvery powerful entities probably at some point. And so for a long time, there are going to be tools in the hands of humans.\nPeople talk about alignment of AGIs and how to make, the problem is even humans are not aligned.\nSo how this will be used and what this is gonna look like is, yeah, it's troubling.\n- Do you think it'll happen slowly enough that we'll be able to as a human civilization\nthink through the problems? - Yes, that's my hope, is that it happens slowly enough and in an open enough way where a lot of people can see\nand participate in it. Just to figure out how to deal with this transition, I think, which is gonna be interesting.\n- I draw a lot of inspiration from nuclear weapons 'cause I sure thought it would be fucked\nonce they develop nuclear weapons. But it's almost like when the systems are not so dangerous\nthey destroy human civilization. We deploy them and learn the lessons and then we quickly,\nif it's too dangerous we quickly, quickly, we might still deploy it but you very quickly learn\nnot to use them. And so there'll be like this balance achieved, humans are very clever as a species. It's interesting, we exploit the resources as much as we can\nbut we avoid destroying ourselves it seems like. - Yeah. Well, I dunno about that actually.\n- I hope it continues. - I mean I'm definitely like concerned about nuclear weapons and so on,\nnot just as a result of the recent conflict, even before that. That's probably like my number one concern for humanity.\n- So if humanity destroys itself or destroys 90% of people\nthat would be because of nukes? - Yeah, I think so. And it's not even about full destruction,\nto me, it's bad enough if we reset society, that would be terrible. That would be really bad. And I can't believe we're so close to it.\n- [Lex] Yeah. - It's like so crazy to me. - It feels like we might be a few Tweets away from something like that. - Yep.\nBasically, it's extremely unnerving and has been for me for a long time. - It seems unstable that world leaders\njust having a bad mood can take one step\ntowards a bad direction and then it escalates. - Yeah. - And because of a collection of bad moods,\nit can escalate without being able to stop. - Yeah.\nIt's a huge amount of power. And then also with the proliferation and basically, I don't actually really see,\nI don't actually know what the good outcomes are here, so I'm definitely worried about that a lot. And then AGI is not currently there\nbut I think at some point it will more and more become something like it. The danger with AGI even is that\nI think it's even slightly worse in the sense that there are good outcomes of AGI\nand then the bad outcomes are an epsilon way, like a tiny run away. And so I think capitalism and humanity, and so on\nwill drive for the positive ways of using that technology. But then if bad outcomes are just like a tiny,\nlike flip a minus sign away, that's a really bad position to be in. - A tiny perturbation of the system\nresults in the destruction of the human species. - [Andrej] Yeah. - It's a weird line to walk. - Yeah, I think in general what's really weird\nabout the dynamics of humanity and this explosion we talked about is just the insane coupling afforded by technology.\n- [Lex] Yeah. - And just the instability of the whole dynamical system. I think it doesn't look good, honestly.\n- Yes. That explosion could be destructive or constructive and the probabilities are non-zero in both ends of it.\n- I'm gonna have to, I do feel like I have to try to be optimistic and so on and I think even in this case I still am predominantly optimistic but there's definitely-\n"}
{"pod": "Lex Fridman Podcast", "input": "Future of human civilization", "output": "- Me too. Do you think we'll become a multi-planetary species? - Probably, yes.\nBut I don't know if it's dominant feature of future humanity. There might be some people on some planets and so on\nbut I'm not sure if it's like, yeah, if it's like a major player in our culture and so on.\n- We still have to solve the drivers of self-destruction here on earth. So just having a backup on Mars\nis not gonna solve the problem. - So by the way, I love the backup on Mars. I think that's amazing. We should absolutely do that.\n- [Lex] Yes. - And I'm so thankful. - Would you go to Mars? - Personally, no, I do like earth quite a lot.\n- Okay. I'll go to Mars. I'll go for you. I'll Tweet at you from there. - Maybe eventually I would, once it's safe enough.\nBut I don't actually know if it's on my lifetime scale unless I can extend it by a lot.\nI do think that for example, a lot of people might disappear into virtual realities and stuff like that and I think that could be the major thrust\nof the cultural development of humanity if it survives. So it might not be, it's just really hard to work\nin physical realm and go out there and I think ultimately all your experiences are in your brain.\n- [Lex] Yeah. - And so it's much easier to disappear into digital realm and I think people will find them more compelling, easier,\nsafer, more interesting. - So you're a little bit captivated by virtual reality, by the possible worlds, whether it's the metaverse\nor some other manifestation of that? - [Andrej] Yeah. - Yeah. It's really interesting.\nI'm interested, just talking a lot to Carmack, where's the thing that's currently preventing that?\n- Yeah, I mean to be clear, I think what's interesting about the future is it's not that, I feel like\nthe variance in the human condition grows. That's the primary thing that's changing. It's not as much the mean of the distribution,\nit's like the variance of it. So there will probably be people on Mars and there will be people in VR, and there will people here on earth.\nIt's just like there will be so many more ways of being. And so feel like, I see it as like a spreading out\nof a human experience. - There's something about the internet that allows you to discover those little groups and you gravitate to, something about your biology\nlikes that kind of world and you find each other. - Yeah. And we'll have trans-humanists and then we'll have the Amish and everything is just gonna coexist.\n- Yeah. The cool thing about it 'cause I've interacted with a bunch of internet communities is they don't know about each other.\nLike you can have a very happy existence just having a very close-knit community and not knowing about each other.\nI mean even you even sense this, just having traveled to Ukraine, they don't know so many things about America.\n- [Andrej] Yeah. - When you travel across the world I think you experience this too. There are certain cultures that are like,\nthey have their own thing going on, they don't. And so you can see that happening more and more and more\nand more in the future. We have little communities. - Yeah. Yeah. I think so. That seems to be how it's going right now.\nAnd I don't see that trend really reversing. I think people are diverse and they're able to choose their own path in existence and I celebrate that.\nAnd so- - Will you spend some, much time in the metaverse, in the virtual reality? Or which community are you,\nare you the physicalist, the physical reality enjoyer\nor do you see drawing a lot of pleasure and fulfillment in the digital world?\n- Yeah, I think, well currently, the virtual reality is not that compelling. - [Lex] Yes. - I do think it can improve a lot\nbut I don't really know to what extent. Maybe there's actually even more exotic things you can think about with neural links or stuff like that.\nSo currently, I kind of see myself as mostly a team, human person, I love nature.\n- [Lex] Yeah. - I love harmony, I love people, I love humanity. I love emotions of humanity and I just want to be\nin this solar punk little utopia. That's my happy place. - [Lex] Yes. - My happy place is people I love,\nthinking about cool problems, surrounded by a lush, beautiful dynamic nature. - [Lex] Yeah. - And secretly high-tech in places that count.\n- Places that count. So you use technology to empower that love for other humans and nature.\n- Yeah, I think a technology used very sparingly. I don't love when it gets in the way of humanity\nin many ways. I like just people being humans in a way, we slightly evolved and prefer I think\njust by default. - People kept asking me 'cause they know you love reading. Are there particular books that you enjoyed\n"}
{"pod": "Lex Fridman Podcast", "input": "Book recommendations", "output": "that had an impact on you for silly or for profound reasons that you would recommend?\nYou mentioned \"The Vital Question\". - Many, of course. I think in biology as an example, \"The Vital Question\" is a good one.\nAnything by Nick Lane really, \"Life Ascending\" I would say is a bit more potentially representative\nas like a summary of a lot of the things he's been talking about. I was very impacted by \"The Selfish Gene\".\nI thought that was a really good book, it helped me understand altruism as an example and where it comes from. And just realizing that the selection\nand the levels of genes was a huge insight for me at the time and it cleared up a lot of things for me. - What do you think about the idea\nthat ideas are the organisms, the memes? - Yeah. Love it. A hundred percent.\n- Are you able to walk around with that notion for a while? That there's an evolutionary kind of process\nwith ideas as well? - There absolutely is. There's memes just like genes and they compete and they live in our brains.\nIt's beautiful. - Are we silly humans thinking that we are the organisms? Is it possible that the primary organisms are the ideas?\n- Yeah, I would say like the ideas kind of live in the software of our civilization in the minds\nand so on. We think as humans that the hardware is the fundamental thing. I human is a hardware entity.\n- [Andrej] Yeah. - But it could be the software, right? - Yeah. Yeah.\nI would say there needs to be some grounding at some point to a physical reality. - Yeah, but if we clone an Andrej,\nthe software is a thing that makes that thing special. Right?\n- Yeah. I guess you're right. - But then cloning might be exceptionally difficult. There might be a deep integration between the software and the hardware\nin ways we don't quite yet understand. - Well, from the altruism point of view, what makes me special is more the gang of genes\nthat are riding in my chromosomes I suppose. Right? They're the replicating unit I suppose-\n- No, but that's just the compute, the thing that makes you special, sure. Well, the reality is what makes you special\nis your ability to survive based on the software that runs on the hardware that was built by the genes.\nSo the software is the thing that makes you survive. Not the hardware or- - It's a little bit of both. It's just like a second layer.\nIt's a new second layer that hasn't been there before the brain. They both coexist. - But there's also layers of the software.\nI mean it's an abstraction on top of abstractions.\nOkay, \"Selfish Gene\". - So \"Selfish Gene\", Nick Lane. I would say sometimes books are not sufficient.\nI like to reach for textbooks sometimes. I feel like books are for too much\nof a general consumption sometime and they're too high up in the level of abstraction and it's not good enough.\n- [Lex] Yeah. - So I like textbooks, I like \"The Cell\". I think \"The Cell\" was pretty cool.\nThat's why also I like the writing of Nick Lane is because he's pretty willing to step one level down\nand he doesn't, yeah, he's willing to go there but he's also willing to be throughout the stack.\nSo he'll go down to a lot of detail but then he will come back up and I think he has a, yeah, basically, I really appreciate that.\n- That's why I love college, early college, even high school, just textbooks on the basics of computer science, of mathematics,\nof biology, of chemistry. - [Andrej] Yes. - Those are, they condense down, it's sufficient in general\nthat you can understand both the philosophy and the details but also you get homework problems\nand you get to play with it as much as you would if you were in programming stuff. - Yeah.\nAnd then I'm also suspicious of textbooks honestly because as an example in deep-learning there's no amazing textbooks and the field is changing very quickly.\nI imagine the same is true in say synthetic biology and so on, these books like \"The Cell\" are kind of outdated.\nThey're still high-level, like what is the actual real source of truth? It's people in wet labs working with cells.\n- Yeah. - Sequencing genomes and, yeah, actually working with it.\nAnd I don't have that much exposure to that or what that looks like. So I still don't fully, I'm reading through the cell\nand it's kind of interesting, and I'm learning but it's still not sufficient I would say in terms of understanding. - Well, it's a clean summarization\nof the mainstream narrative. - [Andrej] Yeah. - But you have to learn that before you break out.\n- [Andrej] Yeah, - Towards the cutting edge. - Yeah. But what is the actual process of working with these cells and growing them and incubating them\nand it's like a massive cooking recipe. So making sure your cell slows and proliferate and then you're sequencing them, running experiments\nand just how that works, I think is the source of truth of at the end of the day what's really useful\nin terms of creating therapies and so on. - Yeah. I wonder what in the future AI textbooks will be\n'cause you know there's \"Artificial Intelligence: A Modern Approach\". I actually haven't read, if it's come out, the recent version, there's been a recent edition.\nI also saw there's a science of deep learning book. I'm waiting for textbooks that are worth recommending, worth reading.\n- [Andrej] Yeah. - It's tricky 'cause it's like papers and code, code, code. - Honestly, I find papers are quite good.\nI especially like the appendix of any paper as well. It's like the most detail you can have.\n- It doesn't have to be cohesive, connected to anything else. You just described me a very specific way you saw the particular thing.\nYeah. - Yeah, many times papers can be actually quite readable, not always, but sometimes the introduction and the abstract is readable even for someone outside of the field.\nThis is not always true and sometimes I think, unfortunately, scientists use complex terms even when it's not necessary.\nI think that's harmful. I think there's no reason for that. - And papers sometimes are longer than they need to be\nin the parts that don't matter. - [Andrej] Yeah. - The appendix should be long but then the papers itself, look at Einstein,\nmake it simple. - Yeah. But certainly, I've come across papers I would say, say like synthetic biology or something that I thought were quite readable for the abstract\nand the introduction and then you're reading the rest of it and you don't fully understand but you kind of are getting a gist and I think it's cool.\n"}
{"pod": "Lex Fridman Podcast", "input": "Advice for young people", "output": "- You give advice to folks interested in machine learning and research but in general life advice\nto a young person, high school, early college about how to have a career they can be proud of\nor a life they can be proud of? - Yeah, I think I'm very hesitant to give general advice.\nI think it's really hard. I've mentioned, some of the stuff I've mentioned is fairly general, I think. Like focus on just the amount of work you're spending\non like a thing. Compare yourself only to yourself, not to others. - [Lex] That's good. - [Andrej] I think those are fairly general.\n- How do you pick the thing? - You just have like a deep interest in something\nor try to find the argmax over the things that you're interested in. - Argmax at that moment and stick with it.\n- [Lex] Yeah. - How do you not get distracted and switch to another thing? - You can if you like.\n- Well, if you do an argmax repeatedly every week, every month. - [Andrej] Yeah, it doesn't converge. - It's a problem.\n- Yeah. You can like low-pass filter yourself in terms of what has consistently been true for you.\nBut yeah, I definitely see how it can be hard but I would say you're going to work the hardest on the thing that you care about the most.\nSo low pass filter yourself and really introspect in your past, what are the things that gave you energy\nand what are the things that took energy away from you? Concrete examples. And usually, from those concrete examples,\nsometimes patterns can merge. I like it when things look like this when I'm in these positions. - So that's not necessarily the field\nbut the kind of stuff you're doing in a particular field. So for you, it seems like you were energized by implementing stuff, building actual things.\n- Yeah, being low-level, learning and then also communicating so that others can go through\nthe same realizations and shortening that gap. Because I usually have to do way too much work to understand a thing and then I'm like, okay,\nthis is actually like, okay, I think I get it and like why was it so much work? It should have been much less work.\nAnd that gives me a lot of frustration and that's why I sometimes go teach. - So aside from the teaching you're doing now,\n"}
{"pod": "Lex Fridman Podcast", "input": "Future of machine learning", "output": "putting out videos, aside from a potential \"Godfather II\"\nwould the AGI at Tesla and beyond, what does the future for Andrej Karpathy hold, have you figured that out yet or no?\nI mean as you see through the fog of war that is all of our future, do you start seeing silhouettes\nof what that possible future could look like? - The consistent thing I've been always interested in,\nfor me at least is Ai. And that's probably what I'm spending the rest of my life on\nbecause I just care about it a lot. And I actually care about many other problems as well. Like say aging, which I basically view as disease\nand I care about that as well. But I don't think it's a good idea to go after it, specifically.\nI don't actually think that humans will be able to come up with the answer. I think the correct thing to do is to ignore those problems\nand you solve AI and then use that to solve everything else. And I think there's a chance that this will work. I think it's a very high chance\nand that's the way I'm betting at least. - So when you think about AI,\nare you interested in all kinds of applications? - [Andrej] Yes. - All kinds of domains.\nAnd any domain you focus on will allow you to get insights to the big problem of AGI? - Yeah, for me it's the ultimate meta-problem.\nI don't wanna work on any one specific problem, there's too many problems. So how can you work on all problems simultaneously? You solve the meta-problem, which to me is just intelligence\nand how do you automate it? - Is there cool small projects like arxiv-sanity\nand so on that you're thinking about that ML world can anticipate.\n- There's always some fun side projects. - [Lex] Yeah. - arxiv-sanity is one, yeah, basically, there's way too many archive papers,\nhow can I organize it and recommend papers and so on. I transcribed all of your podcasts.\n- What did you learn from that experience, from transcribing the process of like\nyou consuming audiobooks and podcasts and so on? - [Andrej] Yeah. - And here's a process that achieves\ncloser to human-level performance on annotation. - Yeah, well, I definitely was surprised that transcription with OpenAI Whisper\nwas working so well compared to what I'm familiar with, from Siri and a few other systems I guess, it works so well.\nAnd that's what gave me some energy to try it out. And I thought it could be fun to run on podcasts.\nIt's not obvious to me why Whisper is so much better compared to anything else because I feel like\nthere should be a lot of incentive for a lot of companies to produce transcription systems and that they've done so over a long time. Whisper is not a super exotic model, it's a transformer,\nit takes mel spectrograms and it just outputs tokens of text. It's not crazy.\nThe model and everything has been around for a long time. I'm not actually a hundred percent sure why this came about. - Yeah, it's not obvious to me either.\nIt makes me feel like I'm missing something for the middle. - [Andrej] I'm missing something. - Yeah, because there is a huge, even Google and so on,\nYouTube transcription. - [Andrej] Yeah. - Yeah. It's unclear. But some of it is also integrating into a bigger system.\n- [Andrej] Yeah. - So the user interface, how it's deployed and all that kind of stuff. Maybe running it as an independent thing is much easier,\nlike an order of magnitude easier than deploying it to a large integrated system like YouTube transcription, or anything,\nlike meetings, like Zoom has transcription, that's kind of crappy.\nBut creating interface where it detects the different individual speakers, it's able to display it in compelling ways,\nrun it real-time, all that kind of stuff. Maybe that's difficult. That's the only explanation I have\nbecause I'm currently paying quite a bit for human transcription, human caption.\n- [Andrej] Right. - Annotation. And like it seems like there's a huge incentive to automate that.\n- [Andrej] Yeah. - It's very confusing. - And I think, I mean, I dunno if you looked at some of the Whisper transcripts, but they're quite good. - They're good.\nAnd especially in tricky cases. - [Andrej] Yeah. - I've seen Whisper's performance on super tricky cases\nand it does incredibly well. So I don't know, a podcast is pretty simple. It's like high-quality audio\nand you're speaking usually pretty clearly. - [Andrej] Yeah. - And so I don't know,\nI don't know what OpenAIs plans are either. - But yeah, there's always fun projects basically.\nAnd stable diffusion also is opening up a huge amount of experimentation I would say in the visual realm and generating images, and videos, and movies ultimately.\n- [Lex] Yeah, videos now. - And so that's going to be pretty crazy. That's going to almost certainly work\nand it's going to be really interesting when the cost of content creation is going to fall to zero. You used to need a painter for a few months to paint a thing\nand now it's going to be speak to your phone to get your video. - So if Hollywood will start using that to generate scenes\nwhich completely opens up. Yeah. So you can make a movie like \"Avatar\" eventually\nfor under a million dollars. - Much less maybe just by talking to your phone. I mean, I know it sounds kind of crazy.\n- And then there'd be some voting mechanism, would there be a show on Netflix that's generated completely automatedly?\nSemi-automatedly? - Yeah, potentially. Yeah. And what does it look like also when you can just generate it on demand\nand there's infinity of it? - Yeah.\nOh, man. All the synthetic content. I mean it's humbling because we treat ourselves as special\nfor being able to generate art, and ideas, and all that kind of stuff. If that can be done in an automated way by Ai.\n- Yeah. I think it's fascinating to me how these, the predictions of AI and what it's going to look like and what it's going to be capable of\nare completely inverted and wrong. And sci-fi of fifties and sixties, were just totally not right.\nThey imagine AI is like super calculating, theorem provers, and we're getting things that can talk to you about emotions.\nThey can do art, it's just weird. - Are you excited about that future? just AI's, like hybrid systems, heterogeneous systems\nof humans and AIs talking about emotions, Netflix and chill with an AI system.\nOr the Netflix thing you watch is also generated by AI? - I think it's going to be interesting for sure\nand I think I'm cautiously optimistic but it's not obvious. - Well, the sad thing is your brain and mine developed\nin a time before Twitter, before the internet.\nSo I wonder people that are born inside of it might have a different experience. Like I, and maybe you will still resist it\nand the people born now will not. - Well, I do feel like humans are extremely malleable. - [Lex] Yeah.\n- And you're probably right. - What is the meaning of life, Andrej?\n"}
{"pod": "Lex Fridman Podcast", "input": "Meaning of life", "output": "We talked about the universe having a conversation with us humans\nor with the systems we create to try to answer. For the creator of the universe to notice us,\nwe're trying to create systems that are loud enough to answer back.\n- I dunno if that's the meaning of life. That's like meaning of life for some people. The first level answer I would say is anyone can choose their own meaning of life\nbecause we are a conscious entity and it's beautiful, number one. But I do think that a deeper meaning of life\nif someone is interested is along the lines of like, what the hell is all this? And like why?\nAnd if you look into fundamental physics and the quantum field theory and the standard model, they're very complicated.\nAnd there's this 19 free parameters of our universe\nand what's going on with all this stuff and why is it here? And can I hack it? Can I work with it?\nIs there a message for me? Am I supposed to create a message? And so I think there's some fundamental answers there\nbut I think there's actually even like, you can't actually really make dent in those without more time.\nAnd so to me also there's a big question around just getting more time, honestly. Yeah.\nThat's what I think about quite a bit as well. - So kind of the ultimate, or at least first way to sneak up to the why question\nis to try to escape the system, the universe?\n- [Andrej] Yeah. - And then for that you backtrack and say, okay, for that, that's gonna take a very long time.\nSo the why question boils down from an engineering perspective to how do we extend? - Yeah.\nI think that's the question number one, practically speaking, because you're not gonna calculate the answer to the deeper questions in the time you have.\n- And that could be extending your own lifetime or extending just the lifetime of human civilization.\n- Of whoever wants to, many people might not want that. - [Lex] Yeah. - But I think people who do want that,\nI think it's probably possible, and I don't know that people fully realize this.\nI feel like people think of death as an inevitability but at the end of the day, this is a physical system.\nSome things go wrong. It makes sense why things like this happen, evolutionarily speaking,\nand there's most certainly interventions that mitigate it. - That would be interesting if death is eventually looked at\nas a fascinating thing that used to happen to humans. - I don't think it's unlikely.\nI think it's likely. - And it's up to our imagination to try to predict\nwhat the world without death looks like. - [Andrej] Yeah. - It's hard to, I think the values will completely change.\n- Could be, I don't really buy all these ideas that, oh, without death, there's no meaning, there's nothingness.\nI don't intuitively buy all those arguments. I think there's plenty of meaning, plenty of things to learn.\nThey're interesting, exciting. I want to know, I want to calculate, I want to improve the condition of all the humans\nand organisms that are alive. - Yeah. The way we find meaning might change. There is a lot of humans, probably including myself,\nthat finds meaning in the finiteness of things, but that doesn't mean that's the only source of meaning.\n- Yeah. I do think many people will go with that, which I think is great. I love the idea that people\ncan just choose their own adventure. You are born as a conscious, free entity by default.\nI'd like to think. - [Lex] Yeah. - And you have your unalienable rights for life.\n- In the pursuit of happiness? I don't know if you that, and the nature, the landscape of happiness.\n- And you can choose your own adventure, mostly. And that's not fully true but. - I'm still am pretty sure I'm an NPC,\nbut an NPC can't know it's an NPC.\nThere could be different degrees and levels of consciousness. I don't think there's a more beautiful way to end it.\nAndrej, you're an incredible person. I'm really honored you would talk with me, everything you've done for the machine learning world,\nfor the AI world to just inspire people, to educate millions of people.\nIt's been great and I can't wait to see what you do next. It's been an honor, man. Thank you so much for talking today.\n- Awesome. Thank you. Thanks for listening to this conversation with Andrej Karpathy, to support this podcast\nplease check out our sponsors in the description. And now, let me leave you some words from Samuel Karlin,\n\"The purpose of models is not to fit the data but to sharpen the questions.\"\nThanks for listening and hope to see you next time.\n"}

{"pod": "Lex Fridman Podcast", "input": "Introduction", "output": "the following is a conversation with demus hasabis ceo and co-founder of deepmind\na company that has published and builds some of the most incredible artificial intelligence systems in the history of\ncomputing including alfred zero that learned all by itself to play the game of gold\nbetter than any human in the world and alpha fold two that solved protein\nfolding both tasks considered nearly impossible for a very long time\ndemus is widely considered to be one of the most brilliant and impactful humans in the history of artificial\nintelligence and science and engineering in general this was truly an honor and a pleasure\nfor me to finally sit down with him for this conversation and i'm sure we will talk many times again in the future\nthis is the lex friedman podcast to support it please check out our sponsors in the description and now dear friends\nhere's demis hassabis let's start with a bit of a personal question\n"}
{"pod": "Lex Fridman Podcast", "input": "Turing Test", "output": "am i an ai program you wrote to interview people until i get good enough to interview you\nwell i'll be impressed if if you were i'd be impressed by myself if you were i don't think we're quite up to that yet\nbut uh maybe you're from the future lex if you did would you tell me is that is that a good thing to tell a language\nmodel that's tasked with interviewing that it is in fact um ai maybe we're in\na kind of meta turing test uh probably probably it would be a good idea not to tell you so it doesn't change your\nbehavior right this is a kind of heisenberg uncertainty principle situation if i told you you behave differently yeah maybe that's what's\nhappening with us of course this is a benchmark from the future where they replay 2022 as a year before ais were\ngood enough yet and now we want to see is it going to pass exactly\nif i was such a program would you be able to tell do you think so to the touring test question\nyou've talked about the benchmark for solving intelligence\nwhat would be the impressive thing you've talked about winning a nobel prize in a system winning a nobel prize\nbut i still return to the touring test as a compelling test the spirit of the touring test is a compelling test\nyeah the turing test of course it's been unbelievably influential and turing's one of my all-time heroes but i think if\nyou look back at the 1950 papers original paper and read the original you'll see i don't think he meant it to\nbe a rigorous formal test i think it was more like a thought experiment almost a bit of philosophy he was writing if you\nlook at the style of the paper and you can see he didn't specify it very rigorously so for example he didn't\nspecify the knowledge that the expert or judge would have um not you know how\nmuch time would they have to investigate this so these important parameters if you were gonna make it uh a true sort of\nformal test um and you know some by some measures people claimed the turing test passed\nseveral you know a decade ago i remember someone claiming that with a with a kind of very bog standard normal uh\nlogic model um because they pretended it was a it was a kid so the the judges\nthought that the machine you know was was a was a child so um that would be\nvery different from an expert ai person uh interrogating a machine and knowing how it was built and so on so i think um\nyou know we should probably move away from that as a formal test and move more towards a general test where we test the\nai capabilities on a range of tasks and see if it reaches human level or above\nperformance on maybe thousands perhaps even millions of tasks eventually and cover the entire sort of cognitive space\nso i think for its time it was an amazing thought experiment and also 1950s obviously it\nwas barely the dawn of the computer age so of course he only thought about text and now um we have a lot more different\ninputs so yeah maybe the better thing to test is the generalizability so across\nmultiple tasks but i think it's also possible as as systems like god show\nthat eventually that might map right back to language so you might be able to demonstrate your ability to generalize\nacross tasks by then communicating your ability to generalize across tasks which is kind of\nwhat we do through conversation anyway when we jump around ultimately what's in there in that\nconversation is not just you moving around knowledge it's you moving around like these\nentirely different modalities of understanding that ultimately map to\nyour ability to to uh operate successfully in all these domains which you can think of as tasks\nyeah i think certainly we as humans use language as our main generalization communication tool so i think we end up\nthinking in language and expressing our solutions in language um so it's going to be very powerful\nuh uh mode in which to uh explain you know the system to explain what it's\ndoing um but i don't think it's the only uh uh modality that matters so i think\nthere's gonna be a lot of you know there's there's a lot of different ways to express uh capabilities uh other than\njust language yeah visual robotics body language\num yeah action is the interactive aspect of all that that's all part of it but what's interesting with gato is that\nit's a it's it's it's sort of pushing prediction to the maximum in terms of like you know mapping arbitrary\nsequences to other sequences and sort of just predicting what's going to happen next so prediction seems to be\nfundamental to intelligence and what you're predicting doesn't so much matter yeah it seems\nlike you can generalize that quite well so obviously language models predict the next word um gato predicts potentially\nany uh action or any token uh and it's just the beginning really it's our most general agent one could call it so far\nbut um you know that itself can be scaled up massively more than we've done so far obviously we're in the in the\nmiddle of doing that but the big part of solving agi is creating benchmarks that\nhelp us get closer and closer sort of creating benchmarks that test the journalizability and it's just still\ninteresting that this fella alan turing was one of the first and probably still\none of the only people that was trying maybe philosophically but was trying to formulate a benchmark that could be\nfollowed it is even though it's it's fuzzy it's still sufficiently rigorous to where you can\nrun that test and i still think something like the touring test will at the end of the day\nbe the thing that truly impresses other humans so that you can have a close friend\nwho's an ai system for that friend to be a good friend they're going to have to be able to\nuh play starcraft and they're going to have to do all of these tasks um get you a beer so the\nrobotics tasks uh play games with you use language\nhumor all those kinds of things but that ultimately can boil down to language it feels like not in terms of the ai\ncommunity but in terms of the actual impact of general intelligence on the world it feels like language will be the\nplace where it truly shines i think so because it's such an important kind of input output for us i think you're right\ni think the turing test that what the the kind of the the philosophy behind it which is the idea of can can a machine\nmimic the behaviors of a human and men and i would say wider than just language\nand text then you know in terms of actions and everything else creativity all these\nthings then um if it can sort of match or exceed human cognitive capabilities\nthen i think we have a you know true intelligence so i thought from that perspective you're right i think he did\nformulate the right uh kind of uh setup i just i think there'll be a kind of\nhumor in the ai systems of the future looking back to this conversation\nand thinking about the touring test and uh also thinking about\nby that time they would know which year they were finally able to sort of cross the threshold of human level\nintelligence and think how funny it is that we humans were still\nconfused about this whole problem that has been long ago been solved well hello to the ai agents of the\nfuture anyway so going back to your to your journey when did you fall in love with programming first\n"}
{"pod": "Lex Fridman Podcast", "input": "Video games", "output": "well it's pretty uh pretty young age actually so um you know i started off uh actually games\nwas my first love so starting to play chess when i was around four years old and then um it was actually with\nwinnings from a chess competition that i managed to buy my first chess computer when i was about eight years old it was\na zx spectrum which was hugely popular in the uk at the time and uh it's amazing machine because i\nthink it trained a whole generation of programmers in the uk because it was so accessible you know you literally\nswitched it on and there was the basic prompt and you could just get going and um my parents didn't really know\nanything about computers so but because it was my money from a chess competition i could i could say i i wanted to buy it\nuh and then you know i just went to bookstores got books on programming and\num started typing in you know the programming code and and then of course um once you start doing that you start\nadjusting it and then making your own games and that's when i fell in love with computers and realized that they were a very magical device um in a way i\nkind of i would have been able to explain this at the time but i felt that they were sort of almost a magical extension of your mind i always had this\nfeeling and i've always loved this about computers that you can set them off doing something some task for you you\ncan go to sleep come back the next day and it's solved um you know that feels magical to me so\ni mean all machines do that to some extent they all enhance our natural capabilities obviously cars make us\nallow us to move faster than we can run but this was a machine to extend the mind\nand and then of course ai is the ultimate expression of what a machine may be able to do or learn so\nvery naturally for me that thought extended into into ai quite quickly remember the the programming language\nthat was first started special to the machine no it was just the base it was just i think it was just\nbasic uh on the zx spectrum i don't know what specific form it was and then later on i got a commodore amiga which uh\nwas a fantastic machine no you're just showing off so yeah well lots of my friends had atari st's and i i managed\nto get amigas it was a bit more powerful and uh and that was incredible and used to do um programming in assembler and\nand uh also amos basic this this specific form of basic it was incredible actually as well all my coding skills\nand when did you fall in love with ai so when did you first start to gain an understanding that you\ncan not just write programs that do some mathematical operations for you while you sleep but something that's\na keen to bringing an entity to life sort of\na thing that can figure out something more complicated than uh than a simple mathematical operation\nyeah so there was a few stages for me all while i was very young so first of all as i was trying to improve at\nplaying chess i was captaining various england junior chess teams and at the time when i was about you know maybe 10 11 years old i was gonna become a\nprofessional chess player that was my first thought um that dream was there sure she\ntried to get to the highest level yeah so i was um you know i got to when i was about 12 years old i got to master stand\nand i was second highest rated player in the world to judith polgar who obviously ended up being an amazing chess player\nand uh world women's champion and when i was trying to improve at chess where you\nknow what you do is you obviously first of all you're trying to improve your own thinking processes so that leads you to\nthinking about thinking how is your brain coming up with these ideas why is it making mistakes how can you how can\nyou improve that thought process but the second thing is that you it was just the beginning this was like in the in the\nearly 80s mid 80s of chess computers if you remember they were physical boards like the one we have in front of us and\nyou pressed down the you know the squares and i think kasparov had a branded version of it that i i i got and\num you were you know used to they're not as strong as they are today but they were they were pretty strong and you\nused to practice against them um to try and improve your openings and other things and so i remember i think i\nprobably got my first one i was around 11 or 12. and i remember thinking um this is amazing you know how how has\nsomeone programmed uh uh this this chess board to play chess uh and uh it was\nvery formative book i bought which was called the chess computer handbook by david levy which came out in 1984 or\nsomething so i must have got it when i was about 11 12 and it explained fully how these chess programs were made i\nremember my first ai program being uh programming my amiga it couldn't it\nwasn't powerful enough to play chess i couldn't write a whole chess program but i wrote a program for it to play othello\nreversey it's sometimes called i think in the u.s and so a slightly simpler game than chess but i used all of the\nprinciples that chess programs had alpha beta search all of that and that was my first ai program i remember that very\nwell was around 12 years old so that that that brought me into ai and then the second part was later on uh when i\nwas around 1617 and i was writing games professionally designing games uh writing a game called theme park which\num had ai as a core gameplay component as part of the simulation um and it sold\nyou know millions of copies around the world and people loved the way that the ai even though it was relatively simple\nby today's ai standards um was was reacting to the way you as the player played it so it was called a sandbox\ngame so it's one of the first types of games like that along with simcity and it meant that every game you played was\nunique is there something you could say just on a small tangent about\nreally impressive ai from a game design human enjoyment perspective\nreally impressive ai that you've seen in games and maybe what does it take to create ai system and how hard of a\nproblem is that so a million questions just as a brief tangent\nwell look i think um games uh games have been significant in my life for three reasons so first of\nall to to i was playing them and training myself on games when i was a kid then i went through a phase of\ndesigning games and writing ai4 games so all the games i i professionally wrote uh had ai as a core component and that\nwas mostly in the in the 90s and the reason i was doing that in games industry was at the time the games\nindustry i think was the cutting edge of technology so whether it was graphics with people like john carmack and quake\nand those kind of things or ai i think actually all the action was going on in\ngames and and we've seen we're still reaping the benefits of that even with things like gpus which you know i find\nironic was obviously invented for graphics computer graphics but then turns out to be amazingly useful for ai\nit just turns out everything's a matrix multiplication it appears you know in the whole world so um so i think games at the time had\nthe most cutting edge ai and a lot of the the games uh uh we you know i was involved in writing so there was a game\ncalled black and white which was one game i was involved with in the early stages of which i still think is the\nmost um impressive uh example of reinforcement learning in a computer game so in that\ngame you know you trained a little pet animal uh and yeah and it sort of learned from how you\nwere treating it so if you treated it badly then it became mean yeah and then it would be mean to to your villagers\nand your and your population the sort of uh the little tribe that you were running uh but if you were kind to it\nthen it would be kind and people were fascinated by how that was and so was i to be honest with the way it kind of\ndeveloped and um especially the mapping to good and evil yeah it made you made you realize made me realize that you can\nsort of in the way in the choices you make can define uh the\nwhere you end up and that means all of us are capable of the good\nuh evil it all matters in uh the different choices along the trajectory to those places that you make it's\nfascinating i mean games can do that philosophically to you and it's rare it seems rare yeah well games are i think a\nunique medium because um you as the player you're not just passively consuming the the entertainment right\nyou're actually actively involved as an as a as an agent so i think that's what makes it in some ways can be more\nvisceral than other other mediums like you know films and books so the second so that was you know designing ai and\ngames and then the third use uh uh i've we've used of ai is in deep mind from\nthe beginning which is using games as a testing ground for proving out ai\nalgorithms and developing ai algorithms and that was a that was a sort of um a core component of our vision at the\nstart of deepmind was that we would use games very heavily uh as our main testing ground certainly to begin with\num because it's super efficient to use games and also you know it's very easy to have metrics to see how well your\nsystems are improving and what direction your ideas are going in and whether you're making incremental improvements\nand because those games are often rooted in something that humans did for a long time beforehand\nthere's already a strong set of rules like it's already a damn good benchmark yes it's really good for\nso many reasons because you've got you've got you've got clear measures of how good humans can be at these things\nand in some cases like go we've been playing it for thousands of years um and and uh often they have scores or at\nleast win conditions so it's very easy for reward learning systems to get a reward it's very easy to specify what\nthat reward is um and uh also at the end it's easy to you know to test uh\nexternally you know how strong is your system by of course playing against you know the world's\nstrongest players at those games so it's it's so good for so many reasons and it's also very efficient to run\npotentially millions of simulations in parallel on the cloud so um i think\nthere's a huge reason why we were so successful back in you know starting out 2010 how come we were able to progress\nso quickly because we'd utilize games and um you know at the beginning of deep\nmind we also hired some amazing game engineers uh who i knew from my previous uh lives in the games industry and uh\nand that helped to bootstrap us very quickly and plus it's somehow super compelling almost at a philosophical\nlevel of man versus machine over over a chessboard or a go board\nand especially given that the entire history of ai is defined by people saying it's going to be impossible to\nmake a machine that beats a human being in chess and then once that happened\npeople were certain when i was coming up in ai that go is not a game that could be solved\nbecause of the combinatorial complexity it's just too it's it's it's you know\nno matter how much moore's law you have compute is just never going to be able to crack the game of go yeah and so that\nthen there's something compelling about facing sort of taking on the impossibility of that task from the\nai researcher perspective engineer perspective and then as a human being\njust observing this whole thing your beliefs about what you thought was\nimpossible being broken apart\nit's it's uh humbling to realize we're not as smart as we thought it's humbling to realize that the things\nwe think are impossible now perhaps will be done in the future there's something\nreally powerful about a game ai system being a human being in a game that\ndrives that message uh home for like millions billions of people especially in the case of go sure\nwell look i think it's a i mean it has been a fascinating journey and and especially as i i think about it from i\ncan understand it from both sides both as the ai you know creators of the ai um but also\nas a games player originally so you know it was a it was a really interesting it was i mean it was a fantastic um but\nalso somewhat bittersweet moment the alphago match for me um uh seeing that and and and being obviously heavily\nheavily involved in that um but you know as you say chess has been uh the i mean\nkasparov i think rightly called it the drosophila of of intelligence right so it's sort of i i love that phrase and\nand i think he's right because chess has been um hand in hand with ai from the\nbeginning of the the whole field right so i think every ai practitioner starting with turing and claude shannon\nand all those uh the sort of forefathers of of of of the field um tried their\nhand at writing a chess program uh i've got original audition of claude shannon's first chess program i think it\nwas 1949 uh the the original sort of uh paper and um they all did that and\nturing famously wrote a chess program that but all the computers around there were obviously too slow to run it so he\nhad to run he had to be the computer right so he literally i think spent two or three days running his own program by\nhand with pencil and paper and playing playing a friend of his uh with his chess program so\nof course deep blue was a huge moment uh beating off um but actually when that happened i\nremember that very very vividly of course because it was you know chess and computers and ai all the things i loved\nand i was at college at the time but i remember coming away from that being more impressed by kasparov's mind than i\nwas by deep blue because here was kasparov with his human mind not only could he play chess more or less to the\nsame level as this brute of a calculation machine um but of course kasparov can do everything else humans\ncan do ride a bike talk many languages do politics all the rest of the amazing things that kasparov does and so with\nthe same brain yeah and and yet deep blue uh brilliant as it was at chess it\nhad been hand coded for chess and um actually had distilled the knowledge of\nchess grand masters uh into into a cool program but it couldn't do anything else like it couldn't even play a strictly\nsimpler game like tic-tac-toe so um something to me was missing from um\nintelligence from that system that we would regard as intelligence and i think it was this idea of generality and and\nalso learning yeah um so and that's what we tried to do out with alphago yeah we\nalphago and alpha zero mu zero and then got on all the things that uh we'll get\ninto some parts of there's just a fascinating trajectory here but let's just stick on chess briefly uh on the\nhuman side of chess you've proposed that from a game design perspective the thing that makes chess\ncompelling as a game uh is that there's a creative tension between a bishop\nand the knight can you explain this first of all it's really interesting to think about what\nmakes the game compelling makes it stick across centuries\nyeah i was sort of thinking about this and actually a lot of even amazing chess players don't think about it necessarily from a games designer point of view so\nit's with my game design hat on that i was thinking about this why is chess so compelling and i think a critical uh reason is the\nthe dynamicness of of of the different kind of chess positions you can have whether they're closed or open and other\nthings comes from the bishop and the night so if you think about how different the the the capabilities of\nthe bishop and knight are in terms of the way they move and then somehow chess has evolved to balance those two\ncapabilities more or less equally so they're both roughly worth three points each so you think that dynamics was\nalways there and then the rest of the rules are kind of trying to stabilize the game well maybe i mean it's sort of\ni don't know his chicken and egg situation probably both came together but the fact that it's got to this beautiful equilibrium where you can have\nthe bishop and knight they're so different in power um but so equal in value across the set of the universe of\nall positions right somehow they've been balanced by humanity over hundreds of years um i think gives gives the game\nthe creative tension uh that you can swap the bishop and knights uh for a bishop for a knight and you you they're\nmore or less worth the same but now you aim for a different type of position if you have the knight you want a closed position if you have the bishop you want\nan open position so i think that creates a lot of the creative tension in chess so some kind of controlled creative\ntension from an ai perspective do you think ai systems convention\ndesign games that are optimally compelling to humans well that's an interesting question you\nknow sometimes i get asked about ai and creativity and and this and the way i answered that is relevant to that\nquestion which is that i think they're different levels of creativity one could say so i think um if we define\ncreativity as coming up with something original right that's that's useful for a purpose then you know i think the kind\nof lowest level of creativity is like an interpolation so an averaging of all the examples you see so maybe a very basic\nai system could say you could have that so you show it millions of pictures of cats and then you say give me an average\nlooking cat right generate me an average looking cat i would call that interpolation then there's extrapolation\nwhich something like alphago showed so alphago played you know millions of games of go against itself\nand then it came up with brilliant new ideas like move 37 in game two bringing a motif strategies and go that that no\nhumans had ever thought of even though we've played it for thousands of years and professionally for hundreds of years so that that i call that extrapolation\nbut then that's still there's still a level above that which is you know you could call out the box thinking or true\ninnovation which is could you invent go right could you invent chess and not just come up with a brilliant chess move\nor brilliant go move but can you can you actually invent chess or something as good as chess or go and i think one day\nuh ai could but what's missing is how would you even specify that task to a a\nprogram right now and the way i would do it if i was best telling a human to do it or a games designer a human games\ndesigner to do it is i would say something like go i would say um come up with a game that only takes five\nminutes to learn which go does because it's got simple rules but many lifetimes to master right or impossible to master\nin one lifetime because so deep and so complex um and then it's aesthetically beautiful uh and also uh it can be\ncompleted in three or four hours of gameplay time which is you know useful for our us you know in in a human day\nand so um you might specify these side of high level concepts like that and then you know with that and maybe a few\nother things uh one could imagine that go satisfies uh those those constraints\num but the problem is is that we we're not able to specify abstract notions\nlike that high-level abstract notions like that yet to our ai systems um and i think there's still something missing\nthere in terms of um high-level concepts or abstractions that they truly understand and that you know combinable\nand compositional um so for the moment i think ai is capable of doing\ninterpolation extrapolation but not true invention so coming up with rule sets\nuh and optimizing with complicated objectives around those rule sets we can't currently do\nbut you could take a specific rule set and then run a kind of self-play\nexperiment to see how long just observe how an ai system from scratch learns how long is that journey\nof learning and maybe if it satisfies some of those other things you mentioned in terms of quickness to learn and so on and you\ncould see a long journey to master for even an ai system then you could say that this is a promising game\num but it would be nice to do almost like alpha codes or programming rules so generating rules that kind of\nuh that automate even that part of the generation of rules so i have thought about systems actually um that i think\nwould be amazing in in for a games designer if you could have a system that um takes your game plays it tens of\nmillions of times maybe overnight and then self balances the rules better so it tweaks the the rules and the maybe\nthe equations and the and the and the parameters so that the game uh is more\nbalanced the units in the game or some of the rules could be tweaked so it's a bit of like a giving a base set\nand then allowing a monte carlo tree search or something like that to sort of explore it right and i think that would\nbe super super a powerful tool actually for for balancing auto balancing a game\nwhich usually takes thousands of hours from hundreds of games human games testers normally to to\nbalance some one you know game like starcraft which is you know blizzard are amazing at balancing their games but it\ntakes them years and years and years so one could imagine at some point when this uh this stuff becomes uh efficient\nenough to you know you might be able to do that like overnight do you think a game that is optimal\ndesigned by an ai system would look very much like uh planet\nearth maybe maybe it's only the sort of game i would love to make is is and i've tried\nyou know my in my game's career the games design career you know my first big game was designing a theme park an\namusement park then uh with games like republic i tried to you know have games where we designed whole cities and and\nallowed you to play in so and of course people like will wright have written games like sim earth uh trying to\nsimulate the whole of earth pretty tricky but um i see earth i haven't actually played that one so what is it\ndoes it incorporative evolution or yeah it has evolution and it's sort of um it tries to it sort of treats it as an\nentire biosphere but from quite a high level so nice to be able to sort of zoom in zoom\nout zoom in exactly so obviously he couldn't do that was in the night i think he wrote that in the 90s so it couldn't you know it wasn't it wasn't\nable to do that but that that would be uh obviously the ultimate sandbox game of course on that topic do you think we're living\n"}
{"pod": "Lex Fridman Podcast", "input": "Simulation", "output": "in a simulation yes well so okay so i'm gonna jump around from the absurdly philosophical\nto the short term sure very very happy to so i think uh my answer to that question is a little bit complex because\nuh there is simulation theory which obviously nick bostrom i think famously first proposed um\nand uh i don't quite believe it in in that sense so um in the in the sense\nthat uh are we in some sort of computer game or have our descendants somehow recreated uh uh earth in the you know\n21st century and and some for some kind of experimental reason i think that um\nbut i do think that we that that we might be that the best way to understand physics and the universe is from a\ncomputational perspective so understanding it as an information universe and actually information being\nthe most fundamental unit of uh reality rather than matter or energy so a\nphysicist would say you know matter or energy you know e equals m c squared these are the things that are are the\nfundamentals of the universe i'd actually say information um which of course itself can be can specify energy\nor matter right matter is actually just you know we're we're just out the way our bodies and all the molecules in our\nbody arrange is information so i think information may be the most fundamental way to describe the universe and\ntherefore you could say we're in some sort of simulation because of that um but i don't i do i'm not i'm not really\na subscriber to the idea that um you know these are sort of throw away billions of simulations around i think\nthis is actually very critical and possibly unique this simulation particular one yes so but and you just\nmean treating the universe as a computer that's\nprocessing and modifying information is is a good way to solve the problems of physics of chemistry of biology\nand perhaps of humanity and so on yes i think understanding physics in terms of\ninformation theory uh might be the best way to to really uh understand what's\ngoing on here from our understanding of a universal turing machine from our understanding of\n"}
{"pod": "Lex Fridman Podcast", "input": "Consciousness", "output": "a computer do you think there's something outside of the capabilities of a computer that is present in our\nuniverse you have a disagreement with roger penrose the nature of consciousness he he thinks\nthat consciousness is more than just a computation uh do you think all of it the whole\nshebang is can be can be a competition yeah i've had many fascinating debates with uh sir roger penrose and obviously\nhe's he's famously and i read you know emperors of new mind and and um and his books uh his classical books uh\nand they they were pretty influential and you know in the 90s and um he believes that there's something more you\nknow something quantum that is needed to explain consciousness in the brain um i\nthink about what we're doing actually at deepmind and what my career is being we're almost like true rings champion so\nwe are pushing turing machines or classical computation to the limits what are the limits of what classical\ncomputing can do now um and at the same time i've also studied neuroscience to\nsee and that's why i did my phd in was to see also to look at you know is there anything quantum in the brain from a\nneuroscience or biological perspective and um and so far i think most neuroscientists and most mainstream\nbiologists and neuroscientists would say there's no evidence of any quantum uh systems or effects in the brain as far\nas we can see it's it can be mostly explained by classical uh classical theories so\nand then so there's sort of the the search from the biology side and then at the same time there's the raising of the\nwater uh at the bar from what classical turing machines can do uh uh and\nand you know including our new ai systems and uh as you alluded to earlier\num you know i think ai especially in the last decade plus has been a continual\nstory now of surprising uh events uh and surprising successes knocking over one\ntheory after another of what was thought to be impossible you know from go to protein folding and so on and so i think\num i would be very hesitant to bet against how far the uh universal turing machine\nand classical computation paradigm can go and and my betting would be\nthat all of certainly what's going on in our brain uh can probably be mimicked or\nor approximated on a on a classical machine um not you know not requiring\nsomething metaphysical or quantum and we'll get there with some of the work with alpha fold\nwhich i think begins the journey of modeling this beautiful and complex world of biology so you think all the\nmagic of the human mind comes from this just a few pounds of mush\nof a biological computational mush that's akin to some of the neural networks\nnot directly but in spirit that deep mind has been working with well look i\nthink it's um you say it's a few you know of course it's this is the i think the biggest miracle of the universe is\nthat um it is just a few pounds of mush in our skulls and yet it's also our brains are the most complex objects in\nthe in that we know of in the universe so there's something profoundly beautiful and amazing about our brains\nand i think that it's an incredibly uh incredible efficient machine and and uh\nuh and it's a is you know phenomenal basically and i think that building ai\none of the reasons i want to build ai and i've always wanted to is i think by building an intelligent artifact like ai\nand then comparing it to the human mind um that will help us unlock the\nuniqueness and the true secrets of the mind that we've always wondered about since the dawn of history like consciousness dreaming uh creativity uh\nemotions what are all these things right we've we've wondered about them since since the dawn of humanity and i think\none of the reasons and you know i love philosophy and philosophy of mind is we found it difficult is there haven't been\nthe tools for us to really other than introspection to from very clever people in in history very clever philosophers\nto really investigate this scientifically but now suddenly we have a plethora of tools firstly we have all\nthe neuroscience tools fmri machines single cell recording all of this stuff but we also have the ability computers\nand ai to build uh intelligent systems so i think that um\nuh you know i think it is amazing what the human mind does and um and and i'm kind\nof in awe of it really and uh and i think it's amazing that without human minds we're able to build things like\ncomputers and and actually even you know think and investigate about these questions i think that's also a testament to the human mind yeah the\nuniverse built the human mind that now is building computers that help\nus understand both the universe and our own human mind right that's exactly it i mean i think that's one you know one\ncould say we we are maybe we're the mechanism by which the universe is going to try and understand\nitself yeah it's beautiful so let's let's go to the\n"}
{"pod": "Lex Fridman Podcast", "input": "AlphaFold", "output": "basic building blocks of biology that i think is another angle at which you can start\nto understand the human mind the human body which is quite fascinating which is from the basic building blocks start to\nsimulate start to model how from those building blocks you can construct bigger and bigger more complex\nsystems maybe one day the entirety of the human biology so here's another problem that thought to\nbe impossible to solve which is protein folding and alpha fold or\nspecific alpha fold 2 did just that it solved protein folding i think it's one of the biggest\nbreakthroughs uh certainly in the history of structural biology but uh in general in\nin science um maybe from a high level\nwhat is it and how does it work and then we can ask some fascinating sure questions after sure um so maybe\nlike to explain it uh to people not familiar with protein folding is you know i first of all explain proteins\nwhich is you know proteins are essential to all life every function in your body depends on proteins sometimes they're\ncalled the workhorses of biology and if you look into them and i've you know obviously as part of alpha fold i've been researching proteins and and\nstructural biology for the last few years you know they're amazing little bio nano machines proteins they're\nincredible if you actually watch little videos of how they work animations of how they work and um proteins are specified by their\ngenetic sequence called the amino acid sequence so you can think of those their genetic makeup and then in the body uh\nin in nature they when they when they fold up into a 3d structure so you can think of it as a string of beads and\nthen they fold up into a ball now the key thing is you want to know what that 3d structure is\nbecause the structure the 3d structure of a protein is what helps to determine what does it\ndo the function it does in your body and also if you're interested in drug drugs or disease you need to understand\nthat 3d structure because if you want to target something with a drug compound or about to block that something the\nprotein is doing uh you need to understand where it's going to bind on the surface of the protein so obviously\nin order to do that you need to understand the 3d structure so the structure is mapped to the function the structure is mapped to the function and\nthe structure is obviously somehow specified by the by the amino acid sequence and that's the in essence the\nprotein folding problem is can you just from the amino acid sequence the one-dimensional\nstring of letters can you immediately computationally predict the 3d structure right and this has been a\ngrand challenge in biology for over 50 years so i think it was first articulated by christian anfinsen a\nnobel prize winner in 1972 uh as part of his nobel prize winning lecture and he\njust speculated this should be possible to go from the amino acid sequence to the 3d structure we didn't say how so\ni you know it's been described to me as equivalent to fermat's last theorem but for biology right you should as somebody\nthat uh very well might win the nobel prize in the future but outside of that you should do more of that kind of thing\nin the margins just put random things that will take like 200 years to solve set people off for 200 years it should\nbe possible exactly and just don't give any interest exactly i think everyone's exactly should be i'll have to remember\nthat for future so yeah so he set off you know with this one throwaway remark just like fermat you know he he set off\nthis whole 50-year uh uh uh field really of computational\nbiology and and they had you know they got stuck they hadn't really got very far with doing this and and um until now\nuntil alpha fold came along this is done experimentally right very painstakingly so the rule of thumb is and you have to\nlike crystallize the protein which is really difficult some proteins can't be crystallized like membrane proteins and\nthen you have to use very expensive electron microscopes or x-ray crystallography machines really\npainstaking work to get the 3d structure and visualize the 3d structure so the rule of thumb in in experimental biology\nis that it takes one phd student their entire phd to do one protein uh and with\nalpha fold two we were able to predict the 3d structure in a matter of seconds\num and so we were you know over christmas we did the whole human proteome or every protein in the human\nbody all 20 000 proteins so the human proteins like the equivalent of the human genome but on protein space and uh\nand sort of revolutionize really what uh a structural biologist can do because\nnow um they don't have to worry about these painstaking experimentals you know should they put all of that effort in or\nnot they can almost just look up the structure of their proteins like a google search and so there's a data set on which it's\ntrained and how to map this amino acids because first of all it's incredible that a protein this little chemical\ncomputer is able to do that computation itself in some kind of distributed way and do it very quickly\nthat's a weird thing and they evolved that way because you know in the beginning i mean that's a great invention just the\nprotein itself yes i mean and then they there's i think probably a history of\nlike uh they evolved to have many of these proteins and those proteins figure out how to be computers\nthemselves in such a way that you can create structures that can interact in complexes with each other in order to\nform high level functions i mean it's a weird system that they figured it out well for sure i mean we you know maybe\nwe should talk about the origins of life too but proteins themselves i think are magical and incredible uh uh uh as i\nsaid little little bio-nano machines and um and and actually levantal who is another\nscientist uh uh a contemporary of anfinsen uh he he coined this eleventh\nhouse what became known as levantal's paradox which is exactly what you're saying he calculated roughly a protein\nan average protein which is maybe 2 000 amino acids bases long is um\nis is can fold in maybe 10 to the power 300 different conformations so there's\n10 to the power 300 different ways that protein could fold up and yet somehow in nature physics solves this solves this\nin a matter of milliseconds so proteins fold up in your body in you know sometimes in fractions of a second so\nphysics is somehow solving that search problem and just to be clear in many of these cases maybe you correct me if i'm\nwrong there's often a unique way for that sequence to form itself yes so\namong that huge number of possibilities yes it figures out a way how to stability\nuh in some cases there might be a misfunction so on which leads to a lot of the disorders and stuff like that but\nyes most of the time it's a unique mapping and that unique mapping is not obvious no exactly that's just what the\nproblem is exactly so there's a unique mapping usually in a healthy in if it's healthy and as you say in disease\nso for example alzheimer's one one one conjecture is that it's because of a misfolded protein a protein that folds\nin the wrong way amyloid beta protein so um and then because it falls in the wrong way it gets tangled up right in\nyour in your neurons so um it's super important to understand both healthy functioning and also\ndisease is to understand uh you know what what these things are doing and how they're structuring of course the next\nstep is sometimes proteins change shape when they interact with something so um they're not just static necessarily in\nin biology maybe you can give some interesting sort of beautiful things to you about these\nearly days of alpha fold of of solving this problem because unlike games this is\nreal physical systems that are less amenable to\nself-play type of mechanisms the the size of the data set is smaller that you might otherwise like so you\nhave to be very clever about certain things is there something you could speak to um what was very hard to solve and what are\nsome beautiful aspects about the the solution yeah i would say alpha fold is the most complex and also probably most\nmeaningful system we've built so far so it's been an amazing time actually in the last you know two three years to see\nthat come through because um as we talked about earlier you know games is what we started on uh building things\nlike alphago and alpha zero but really the ultimate goal was to um not just to crack games it was just to to to build\nuse them to bootstrap general learning systems we could then apply to real world challenges specifically my passion\nis scientific challenges like protein folding and then alpha fold of course is our first big proof point of that and so\num you know in terms of the data uh and the amount of innovations that had to go into it we you know it was like more\nthan 30 different component algorithms needed to be put together to crack the protein folding um i think some of the\nbig innovations were that um kind of building in some hard coded constraints around physics and\nevolutionary biology um to constrain sort of things like the bond angles uh\nuh in the in the in the protein and things like that um a lot but not to impact the learning\nsystem so still allowing uh the system to be able to learn the physics uh\nitself um from the examples that we had and the examples as you say there are only about 150 000 proteins even after\n40 years of experimental biology only around 150 000 proteins have been the structures have been found out about so\nthat was our training set which is um much less than normally we would like to use\nbut using various tricks things like self distillation so actually using alpha folds predictions um some of the\nbest predictions that it thought was highly confident in we put them back into the training set right to make the\ntraining set bigger that was critical to to alpha fold working so there was actually a huge\nnumber of different um uh innovations like that that were required to to ultimately crack the problem after fold\none what it produced was a distagram so a kind of a matrix of the pairwise distances\nbetween all of the molecules in the in the in the protein and then there had to be a separate optimization process to uh\ncreate the 3d structure and what we did for alpha volt2 is make it truly end to end so we went straight\nfrom the amino acid sequence of of of bases to the 3d structure directly without going\nthrough this intermediate step and in machine learning what we've always found is that the more end to end you can make\nit the better the system and it's probably because um we you know the in\nthe end the system is better at learning what the constraints are than than we are as the human designers of specifying\nit so anytime you can let it flow end to end and actually just generate what it is you're really looking for in this\ncase the 3d structure you're better off than having this intermediate step which you then have to hand craft the next\nstep for so so it's better to let the gradients and the learning flow all the way through the system um from the end point the end\noutput you want to the inputs so that's a good way to start a new problem handcraft a bunch of stuff add a bunch\nof manual constraints with a small intent learning piece or a small learning piece and grow that learning\npiece until it consumes the whole thing that's right and so you can also see you know this is a bit of a method we've\ndeveloped over doing many sort of successful outfits we call them alpha x projects right is and the easiest way to\nsee that is the evolution of alphago to alpha zero so alphago was um a learning\nsystem but it was specifically trained to only play go right so uh and what we wanted to do with first version of go is\njust get to world champion performance no matter how we did it right and then and then of course alphago zero we we we\nremoved the need to use human games as a starting point right so it could just play against itself from random starting\npoint from the beginning so that removed the the need for human knowledge uh about go and then finally alpha zero\nthen generalized it so that any things we had in there the system including things like symmetry of the go board uh\nwere removed so the alpha zero could play from scratch any two player game and then mu0 which is the final\nlatest version of that set of things was then extending it so that you didn't even have to give it the rules of the\ngame it would learn that for itself so it could also deal with computer games as well as board games so that line of\nalpha golf goes zero alpha zero mu zero that's the full trajectory of what you\ncan take from uh imitation learning to full self\nsupervised learning yeah exactly and learning learning uh the entire structure of the environment you put in\nfrom scratch right and and and and bootstrapping it uh through self-play uh yourself but the thing is it would have\nbeen impossible i think or very hard for us to build alpha zero or mu0 first out of the box\neven psychologically because you have to believe in yourself for a very long time you're constantly dealing with doubt\nbecause a lot of people say that it's impossible exactly so it was hard enough just to do go as you were saying everyone thought that was impossible or\nat least a decade away um from when we when we did it back in 2015 24 you know\n2016 and um and so yes it would have been psychologically probably very difficult\nas well as the fact that of course we learnt a lot by building alphago first right so it's i think this is why i call\nai in engineering science it's one of the most fascinating science disciplines but it's also an engineering science in\nthe sense that unlike natural sciences um the phenomenon you're studying it doesn't exist out in nature you have to\nbuild it first so you have to build the artifact first and then you can study how how and pull it apart and how it\nworks this is tough to uh ask you this question because you probably will say it's everything but\nlet's let's try let's try to think to this because you're in a very interesting position where deepmind is\n"}
{"pod": "Lex Fridman Podcast", "input": "Solving intelligence", "output": "the place of some of the most uh brilliant ideas in the history of ai but it's also a place of brilliant\nengineering so how much of solving intelligence this big goal for deepmind how much of it is\nscience how much is engineering so how much is the algorithms how much is the data how much is the\nhardware compute infrastructure how much is it the software computer infrastructure yeah um what else is\nthere how much is the human infrastructure and like just the humans interact in certain kinds of ways in all the space\nof all those ideas how much does maybe like philosophy how much what's the key if um\nuh if if you were to sort of look back like if we go forward 200 years look back\nwhat was the key thing that solved intelligence is that ideas i think it's a combination first of all\nof course it's a combination of all those things but the the ratios of them changed over over time\nso yeah so um even in the last 12 years so we started deep mine in 2010 which is hard to imagine now because 2010 it's\nonly 12 short years ago but nobody was talking about ai uh you know if you remember back to your mit days you know\nno one was talking about it i did a postdoc at mit back around then and it was sort of thought of as a well look we\nknow ai doesn't work we tried this hard in the 90s at places like mit mostly losing using logic systems and\nold-fashioned sort of good old-fashioned ai we would call it now um people like minsky and and and patrick winston and\nyou know all these characters right and used to debate a few of them and they used to think i was mad thinking about that some new advance could be done with\nlearning systems and um i was actually pleased to hear that because at least you know you're on a unique track at\nthat point right even if every all of your you know professors are telling you you're mad that's true and of course in\nindustry uh you can we couldn't get you know as difficult to get two cents together uh and which is hard to imagine\nnow as well given it's the biggest sort of buzzword in in vcs and and fundraising's easy and all these kind of\nthings today so back in 2010 it was very difficult and what we the reason we started then and\nshane and i used to discuss um uh uh what were the sort of founding tenets of deep mind and it was very various things\none was um algorithmic advances so deep learning you know jeff hinton and cohen just had just sort of invented that in\nacademia but no one in industry knew about it uh we love reinforcement learning we thought that could be scaled\nup but also understanding about the human brain had advanced um quite a lot uh in the decade prior with fmri\nmachines and other things so we could get some good hints about architectures and algorithms and and sort of um\nrepresentations maybe that the brain uses so as at a systems level not at a implementation level um and then the\nother big things were compute and gpus right so we could see a compute was going to be really useful and it got to\na place where it became commoditized mostly through the games industry and and that could be taken advantage of and\nthen the final thing was also mathematical and theoretical definitions of intelligence so things like ai xi aix\nwhich uh shane worked on with his supervisor marcus hutter which is a sort of theoretical uh proof really of\nuniversal intelligence um which is actually a reinforcement learning system um in the limit i mean it assumes\ninfinite compute and infinite memory in the way you know like a turing machine proof but i was also waiting to see\nsomething like that too to you know like turing machines uh and and computation theory that people like turing and\nshannon came up with underpins modern computer science um uh you know i was waiting for a theory like that to sort\nof underpin agi research so when i you know met shane and saw he was working on something like that you know that to me\nwas a sort of final piece of the jigsaw so in the early days i would say that\nideas were the most important uh you know and for us it was deep reinforcement learning scaling up deep\nlearning um of course we've seen transformers so huge leaps i would say you know three or four from for if you\nthink from 2010 until now uh huge evolutions things like alphago um and um\nand and maybe there's a few more still needed but as we get closer to ai agi um\ni think engineering becomes more and more important and data because scale and of course the the recent you know\nresults of gpt3 and all the big language models and large models including our ones uh has shown that scale is a is and\nlarge models are clearly going to be unnecessary but perhaps not sufficient part of an agi solution and\nthroughout that like you said and i'd like to give you a big thank you you're one of the pioneers in this is\nsticking by ideas like reinforcement learning that this can actually work\ngiven actually limited success in the past and also\nwhich we still don't know but proudly having the best researchers in the world\nand talking about solving intelligence so talking about whatever you call it agi or something like this\nthat speaking of mit that's that's just something not you wouldn't bring up no uh not not maybe you did in uh like 40\n50 years ago but that was um ai was a place where you do tinkering\nvery small scale not very ambitious projects and maybe the biggest ambitious projects\nwere in the space of robotics and doing like the darpa challenge sure but the task of solving intelligence and\nbelieving you can that's really really powerful so in order for engineering to do its work\nto have great engineers build great systems you have to have that belief that threats throughout the whole thing\nthat you can actually solve some of these impossible challenges yeah that's right and and back in 2010 you know our\nmission statement um and still is today you know it was used to be uh solving step one solve intelligence step two use\nit to solve everything else yes so if you can imagine pitching that to a vc in 2010 you know the kind of looks we we\ngot we managed to you know find a few uh kooky people to back us but it was uh it was tricky and and i and i got to the\npoint where we we wouldn't mention it to any of our professors because they would just eye roll and think we you know\ncommitted career suicide and and uh and and you know so it was there's a lot of things that we had to do but we always\nbelieved it and one reason you know by the way one reason we i believe i've always believed in reinforcement learning is that\nthat if you look at neuroscience that is the way that the you know primate brain learns one of the main mechanisms is the\ndopamine system implement some form of td learning a very famous result in the late 90s uh where they saw this in\nmonkeys and uh and as a you know proper game prediction error so we you know again in the limit this is this is what\ni think you can use neuroscience for is is you know any at mathematics you when you're when you're doing something as\nambitious as trying to solve intelligence and you're you're you know it's blue sky research no one knows how to do it you you you need to use any\nevidence or any source of information you can to help guide you in the right direction or give you confidence you're\ngoing in the right direction so so that that was one reason we pushed so hard on that and that's and just going back to\nyour early question about organization the other big thing that i think we innovated with at deepmind to encourage\ninvention and and uh and innovation was the multi-disciplinary organization we\nbuilt and we still have today so deepmind originally was a confluence of the of the most cutting-edge knowledge\nin neuroscience with machine learning engineering and mathematics right and and gaming\nand then since then we built that out even further so we have philosophers here and and uh by you know ethicists\nbut also other types of scientists physicists and so on um and that's what brings together i tried to build a sort\nof um new type of bell labs but in this golden era right uh\nand and a new expression of that um to try and uh foster this incredible sort\nof innovation machine so talking about the humans in the machine the mind itself is a learning machine\nwith a lots of amazing human minds in it coming together to try and build these uh learning systems\nif we return to the big ambitious dream of alpha fold that may be the early steps on a very\nlong journey in um in biology\ndo you think the same kind of approach can use to predict the structure and function of more complex biological\nsystems so multi-protein interaction and then i mean you can go out from there just\nsimulating bigger and bigger systems that eventually simulate something like the human brain or the human body just\nthe big mush the mess of the beautiful resilient mesobiology do do you see that\nas a long-term vision i do and i think um you know if you think about what are the\nthings top things i wanted to apply ai ai2 once we had powerful enough systems biology and curing diseases and\nunderstanding biology uh was right up there you know top of my list that's one of the reasons i personally pushed that\nmyself and with alpha fold but i think alpha fold uh amazing as it is is just\nthe beginning um and and and i hope it's evidence of uh what could be done with\ncomputational methods so um you know alpha fold solve this this huge problem of the structure of proteins but biology\nis dynamic so really what i imagine from here we're working on all these things now is protein protein interaction uh\nprotein ligand binding so reacting with molecules um then you want to get build up to pathways and then eventually a\nvirtual cell that's my dream uh maybe in the next 10 years and i've been talking actually to a lot of biologists friends\nof mine paul nurse who runs the qrik institute amazing biologist nobel prize winning biologist we've been discussing\nfor 20 years now virtual cells could you build a virtual simulation of a cell and\nif you could that would be incredible for biology and disease discovery because you could do loads of experiments on the virtual cell and then\nonly at the last stage validate it in the wet lab so you could you know in terms of the search space of discovering\nnew drugs you know it takes 10 years roughly to go from uh uh to to go from uh you know identifying a target to uh\nhaving a drug candidate um maybe that could be shortened to you know by an order of magnitude with if you could do\nmost of that that that work in silico so in order to get to a virtual cell\nwe have to build up uh uh understanding of different parts of biology and the interactions and and um so you know\nevery every few years we talk about this with i talked about this with paul and then finally last year after alpha fault\ni said now is the time we can finally go for it and and alpha falls the first proof point that this might be possible\nuh and he's very excited when we have some collaborations with his with his lab they're just across the road actually from us as you know wonderful\nbeing here in king's cross with the quick institute across the road and um and i think the next steps you know i\nthink there's going to be some amazing advances in biology built on top of things like alpha fold uh we're already\nseeing that with the community doing that after we've open sourced it and released it um and uh you know i also i\noften say that i think uh if you think of mathematics is the perfect description language for physics\ni think ai might be end up being the perfect description language for biology because\nbiology is so messy it's so emergent so dynamic and complex um i think i find it\nvery hard to believe we'll ever get to something as elegant as newton's laws of motions to describe a cell right it's\njust too complicated um so i think ai is the right tool for this you have to uh\nyou have to start at the basic building blocks and use ai to run the simulation for all those building blocks so have a\nvery strong way to do prediction of what given these building blocks what kind of biology how the\nthe function and the evolution of that biological system it's almost like a cellular automata you\nhave to run you can't analyze it from a high level you have to take the basic ingredients figure out the rules yeah\nand let it run but in this case the rules are very difficult to figure out yes yes learn them that's exactly it so\nit's the biology is too complicated to figure out the rules it's it's it's too emergent too dynamic say compared to a\nphysics system like the motion of a planet yeah right and and so you have to learn the rules and that's exactly the\ntype of systems that we're building so you you mentioned you've open sourced alpha fold and even the data involved\n"}
{"pod": "Lex Fridman Podcast", "input": "Open sourcing AlphaFold & MuJoCo", "output": "to me personally also really happy and a big thank you for open sourcing mijoko\nuh the physics simulation engine that's that's often used for robotics research\nand so on so i think that's a pretty gangster move uh so what what's the\nwhat's i mean this uh very few companies or people would do\nthat kind of thing what's the philosophy behind that you know it's a case-by-case basis and in both those cases we felt\nthat was the maximum benefit to humanity to do that and and the scientific community in one case the robotics uh\nphysics community with mojoco so purchased it we purchased to obs we purchased it for the express\nprinciple to open source it so um so you know i hope people appreciate that\nit's great to hear that you do and then the second thing was and mostly we did it because the person building it is uh\nuh would not it was not able to cope with supporting it anymore because it was it got too big for him his amazing\nprofessor uh who who built it in the first place so we helped him out with that and then with alpha folds even\nbigger i would say and i think in that case we decided that there were so many downstream applications of alpha fold um\nthat we couldn't possibly even imagine what they all were so the best way to accelerate uh drug discovery and also\nfundamental research would be to to um give all that data away and and and the\nand the and the system itself um you know it's been so gratifying to see what people have done that within just one\nyear which is a short amount of time in science and uh it's been used by over 500 000 researchers have used it we\nthink that's almost every biologist in the world i think there's roughly 500 000 biologists in the world professional biologists have used it to to look at\ntheir proteins of interest we've seen amazing fundamental research done so a couple of weeks ago front\ncover there was a whole special issue of science including the front cover which had the nuclear pore complex on it which\nis one of the biggest proteins in the body the nuclear poor complex is a protein that governs all the nutrients\ngoing in and out of your cell nucleus so they're like little hole gateways that open and close to let things go in and\nout of your cell nucleus so they're really important but they're huge because they're massive doughnut rings shaped things and they've been looking\nto try and figure out that structure for decades and they have lots of you know experimental data but it's too low\nresolution there's bits missing and they were able to like a giant lego jigsaw puzzle use alpha fold predictions plus\nexperimental data and combined those two independent sources of information uh actually four different groups around\nthe world were able to put it together the sec more or less simultaneously using alpha fault predictions so that's\nbeen amazing to see and pretty much every pharma company every drug company executive i've spoken to has said that\ntheir teams are using alpha fold to accelerate whatever drugs uh uh they're\ntrying to discover so i think the knock-on effect has been enormous in terms of uh the impact that uh\nalpha-fold has made and it's probably bringing in it's creating biologists it's bringing more people into the field\num both on the excitement and both on the technical skills involved and um\nit's almost like uh a gateway drug to biology yes it is you get more computational people involved too\nhopefully and and i think for us you know the next stage as i said you know in future we have to have other\nconsiderations too we're building on top of alpha fold and these other ideas i discussed with you about protein protein interactions and and genomics and other\nthings and not everything will be open source some of it will will do commercially because that will be the best way to actually get the most\nresources and impact behind it in other ways some other projects will do non-profit style um and also we have to\nconsider for future things as well safety and ethics as well like but you know synthetic biology there are you\nknow there is dual use and we have to think about that as well with alpha fold we you know we consulted with 30\ndifferent bioethicists and and other people expert in this field to make sure it was safe before um we released it so\nthere'll be other considerations in future but for right now you know i think alpha fold is a kind of a gift from us to to to the scientific\ncommunity so i'm pretty sure that something like alpha fold\nuh would be part of nobel prizes in the future but us humans of course are horrible\nwith credit assignment so we'll of course give it to the humans do you think there will be a day\nwhen ai system can't be denied that it earned that nobel prize do you\nthink we'll see that in 21st century it depends what type of ais we end up building right whether they're um\nyou know goal seeking agents who specifies the goals uh who comes up with the hypotheses\nwho you know who determines which problems to tackle right so i think it's about an announcement yeah so it's\nannouncing the results exactly as part of it um so i think right now of course it's it's it's it's amazing human\ningenuity that's behind these systems and then the system in my opinion is just a tool you know it'd be a bit like\nsaying with galileo and his telescope you know the ingenuity the the the credit should go to the telescope i mean\nit's clearly galileo building the tool which he then uses so i still see that in the same way\ntoday even though these tools learn for themselves um they're i think i think of things like alpha fold and that the\nthings we're building as the ultimate tools for science and for acquiring new knowledge to help us as scientists\nacquire new knowledge i think one day there will come a point where an ai system may solve or come up with\nsomething like general relativity of its own bat not just by averaging everything on the internet or\naveraging everything on pubmed although that would be interesting to see what that would come up with um so\nthat to me is a bit like our earlier debate about creativity you know inventing go rather than just coming up\nwith a good go move and um so i think uh solving i think to to you know if we\nwanted to give it the credit of like a nobel type of thing then it would need to invent go uh and sort of invent that\nnew conjecture out of the blue um rather than being specified by the the human\nscientists or the human creators so i think right now that's it's definitely just a tool although it is interesting\nhow far you get by averaging everything on the internet like you said because you know a lot of people do see science as you're\nalways standing on the shoulders of giants and the question is how much are you really\nreaching up above the shoulders of giants maybe it's just assimilating different kinds\nof results of the past with ultimately this new perspective that gives you this breakthrough idea\nbut that idea may not be novel in the way that we can't be already discovered on the internet maybe\nthe nobel prizes of the next 100 years are already all there on the internet to be discovered\nthey could be they could be i mean i think um this is one of the big mysteries i think\nis that uh uh i i first of all i believe a lot of the big new breakthroughs that are going\nto come in the next few decades and even in the last decade are going to come at the intersection between different subject areas where um there'll be some\nnew connection that's found between what seemingly with disparate areas and and one can even think of deep mind as i\nsaid earlier as a sort of interdisciplinary between neuroscience ideas and ai engineering ideas uh\noriginally and so um so i think there's that and then one of the things we can't\nimagine today is and one of the reasons i think people we were so surprised by how well large models worked is that\nactually it's very hard for our human minds our limited human minds to understand what it would be like to read the whole\ninternet right i think we can do a thought experiment and i used to do this of like well what if i read the whole of\nwikipedia what would i know and i think our minds can just about comprehend maybe what that would be like but the whole\ninternet is beyond comprehension so i think we just don't understand what it would be like to be able to hold all of\nthat in mind potentially right and then active at once and then maybe what are\nthe connections that are available there so i think no doubt there are huge things to be discovered just like that\nbut i do think there is this other type of creativity of true spark of new knowledge new idea never thought before\nabout can't be average from things that are known um that really of course everything come you know nobody creates\nin a vacuum so there must be clues somewhere but just a unique way of putting those things together i think\nsome of the greatest scientists in history have displayed that i would say although it's very hard to know going\nback to their time what was exactly known uh when they came up with those things although\nyou're making me really think because just the thought experiment of deeply knowing a hundred wikipedia pages\ni don't think i can um i've been really impressed by wikipedia for for technical topics yeah so if you\nknow a hundred pages or a thousand pages i don't think who can visually truly\ncomprehend what's what kind of intelligence that is that's a pretty powerful intelligence if you\nknow how to use that and integrate that information correctly yes i think you can go really far you can probably\nconstruct thought experiments based on that like simulate different ideas so if this\nis true let me run this thought experiment then maybe this is true it's not really invention it's like just\ntaking literally the knowledge and using it to construct a very basic simulation of the world i mean some argue it's\nromantic in part but einstein would do the same kind of things with a thought experiment yeah one could imagine doing\nthat systematically across millions of wikipedia pages plus pubmed all these things i think there are\nmany many things to be discovered like that they're hugely useful you know you could imagine and i want us to do some\nof those things in material science like room temperature superconductors or something on my list one day i'd like to\nlike you know have an ai system to help build better optimized batteries all of these sort of mechanical things mr i\nthink a systematic sort of search could be uh guided by a model could be um could be\nextremely powerful so speaking of which you have a paper on nuclear fusion\n"}
{"pod": "Lex Fridman Podcast", "input": "Nuclear fusion", "output": "uh magnetic control of tokamak plasmas to deep reinforcement learning so you uh\nyou're seeking to solve nuclear fusion with deep rl so it's doing control of high temperature plasmas can you explain this\nwork and uh can ai eventually solve nuclear fusion it's been very fun last year or two and\nvery productive because we've been taking off a lot of my dream projects if you like of things that i've collected over the years of\nareas of science that i would like to i think could be very transformative if we helped accelerate and uh really\ninteresting problems scientific challenges in of themselves this is energy so energy yes exactly so\nenergy and climate so we talked about disease and biology as being one of the biggest places i think ai can help with\ni think energy and climate uh is another one so maybe they would be my top two um\nand fusion is one one area i think ai can help with now fusion has many challenges mostly physics material\nscience and engineering challenges as well to build these massive fusion reactors and contain the plasma and what\nwe try to do whenever we go into a new field to apply our systems is we look for um\nwe talk to domain experts we try and find the best people in the world to collaborate with um\nin this case in fusion we we collaborated with epfl in switzerland the swiss technical institute who are amazing they have a test reactor that\nthey were willing to let us use which you know i double checked with the team we were going to use carefully and safely\ni was impressed they managed to persuade them to let us use it and um and it's a it's an amazing test reactor they have\nthere and they try all sorts of pretty crazy experiments on it and um the the\nthe what we tend to look at is if we go into a new domain like fusion what are all the bottleneck problems uh like\nthinking from first principles you know what are all the bottleneck problems that are still stopping fusion working today and then we look at we you know we\nget a fusion expert to tell us and then we look at those bottlenecks and we look at the ones which ones are amenable to\nour ai methods today yes right and and and then and would be interesting from a research perspective from our point of\nview from an ai point of view and that would address one of their bottlenecks and in this case plasma control was was\nperfect so you know the plasma it's a million degrees celsius something like that it's hotter than the sun\nand there's obviously no material that can contain it so they have to be containing these magnetic very powerful\nsuperconducting magnetic fields but the problem is plasma is pretty unstable as you imagine you're kind of holding a\nmini sun mini star in a reactor so you know you you kind of want to predict\nahead of time what the plasma's going to do so you can move the magnetic field within a few\nmilliseconds you know to to basically contain what it's going to do next so it seems like a perfect problem if you\nthink of it for like a reinforcement learning prediction problem so uh you know your controller you're gonna move\nthe magnetic field and until we came along you know they were they were doing it with with traditional operational uh\nresearch type of uh controllers uh which are kind of handcrafted and the problem is of course they can't react in the\nmoment to something the plasma's doing that they have to be hard-coded and again knowing that that's normally our\ngo-to solution is we would like to learn that instead and they also had a simulator of these plasma so there were\nlots of criteria that matched what we we like to to to use so can ai eventually solve nuclear\nfusion well so we with this problem and we published it in a nature paper last year uh we held the fusion that we held\nthe plasma in specific shapes so actually it's almost like carving the plasma into different shapes and control\nand hold it there for the record amount of time so um so that's one of the problems of of fusion sort of um solved\nso i have a controller that's able to no matter the shape uh contain it continue yeah contain it and hold it in structure\nand there's different shapes that are better for for the energy productions called droplets and and and so on so um\nso that was huge and now we're looking we're talking to lots of fusion startups to see what's the next problem we can\ntackle uh in the fusion area so another fascinating place\n"}
{"pod": "Lex Fridman Podcast", "input": "Quantum simulation", "output": "in a paper title pushing the frontiers of density functionals by solving the fractional electron problem so you're\ntaking on modeling and simulating the quantum mechanical behavior of electrons yes\num can you explain this work and can ai model and simulate arbitrary quantum\nmechanical systems in the future yeah so this is another problem i've had my eye on for you know a decade or more which\nis um uh sort of simulating the properties of electrons if you can do that you can\nbasically describe how elements and materials and substances work so it's\nkind of like fundamental if you want to advance material science um and uh you know we have schrodinger's equation and\nthen we have approximations to that density functional theory these things are you know are famous and um people\ntry and write approximations to to these uh uh to these functionals and and kind of come up with descriptions of the\nelectron clouds where they're gonna go how they're gonna interact when you put two elements together uh and what we try\nto do is learn a simulation uh uh learner functional that will describe more chemistry types of chemistry so um\nuntil now you know you can run expensive simulations but then you can only simulate very small uh molecules very\nsimple molecules we would like to simulate large materials um and so uh today there's no way of doing that and\nwe're building up towards uh building functionals that approximate schrodinger's equation and then allow\nyou to describe uh what the electrons are doing and all materials sort of science and\nmaterial properties are governed by the electrons and and how they interact so have a good summarization of the\nsimulation through the functional um but one that is still\nclose to what the actual simulation would come out with so what um how difficult is that to ask what's\ninvolved in that task is it running those those complicated simulations yeah and learning the task of mapping from the\ninitial conditions and the parameters of the simulation learning what the functional would be yeah so it's pretty\ntricky and we've done it with um you know the nice thing is we there are we can run a lot of the simulations that\nthe molecular dynamics simulations on our compute clusters and so that generates a lot of data so in this case\nthe data is generated so we like those sort of systems and that's why we use games simulator generated data\nand we can kind of create as much of it as we want really um and just let's leave some you know if any computers are\nfree in the cloud we just run we run some of these calculations right compute cluster calculation that's all the the\nfree compute times used up on quantum mechanics quantum mechanics exactly simulations and protein simulations and\nother things and so um and so you know when you're not searching on youtube for video cat videos we're using those\ncomputers usefully and quantum chemistry that's the idea and and putting them for good use and\nthen yeah and then all of that computational data that's generated we can then try and learn the functionals\nfrom that which of course are way more efficient once we learn the functional than um\nrunning those simulations would be do you think one day ai may allow us to\n"}
{"pod": "Lex Fridman Podcast", "input": "Physics", "output": "do something like basically crack open physics so do something like travel faster than the speed of light\nmy ultimate aim has always been with ai is um the reason i am personally working on\nai for my whole life it was to build a tool to help us understand stand the universe so i wanted to and that means\nphysics really and the nature of reality so um uh i don't think we have systems that\nare capable of doing that yet but when we get towards agi i think um that's one of the first things i think we should\napply agi to i would like to test the limits of physics and our knowledge of physics there's so many things we don't know\nthere's one thing i find fascinating about science and you know as a huge proponent of the scientific method as\nbeing one of the greatest ideas humanity's ever had and allowed us to progress with our knowledge\nbut i think as a true scientist i think what you find is the more you find out uh you the more you realize we don't\nknow and and i always think that it's surprising that more people don't aren't troubled you know every night i think\nabout all these things we interact with all the time that we have no idea how they work time\nconsciousness gravity life we can't i mean these are all the fundamental things of nature i think the\nway we don't really know what they are to live life we uh pin certain\nassumptions on them and kind of treat our assumptions as if they're a fact yeah that allows us to sort of box them\noff somehow yeah box them off but the reality is when you think of time\nyou should remind yourself you should put it off the sh take it off the shelf and realize like\nno we have a bunch of assumptions there's still a lot of there's even now a lot of debate there's a lot of uncertainty about exactly what is time\nuh is there an error of time you know there's there's a lot of fundamental questions you can't just make\nassumptions about and maybe ai allows you to um\nnot put anything on the shelf yeah not make any uh hard assumptions and really open it up and see what\nexactly i think we should be truly open-minded about that and uh exactly that not be dogmatic to a particular\ntheory um it'll also allow us to build better tools experimental tools eventually\nthat can then test certain theories that may not be testable today about as things about like\nwhat we spoke about at the beginning about the computational nature of the universe how one might if that was true\nhow one might go about testing that right and and how much uh you know there are people who've conjectured people\nlike uh scott aronson and others about uh you know how much information can a specific planck unit of space and time\ncontain right so one might be able to think about testing those ideas if you had um\nai helping you build some new exquisite uh uh experimental tools this is what i\nimagine you know many decades from now we'll be able to do and what kind of questions can be answered through\nrunning a simulation of of them so there's a bunch of physics simulations you can imagine that could\nbe run in an uh so some kind of efficient way much like you're doing in the quantum\nsimulation work and perhaps even the origin of life so figuring out how\ngoing even back before the work of alpha fault begins of how this whole whole thing\num emerges from a rock yes from a static thing would what do you do you think ai\nwill allow us to is that something you have your eye on it's trying to understand the origin of life first of\n"}
{"pod": "Lex Fridman Podcast", "input": "Origin of life", "output": "all yourself what do you think um how the heck did life originate on earth\nyeah well maybe we i'll come to that in a second but i think the ultimate use of ai is to\nkind of use it to accelerate science to the maximum so i um think of it a little bit like the\ntree of all knowledge if you imagine that's all the knowledge there is in the universe to attain and we sort of barely scratched the\nsurface of that so far in even though you know we've we've done pretty well since the enlightenment right as\nhumanity and i think ai will turbo charge all of that like we've seen with alpha fold and i want to explore as much\nof that tree of knowledge as it's possible to do and um and i think that involves ai helping us with with with\nunderstanding or finding patterns um but also potentially designing and building new tools experimental tools so i think\nthat's all uh and also running simulations and learning simulations all of that we're\nalready we're sort of doing it at a at a at a you know baby steps level here but\ni can imagine that in in in the decades to come as uh you know what's the full\nflourishing of of that line of thinking it's going to be truly incredible i would say if i visualize this tree of\nknowledge something tells me that that knowledge for tree of knowledge for humans is much smaller\nin the set of all possible trees of knowledge is actually quite small giving our cognitive\nlimitations limited cognitive capabilities that even\nwith with the tools we build we still won't be able to understand a lot of things and that's perhaps what non-human\nsystems might be able to reach farther not just as tools but in themselves understanding\nsomething that they can bring back yeah it could well be so i mean there's so many things that that are sort of\nencapsulated in what you just said there i think first of all um there's there's two different things there's like what do we understand today\nyeah what could the human mind understand and what is the totality of what is there to be understood yeah\nright and so there's three consensus you know you can think of them as three larger and larger trees or exploring\nmore branches of that tree and i i think with ai we're going to explore that whole lot now the question is is uh you\nknow if you think about what is the totality of what could be understood um there may be some fundamental physics\nreasons why certain things can't be understood like what's outside the simulation or outside the universe maybe\nit's not understandable from within the universe so that's there may be some hard constraints like that you know it could\nbe smaller constraints like um we think of space time as fundamental\nus our human brains are really used to this idea of a three-dimensional world with time right\nmaybe but our tools could go beyond that they wouldn't have that limitation necessary they could think in 11\ndimensions 12 dimensions whatever is needed but um we could still maybe understand that in several different\nways the example i always give is um when i you know play gary kasparov at speed chess or we've talked about chess\nand these kind of things um you know he if you if you if you're reasonably good at chess you can um you can't come up\nwith the move gary comes up with in his move but he can explain it to you and you can understand and you can understand post hoc the reasoning yeah\nso so i think there's a there's an even further level of like well maybe you couldn't have invented that thing but\nbut using like going back to using language again perhaps you can understand and appreciate that same way\nlike you can appreciate you know vivaldi or mozart or something without you can appreciate the beauty of that without um\nbeing able to to construct it yourself right invent the music yourself so i think we see this in all forms of life\nso it'll be that times you know a million but it would you can imagine also one sign of intelligence is the\nability to explain things clearly and simply right you know people like richard feynman another one of my all-time heroes used to say that right\nif you can't you know if you can explain it something simply then you that's a that's the best sign a complex topic\nsimply then that's one of the best signs of you understanding it yeah so i can see myself talking trash in the ai\nsystem in that way yes uh it gets frustrated how dumb i am and trying to explain something to me i was\nlike well that means you're not intelligent because if you were intelligent you'd be able to explain it simply yeah of course you know there's\nalso the other option of course we could enhance ourselves and and without devices we we are already sort of\nsymbiotic with our compute devices right with our phones and other things and you know this stuff like neural link and etc\nthat could be could could advance that further um so i think there's lots of lots of really amazing possibilities uh\nthat i could foresee from here well let me ask you some wild questions so out there looking for friends\n"}
{"pod": "Lex Fridman Podcast", "input": "Aliens", "output": "do you think there's a lot of alien civilizations out there so i guess this also goes back to your\norigin of life question too because i think that that's key um my personal opinion looking at all this\nand and you know it's one of my hobbies physics i guess so so i i you know it's something i think about a lot and talk\nto a lot of experts on and and and read a lot of books on and i think my feeling currently is that that we are\nalone i think that's the most likely scenario given what what evidence we have so um and the reasoning is i think\nthat you know we've tried since uh things like seti program and i guess since the\ndawning of the the space age uh we've you know had telescopes open radio telescopes and other things and if you\nthink about um and try to detect signals now if you think about the evolution of humans on earth we could have easily\nbeen um a million years ahead of our time now or million years behind quite\neasily with just some slightly different quirk thing happening hundreds of thousands years ago uh you know things\ncould have been slightly different if the bto had hit the dinosaurs a million years earlier maybe things would have evolved uh we'd be a million years\nahead of where we are now so what that means is if you imagine where humanity will be in a few hundred years let alone\na million years especially if we hopefully um you know solve things like climate change and other things and we continue\nto flourish and we build things like ai and we do space traveling and all of the stuff\nthat that humans have dreamed of for forever right and sci-fi has talked about forever um\nwe will be spreading across the stars right and void neumann famously calculated you know it would only take\nabout a million years if you send out von neumann probes to the nearest you know the nearest uh uh other solar\nsystems and and then they built all they did was build two more versions of themselves and set those two out to the\nnext nearest systems uh you you know within a million years i think you would have one of these probes in every system\nin the galaxy so it's not actually in cosmo cosmological time that's actually a very short amount of time\nso and and you know we've people like dyson have thought about constructing dyson spheres around stars to collect\nall the energy coming out of the star you know that there would be constructions like that would be visible across base um probably even across a\ngalaxy so and then you know if you think about all of our radio television uh\nemissions that have gone out since since the you know 30s and 40s um imagine a\nmillion years of that and now hundreds of civilizations doing that when we opened our ears at the point we got\ntechnologically sophisticated enough in the space age we should have heard a cacophony of voices we should\nhave joined that cacophony of voices and what we did we opened our ears and we heard nothing\nand many people who argue that there are aliens would say well we haven't really done exhaustive search yet and maybe\nwe're looking in the wrong bands and and we've got the wrong devices and we wouldn't notice what an alien form was\nlike to be so different to what we're used to but you know i'm not i don't really buy that that it shouldn't be as\ndifficult as that like we i think we've searched enough there should be if it were everywhere if it was it should be everywhere we should see dyson's fears\nbeing put up sun's blinking in and out you know there should be a lot of evidence for those things and then there are other people argue well the sort of\nsafari view of like well we're a primitive species still because we're not space faring yet and and and we're\nyou know there's some kind of globe like universal rule not to interfere star trek rule but like look look we can't\neven coordinate humans to deal with climate change and we're one species what is the chance that of all of these\ndifferent human civilization you know alien civilizations they would have the same priorities and and and and agree\nacross you know these kind of matters and even if that was true and we were in some sort of safari for our own good to\nme that's not much different from the simulation hypothesis because what does it mean the simulation hypothesis i think in its most fundamental level it\nmeans what we're seeing is not quite reality right it's something there's something more deeper underlying it\nmaybe computational now if we were in a if we were in a sort of safari park and\neverything we were seeing was a hologram and it was projected by the aliens or whatever that to me is not much different than thinking we're inside of\nanother universe because we still can't see true reality right i mean there's there's other explanations it could be\nthat the way they're communicating is just fundamentally different that we're too dumb to understand the much better\nmethods of communication they have it could be i mean i mean it's silly to say but\nour own thoughts could be the methods by which they're communicating like the place from which our ideas writers talk\nabout this like the muse yeah it sounds like very kind of uh\nwild but it could be thoughts it could be some interactions with our mind that we\nthink are originating from us is actually something that uh\nis coming from other life forms elsewhere consciousness itself might be that it could be but i don't see any\nsensible argument to the why why would all of the alien species be using this way yes some of them will be more\nprimitive they would be close to our level you know there would there should be a whole sort of normal distribution\nof these things right some would be aggressive some would be you know curious others would be very stoical and\nphilosophical because you know maybe they're a million years older than us but it's not it shouldn't be like what i\nmean one one alien civilization might be like that communicating thoughts and others but i don't see why you know\npotentially the hundreds there should be would be uniform in this way right it could be a violent dictatorship that the\nthe people the alien civilizations that uh become successful\nbecome um [Music] gain the ability to be destructive an\norder of magnitude more destructive but of course the the sad thought\nwell either humans are very special we took a lot of leaps that arrived at what it\nmeans to be human yeah um there's a question there which was the hardest which was the most special but\nalso if others have reached this level and maybe many others have reached this level the great filter\nthat prevented them from going farther to becoming a multi-planetary species or reaching out into the stars\nand those are really important questions for us whether um whether there's other alien\ncivilizations out there or not this is very useful for us to think about if we destroy ourselves\nhow will we do it and how easy is it to do yeah well you know these are big questions and i've thought about these a\nlot but the the the interesting thing is that if we're if we're alone that's somewhat comforting from the\ngreat filter perspective because it probably means the great filters were are past us and i'm pretty sure they are\nso that by in going back to your origin of life question there are some incredible things that no one knows how\nhappened like obviously the first life form from chemical soup that seems pretty hard but i would guess the\nmulticellular i wouldn't be that surprised if we saw single single cell sort of life forms elsewhere\nuh bacteria type things but multicellular life seems incredibly hard that step of you know capturing\nmitochondria and then sort of using that as part of yourself you know when you've just eaten it would you say that's the\nbiggest the most uh like if if you had to choose one sort of uh\nhitchhiker's got this galaxy one sentence summary of like oh those clever creatures did this that would be the\nmultilist i think that was probably the one that that's the biggest i mean there's a great book called the 10 grand great inventions of evolution by nick\nlane and he speculates on 10 10 of these you know what could be great filters um\ni think that's one i think the the advent of of intelligence and and conscious intelligence and in order you\nknow to us to be able to do science and things like that is huge as well i mean it's only evolved once as far as you\nknow uh in in earth history so that would be a later candidate but there's\ncertainly for the early candidates i think multicellular life forms is huge by the way what it's interesting to ask\nyou if you can hypothesize about what is the origin of intelligence is it\n"}
{"pod": "Lex Fridman Podcast", "input": "Intelligent life", "output": "uh that we started cooking meat over fire\nis it that we somehow figured out that we could be very powerful when we start collaborating so cooperation between\num our ancestors so that we can overthrow the alpha male\nuh what is it richard i talked to richard randham who thinks we're all just beta males who figured out how to\ncollaborate to defeat the one the dictator the authoritarian alpha male\num that control the tribe um is there other explanation did was there um 2001\nspace out any type of monolith yeah that came down to earth well i i think um i think all of those things you suggest\nfor good candidates fire and and and cooking right so that's clearly important\nyou know energy efficiency yeah cooking our meat and then and then being able to to to be more efficient about eating it\nand getting it consuming the energy um i think that's huge and then utilizing fire and tools i think you're right\nabout the the tribal cooperation aspects and probably language as part of that yes um because probably that's what\nallowed us to outcompete neanderthals and and perhaps less cooperative species so um so that may be the case tool\nmaking spears axes i think that let us i mean i think it's pretty clear now that\nhumans were responsible for a lot of the extinctions of megafauna um especially in in the americas when humans arrived\nso uh you can imagine once you discover tool usage how powerful that would have been and how scary for animals so i\nthink all of those could have been explanations for it you know the interesting thing is that it's a bit\nlike general intelligence too is it's very costly to begin with to have a brain\nand especially a general purpose brain rather than a special purpose one because the amount of energy our brains use i think it's like 20 of the body's\nenergy and it's it's massive and when you're thinking chest one of the funny things that that we used to say is as\nmuch as a racing driver uses for a whole you know formula one race if just playing a game of you know serious high\nlevel chess which you you know you wouldn't think just sitting there um because the brain's using so much uh\nenergy so in order for an animal an organism to justify that there has to be a huge payoff and the problem with with\nhalf a brain or half you know intelligence saying iqs of you know\nof like a monkey brain it's it's not clear you can justify that evolutionary until you get to the human\nlevel brain and so but how do you how do you do that jump it's very difficult which is why i think it's only been done\nonce from the sort of specialized brains that you see in animals to this sort of general purpose chewing powerful brains\nthat humans have um and which allows us to invent the modern modern world um and\nuh you know it takes a lot to to cross that barrier and i think we've seen the same with ai systems which is that uh\nmaybe until very recently it's always been easier to craft a specific solution to a problem like chess than it has been\nto build a general learning system that could potentially do many things because initially uh that system will be way\nworse than uh less efficient than the specialized system so one of the interesting\n"}
{"pod": "Lex Fridman Podcast", "input": "Conscious AI", "output": "quirks of the human mind of this evolved system is that it appears to be\nconscious this thing that we don't quite understand but it seems very\nvery special its ability to have a subjective experience that it feels like something\nto eat a cookie the deliciousness of it or see a color and that kind of stuff do you think in order to solve intelligence\nwe also need to solve consciousness along the way do you think agi systems need to have consciousness in order to\nbe truly intelligent yeah we thought about this a lot actually and um i think that\nmy guess is that consciousness and intelligence are double dissociable so you can have one without the other both\nways and i think you can see that with consciousness in that i think some animals and pets if you have a pet dog\nor something like that you can see some of the higher animals and dolphins things like that are uh have\nself-awareness and uh very sociable um seem to dream um you know those kinds of\na lot of the traits one would regard as being kind of conscious and self-aware um and but yet they're not that smart\nright uh so they're not that intelligent by by say iq standards or something like that yeah it's also possible that our\nunderstanding of intelligence is flawed like putting an iq to it sure maybe the thing that a dog can do\nis actually gone very far along the path of intelligence and we humans are just able to\nplay chess and maybe write poems right but if we go back to the idea of agi and general intelligence you know dogs are\nvery specialized right most animals are pretty specialized they can be amazing at what they do but they're like kind of elite sports sports people or something\nright so they do one thing extremely well because their entire brain is is optimized they have somehow convinced\nthe entirety of the human population to feed them and service them so in some way they're controlling yes exactly well\nwe co-evolved to some crazy degree right uh including the the way the dogs you know even even wag their tails and\ntwitch their noses right we find we're finding inexorably cute yeah um but i think um you can also see intelligence\non the other side so systems like artificial systems that are amazingly smart at certain things like maybe\nplaying go and chess and other things but they don't feel at all in any shape or form conscious in the way that you\nknow you do to me or i do to you and um and i think actually\nbuilding ai is uh these intelligent constructs uh is one of the best ways to explore the\nmystery of consciousness to break it down because um we're going to have devices that are\npretty smart at certain things or capable of certain things but potentially won't have any semblance of\nself-awareness or other things and in fact i would advocate if there's a choice building systems in\nthe first place ai systems that are not conscious to begin with uh are just tools um until we understand them better\nand the capabilities better so on that topic just not as the ceo of deep mind\njust as a human being let me ask you about this one particular anecdotal evidence of the google engineer\nwho made a comment or believed that there's some aspect of a language model\nthe lambda language model that exhibited sentience so you said you believe there might be a\nresponsibility to build systems that are not essential and this experience of a particular engineer i think i'd love to\nget your general opinion on this kind of thing but i think it will happen more and more and more which uh not when engineers but when\npeople out there that don't have an engineering background start interacting with increasingly intelligent systems\nwe anthropomorphize them they they start to have deep impactful\num interactions with us in a way that we miss them yeah when they're gone and\nwe sure feel like they're living entities self-aware entities and maybe even we project sentience onto\nthem so what what's your thought about this particular uh system was is uh\nhave you ever met a language model that's sentient no i no no what do you make of the case\nof when you kind of feel that there's some elements of sentience to this system yeah so this is you know\nan interesting question and uh uh obviously a very fundamental one so first thing to say is i think that\nnone of the systems we have today i i would say even have one iota of uh semblance of consciousness or sentience\nthat's my personal feeling interacting with them every day so i think that's way premature to be discussing what that\nengineer talked about i appreciate i think at the moment it's more of a projection of the way our own minds work\nwhich is to see uh uh uh sort of purpose and direction\nin almost anything that we you know our brains are trained to interpret uh agency basically in things uh even the\nan inanimate thing sometimes and of course with a a language system because language is so fundamental to\nintelligence that's going to be easy for us to anthropomorphize that i mean back in the day even the first uh\nyou know the dumbest sort of template chatbots ever eliza and and and and the ilk of the original chatbots back in the\n60s fooled some people under certain circumstances right they pretended to be a psychologist so just basically rabbit\nback to you the same question you asked it back to you um and uh some people believe that so i\ndon't think we can this is why i think the turing test is a little bit flawed as a formal test because it depends on the sophistication of the of the judge\num whether or not they are qualified to make that distinction so\ni think we should uh talk to you know the the top philosophers about this people like daniel dennett and uh david\nchalmers and others who've obviously thought deeply about consciousness of course consciousness itself hasn't been\nwell there's no agreed definition if i was to you know uh speculate about that\nuh you know i kind of the definite the working definition i like is it's the way information feels when you know it\ngets processed i think maybe max tegmark came up with that i like that idea i don't know if it helps us get towards any more operational thing but but it's\nit's it's i think it's a nice way of viewing it um i think we can obviously see from neuroscience certain\nprerequisites that are required like self-awareness i think is necessary but not sufficient component this idea of a\nself and other and set of coherent preferences that are coherent over time\nyou know these things are maybe memory um these things are probably needed for a sentient or conscious being um but but\nthe reason that the difficult thing i think for us when we get and i think this is a really interesting philosophical debate is when we get\ncloser to agi and and and you know and and much more powerful systems than we have today\num how are we going to make this judgment and one way which is the turing test is sort of a behavioral judgment is\nis the system exhibiting all the behaviors um that a human sentient uh or\na sentient being would would would exhibit um is it answering the right questions is it saying the right things is it indistinguishable from a human um\nand so on but i think there's a second thing that makes us as humans regard each other as\nsentient right why do we why do we think this and i debated this with daniel dennett and i think there's a second reason that's often overlooked which is\nthat we're running on the same substrate right so if we're exhibiting the same behavior uh more or less as humans and\nwe're running on the same you know carbon-based biological substrate the squishy you know few pounds of of flesh\nin our skulls then the most parsimonious i think explanation is that you're\nfeeling the same thing as i'm feeling right but we will never have that second part the substrate equivalence with a\nmachine right so we will have to only judge based on the behavior and i think the substrate equivalence is a critical part\nof why we make assumptions that we're conscious and in fact even with with animals high-level animals why we think\nthey might be because they're exhibiting some of the behaviors we would expect from a sentient animal and we know they're made of the same things\nbiological neurons so we're gonna have to come up with explanations uh or models of the gap\nbetween substrate differences between machines and humans did to get anywhere\nbeyond the behavioral but to me sort of the practical question is very interesting and very important when\nyou have millions perhaps billions of people believing that you have ascension ai believing what that google engineer\nbelieved which i just see is an obvious very near-term future thing certainly on\nthe path to agi how does that change the world what's the responsibility of the ai\nsystem to help those millions of people and also what's the ethical thing because\nyou can you can make a lot of people happy by creating a meaningful deep experience\nwith a system that's faking it before it makes it yeah and i i don't\nis a are we the right or who is to say what's the right thing to do should ai\nalways be tools like why why why are we constraining ais to always be tools as\nopposed to friends yeah i think well i mean these are you know you know fantastic\nquestions and and also critical ones and we've been thinking about this uh since\nthe start of d minor before that because we planned for success and you know how how you know you know however remote\nthat looked like back in 2010 and we've always had sort of these ethical considerations as fundamental at\ndeepmind um and my current thinking on the language models is and and large models is they're not ready we don't\nunderstand them well enough yet um and you know in terms of analysis tools and and guard rails what they can and can't\ndo and so on to deploy them at scale because i think you know there are big still ethical questions like should an\nai system always announce that it is an ai system to begin with probably yes um\nit what what do you do about answering those philosophical questions about the feelings uh people may have about ai\nsystems perhaps incorrectly attributed so i think there's a whole bunch of research that needs to be done first um\nto responsibly before you know you can responsibly deploy these systems at scale that would be at least be my\ncurrent position over time i'm very confident we'll have those tools like interpretability\nquestions um and uh analysis questions uh and then\nwith the ethical quandary you know i think there it's important to\nuh look beyond just science that's why i think philosophy social sciences even\ntheology other things like that come into it where um what you know arts and humanities what what does it mean to be\nhuman and the spirit of being human and and to enhance that and and the human condition right and allow us to\nexperience things we could never experience before and improve the the overall human condition and humanity\noverall you know get radical abundance solve many scientific problems solve disease so this is the era i think this\nis the amazing era i think we're heading into if we do it right um but we've got to be careful we've already seen with\nthings like social media how dual use technologies can be misused by firstly\nby by by bad you know p bad actors or naive actors or crazy actors right so\nthere's that set of just the common or garden misuse of existing dual use technology and then of course there's an\nadditional uh uh thing that has to be overcome with ai that eventually it may have its own agency so it could be uh uh\nuh good or bad in in in of itself so i think these questions have to be approached very carefully um using the\nscientific method i would say in terms of hypothesis generation careful control testing not live a b testing out in the\nworld because with powerful dual technologies like ai if something goes wrong it may cause you\nknow a lot of harm before you can fix it um it's not like a you know an imaging app or game app where you know that if\nif something goes wrong it's relatively easy to fix and and the harm's relatively small so i think\nit comes with you know the the the usual uh cliche of like with a lot of power\ncomes a lot of responsibility and i think that's the case here with things like ai given the the enormous\nopportunity in front of us and i think we need a lot of voices uh and as many\ninputs into things like the design of the systems and the values they should have and what goals should\nthey be put to um i think as wide a group of voices as possible beyond just the technologies is needed uh to input\ninto that and to have a say in that especially when it comes to deployment of these systems which is when the\nrubber really hits the road it really affects the general person in the street rather than fundamental research and\nthat's why i say i think as a first step it would be better if we have the choice to build\nthese systems as tools to give and i'm not saying that it should never they should never go beyond tools because of\ncourse the potential is there um for it to go way beyond just tools uh but um i\nthink that would be a good first step in order for us to you know allow us to carefully experiment understand what\nthese things can do so the leap between tool to sentient entity being is one\nshould take very careful yes let me ask a dark personal question so you're one of the most brilliant\n"}
{"pod": "Lex Fridman Podcast", "input": "Power", "output": "people in the ag community also one of the most kind and uh if i may say sort of loved people\nin the community that said uh creation of a super intelligent ai\nsystem would be one of the most powerful things in the world tools or otherwise\nand again as the old saying goes power corrupts and absolute power crops absolutely\nyou are likely to be one of the people\ni would say probably the most likely person to be in the control of such a system\ndo you think about the corrupting nature of power when you talk about these kinds of systems that\num as all dictators and people have caused atrocities in the past always think they're doing good\nbut they don't do good because the powers polluted their mind about what is good and what is evil do you think about\nthis stuff or are we just focused on language modeling no i think about them all the time and you know i think\nwhat are the defenses against that i think one thing is to remain very grounded and sort of humble uh no matter\nwhat you do or achieve and i try to do that i might you know my best friends are still my set of friends from my\nundergraduate cambridge days my family's you know and and friends are very important\num i've always i think trying to be a multi-disciplinary person it helps to keep you humble because no matter how\ngood you are at one topic someone will be better than you at that and it and always relearning a new topic again from\nscratch is or new field is very humbling right so for me that's been biology over the last five years you know huge area\ntopic and and and it's been and i just love doing that but it helps to keep you grounded like it keeps you open-minded\nand and then the other important thing is to have a really good amazing set of uh people around you at your company or\nyour organization who are also very ethical and grounded themselves and help to keep you that way\nand then ultimately just to answer your question i hope we're going to be a big part of of birthing ai and that being\nthe greatest benefit to humanity of any tool or technology ever and and getting us into a world of radical abundance and\ncuring diseases and and and solving many of the big challenges we have in front of us and then ultimately you know help the\nultimate flourishing of humanity to travel the stars and find those aliens if they are there and if they're not there find out why they're not there\nwhat what is going on here in the universe um this is all to come and and that's what i've always dreamed about um\nbut i don't think i think ai is too big an idea it's not going to be uh there'll be a certain set of pioneers who get\nthere first i hope we're in the vanguard so we can influence how that goes and i think it matters who builds who which which\ncultures they come from and what values they have uh the builders of ai systems because i think even though the ai\nsystem is going to learn for itself most of its knowledge there'll be a residue in the system of the culture and the\nvalues of the creators of the system um and there's interesting questions to to discuss about that geopolitically you\nknow different cultures as we're in a more fragmented world than ever unfortunately i think in terms of global cooperation\nwe see that in things like climate where we can't seem to get our act together uh globally to cooperate on these pressing\nmatters i hope that will change over time perhaps you know if we get to an era of radical abundance we don't have\nto be so competitive anymore maybe we can be more cooperative if resources aren't so scarce it's true\nthat in terms of power corrupting and leading to destructive things it seems that some of\nthe atrocities of the past happen when there's a significant constraint on resources i think that's\nthe first thing i don't think that's enough i think scarcity is one thing that's led to competition destruct you know sort of zero sum game thinking i\nwould like us to all be in a positive sum world and i think for that you have to remove scarcity i don't think that's enough unfortunately to get world peace\nbecause there's also other corrupting things like wanting power over people and this kind of stuff which is not\nnecessarily satisfied by by just abundance but i think it will help um\nand i think uh but i think ultimately ai is not going to be run by any one person or one organization i think it should\nbelong to the world belong to humanity um and i think maybe many there'll be many ways this will happen and\nultimately um everybody should have a say in that do you have advice\n"}
{"pod": "Lex Fridman Podcast", "input": "Advice for young people", "output": "for uh young people in high school and college maybe um\nif they're interested in ai or interested in having a big impact on the world what they should\ndo to have a career they can be proud of her to have a life they can be proud of i love giving talks to the next\ngeneration what i say to them is actually two things i i think the most important things to learn about and to\nfind out about when you're when you're young is what are your true passions is first of all there's two things one is\nfind your true passions and i think you can do that by the way to do that is to explore as many things as possible when\nyou're young and you you have the time and you and you can take those risks um i would also encourage people to look at\nthe finding the connections between things in a unique way i think that's a really great way to find a passion second thing\ni would say advise is know yourself so spend a lot of time\nunderstanding how you work best like what are the optimal times to work what are the optimal ways that you study um\nwhat are your how do you deal with pressure sort of test yourself in various scenarios and try and improve your\nweaknesses but also find out what your unique skills and strengths are and then\nhone those so then that's what will be your super value in the world later on and if you can then combine those two\nthings and find passions that you're genuinely excited about that intersect with what your unique strong skills are\nthen you're you know you're on to something incredible and and you know i think you can make a huge difference in the world so let me ask about know\nyourself this is fun this is fun quick questions about day in the life the\nperfect day the perfect productive day in the life of demise's house yeah maybe uh maybe these days you're um\nthere's a lot involved yeah it may be a slightly younger you could focus on a demonstration\nproject maybe um how early do you wake up are you night owl do you wake up early in the morning\nwhat are some interesting habits uh how many dozens of cups of coffees do you drink a day what's the computer um\nthat you use uh what's the setup how many screens what kind of keyboard are we talking uh\nemacs vim are we talking something more modern so it's a bunch of those questions so maybe uh day in the life\nwhat what's the perfect day involved well these days it's quite different from say 10 20 years ago back 10 20\nyears ago it would have been you know a whole day of research individual research or\nprogramming doing some experiment neuroscience computer science experiment reading lots of research papers uh and\nthen perhaps at night time you know um reading science fiction books or or uh\nplaying uh some games but lots of focus so like deep focused work on whether\nit's uh programming or reading research paper yes yes so that would be a lot of debrief you know uh focused work these\ndays for the last sort of i guess you know five to ten years i've actually got quite a structure that works very well\nfor me now which is that um i'm a night complete night out always have been so i optimized for that so you know i get you\nknow i basically do a normal day's work get into work about 11 o'clock and sort of do work to about seven uh in the\noffice uh and i will arrange back-to-back meetings for the entire time of that and with as many me as many\npeople as possible so that's my collaboration management part of the day then i go home uh spend time with the\nfamily and friends uh have dinner uh uh relax a little bit and then i start a\nsecond day of work i call it my second day work around 10 pm 11 p.m and that's the time till about the small hours of\nthe morning four five in the morning where i will do my thinking and reading\na research writing research papers um sadly don't have time to code anymore\nbut it's it's not efficient to to do that uh these days uh given the amount of time i have um but that's when i do\nyou know maybe do the long kind of stretches of of thinking and planning and then probably you know using using\nemail or other things i would set i would fire off a lot of things to my team to deal with the next morning for\nactually thinking about this overnight we should go for this project or arrange this meeting the next day when you're\nthinking through a problem are you talking about a sheet of paper or the patent pen is there some independent structure yeah i like processes i still\nlike pencil and paper best for working out things but um these days it's just so efficient to read research papers\njust on the screen i still often print them out actually i still prefer to mark out things and i find it goes into\nthe brain quick better and sticks in the brain better when you're you're still using physical pen and pencil and paper\nso you take notes with the i have lots of nodes electronic ones and also um whole stacks of notebooks that\num that i use at home yeah on some of these most challenging next steps for example stuff\nnone of us know about that you're working on you're thinking there's some deep thinking required\nthere right like what what is the right problem what is the right approach because you're gonna have to invest a\nhuge amount of time for the whole team they're going to have to pursue this thing what's the right way to do it is\nis rl going to work here or not yes um what's the right thing to try what's the right benchmark to use yeah we need to\nconstruct a benchmark from scratch all those kinds of things yes so i think all those kind of things in the night time\nphase but also much more um i find i've always found the quiet hours of the\nmorning um when everyone's asleep it's super quiet outside um i love that time\nit's the golden hours like between like one and three in the morning um put some music on some inspiring music on and\nthen um think these deep thoughts so that's when i would read you know my philosophy books and uh spinoza's my you\nknow recent favorite can all these things i i i you know read about a great uh uh\na scientist of history how they did things how they thought things so that's when you do all your create that's when\ni do all my creative thinking and it's good i think i think people recommend you know you do your your your sort of\ncreative thinking in one block and the way i organize the day that way i don't get interrupted because obviously no one\nelse is up uh at those times so i can i can go uh you know as i can sort of get\nsuper deep and super into flow the other nice thing about doing it night time wise is if i'm really uh onto something\nor i've i've got really deep into something i can choose to extend it and i'll go into six in the morning whatever\nand then i'll just pay for it the next day yeah cause i'll be a bit tired and i won't be my best but that's fine i can\ndecide looking at my schedule the next day that and given where i'm at with this particular thought or creative idea\nthat i'm going to pay that cost the next day so so i think that's that's more flexible than morning people who do that\nyou know they get up at four in the morning they can also do those golden hours then but then their start of their schedule day starts at breakfast you\nknow 8 a.m whatever they have their first meeting and then it's hard you have to reschedule a day if you're in flow yeah that's going to be i don't\nhave to see that special threat of thoughts that the you're too passionate about you that\nthis is where some of the greatest ideas could potentially come is when you just lose yourself late into yeah\nand for the meetings i mean you're loading in really hard problems in a very short amount of time so you have to\ndo some kind of first principles thinking here it's like what's the problem what's the state of things what's the right next step yes you have\nto get really good at context switching which is one of the hardest things because especially as we do so many\nthings if you include all the scientific things we do scientific fields we're working in these are entire you know\ncomplex fields in themselves and you you have to sort of keep up to abreast of that but i enjoy it i've always been uh\na sort of generalist in a way and that's actually what happened with my games career after chess i i i one of the\nreasons i stopped playing chess was that i got into computers but also i started realizing there were many other great games out there to play too so\ni've always been that way inclined multidisciplinary and there's too many interesting things in in the world to spend all your time just on one thing\nso you mentioned spinoza gotta ask the big ridiculously big question about life\n"}
{"pod": "Lex Fridman Podcast", "input": "Meaning of life", "output": "what do you think is the meaning of this whole thing uh why are we humans here you've already\nmentioned that perhaps the universe created us is that why you think we're here\nto understand how the universe yeah i think my answer to that would be and at least the the life i'm living is to gain\nand uh to gain and understand the knowledge you know to gain knowledge and understand the universe that's what i\nthink uh i can't see any higher purpose than that if you think back to the classical greeks you know the virtue of\ngaining knowledge it's uh i think it's that it's one of the few true virtues is to understand um the world around us and\nthe context and humanity better and um and i think if you do that you become more compassionate and more\nunderstanding yourself and and more tolerant and all these i think all these other things may flow from that and to\nme you know understanding the nature of reality that is the biggest question what is going on here is sometimes the\ncolloquial way i say what is really going on here uh it's so mysterious i feel like we're\nin some huge puzzle and and it's but the world is also seems to be the universe\nseems to be structured in a way you know why is it structured in a way that science is even possible that you know\nmethods the scientific method works things are repeatable um it feels like it's almost structured\nin a way to be conducive to gaining knowledge so i feel like and you know why should computers be even possible\nisn't that amazing that uh computational electronic devices can can can can be\npossible and they're made of sand our most you know common element that we have you know silicon that on the on the\nearth's crust they could be made of diamond or something then we would have only had one computer yeah right so it's\na lot of things are kind of slightly suspicious to me it sure as heck sounds this puzzle sure sounds like something\nwe talked about earlier what it takes to to design a game that's really fun to play for prolonged\nperiods of time and it does seem like this puzzle like you mentioned the more you learn about\nit the more you realize how little you know so it humbles you but excites you by the\npossibility of learning more it's one heck of a one heck of a puzzle we got going on here um so like i mentioned of\nall the people in the world you're very likely to be the one who creates the agi\nsystem um that achieves human level intelligence and goes beyond it so if\nyou got a chance and very well you could be the person that goes into the room with the system and have a conversation\nmaybe you only get to ask one question if you do what question would you ask her\ni would probably ask um what is the true nature of reality i think that's the question i don't know\nif i'd understand the answer because maybe it would be 42 or something like that but um that's the question i would\nask and then there'll be a deep sigh from the systems like all right how do i\nexplain to the excuse me exactly all right let me i don't have time to explain uh maybe i'll draw you a\npicture that it is i mean how do you even begin um\nto answer that question well i think it would um what would you what would you think the answer could\npossibly look like i think it could it could start looking like uh\nuh more fundamental explanations of physics would be the beginning you know more careful specification of that\ntaking you walking us through by the hand as to what one would do to maybe prove those things out maybe giving you\nglimpses of what things you totally missed in the physics of today exactly just here here's glimpses of no\nlike there's a much uh a much more elaborate world or a much simpler world or something\na much deeper maybe simpler explanation yes of things right than the standard model of physics which we know doesn't\nwork but we still keep adding to so um and and that's how i think the beginning\nof an explanation would look and it would start encompassing many of the mysteries that we have wondered about for thousands of years like you know\nconsciousness uh life and gravity all of these things yeah giving us a glimpses of\nexplanations for those things yeah well um damas dear one of the special\nhuman beings in this giant puzzle of ours and it's a huge honor that you would take a pause from the bigger\npuzzle to solve this small puzzle of a conversation with me today it's truly an honor and a pleasure thank you thank you\ni really enjoyed it thanks lex thanks for listening to this conversation with demas establish to\nsupport this podcast please check out our sponsors in the description and now let me leave you with some words\nfrom edskar dykstra computer science is no more about computers\nthan astronomy is about telescopes thank you for listening and hope to see\nyou next time\n"}

{"pod": "Lex Fridman Podcast", "input": "Introduction", "output": "the following is a conversation with wojciech zaramba co-founder of openai\nwhich is one of the top organizations in the world doing artificial intelligence research and development\nwojciech is the head of language and cogeneration teams building and doing\nresearch on github copilot openai codex and gpt\nthree and who knows four five six n and\nn plus one and he also previously led openai's robotic efforts\nthese are incredibly exciting projects to me that deeply challenge and expand\nour understanding of the structure and nature of intelligence the 21st century\ni think may very well be remembered for a handful of revolutionary ai systems\nand their implementations gpt codex and applications of language models and transformers in general\nto the language and visual domains may very well be at the core of these ai\nsystems to support this podcast please check out our sponsors they're listed in the description\nthis is a lex friedman podcast and here is my conversation with wachek zaremba\n"}
{"pod": "Lex Fridman Podcast", "input": "The Fermi paradox", "output": "you mentioned that sam altman asked about the fermi paradox\nand the people at open ai had really sophisticated interesting answers so that's when you knew this is the right\nteam to be working with so let me ask you about the fermi paradox about aliens\nwhy have we not found overwhelming evidence for aliens visiting earth i don't have a conviction in the answer\nbut rather kind of probabilistic perspective on what might be a let's say possible answers it's also interesting\nthat the question itself even can't touch on the you know your typical\nquestion of what's the meaning of life because like if you assume that like we don't see aliens because they destroy themselves that kind of upwards their\nfocus on making sure that we won't destroy ourselves yeah and at the moment the\nplace where i am actually with my belief and these things also change over the time is i think that we might be alone in the\nuniverse which actually makes life more or less a consciousness life more kind of valuable and that means\nthat we should more appreciate it have you always been alone so what's your intuition about our galaxy our\nuniverse is it just sprinkled with graveyards of intelligent civilizations or are we truly is is life\nintelligent life truly unique at the moment my belief that it is unique but i would say i could also\nyou know there was like some footage released with ufo objects which makes me\nactually doubt my own belief yes yeah i can tell you one crazy answer\nthat i have heard yes so apparently when you look actually at the\nlimits of computation you can compute more if the temperature of the universe would\ndrop down so one of the things that aliens might want to do if they are\ntruly optimizing to maximize amount of compute which you know maybe can lead to or let's say simulations or so it's\ninstead of wasting current entropy of the universe because you know we by living we are actually somewhat wasting\nentropy then you can wait for the universe to cool down such that you have more computation that's kind of a funny\nanswer i'm not sure if i believe in it but that would be one of the reasons why you don't see aliens it's also possible\nsee some people say that maybe there is not that much point in actually going to other galaxies\nif you can go inwards so there is no limits of what could be an experience\nif we could you know connect machines to our brains while there are still some limits if we\nwant to explore universe yeah there could be a lot of ways to go inwards too\nonce you figure out some aspect of physics we haven't figured out yet maybe you can travel to different dimensions i\nmean travel in three-dimensional space may\nnot be the most fun kind of travel there may be like just a huge amount of different ways to travel and it doesn't\nrequire a spaceship going slowly in 3d space space time it also\nfeels you know one of the problems is that speed of light is low and universe is vast yeah and um\nit seems that actually most likely if we want to travel very far then then we would instead of actually\nsending spaceships with humans that wait a lot we would send something similar to what yuri\nmiller is working on these are like a huge uh sail which is at first powered power there is a shot of laser from an\nearth and it can propel it to a quarter of speed of light and uh sail itself\ncontains a few grams of equipment and that might be the way to actually\ntransport matter through universe but then when you think what would it mean for humans it means that\nwe would need to actually put their 3d printer and you know 3d print a human on other planet i don't know play them\nyoutube or let's say or like a pre 3d print like a huge human right away or maybe a womb or so um yeah\nwith our current techniques of archaeology if a civilization was born and died\nlong long enough ago on earth we wouldn't be able to tell and so that makes me really sad\nand so i think about earth in that same way how can we leave some remnants if we\ndo destroy ourselves how can we leave remnants for aliens in the future to discover\nlike here's some nice stuff we've done like wikipedia and youtube do we have it like\nin a satellite orbiting earth with a hard drive like how how do we say\nhow do we back up human civilization uh for the good parts or all of it is good parts\nso that uh it can be preserved longer than our bodies can that's a\nthat's kind of a it's a difficult question it also requires the difficult acceptance of the\nfact that we may die and if we die we may die suddenly as a civilization\nso let's see i think it kind of depends on the cataclysm we have observed in other parts of the universe that births\nof gamma rays these are high energy rays of light that actually can\napparently kill entire galaxy so there might be actually nothing even\nto nothing to protect us from it i'm also when i'm looking actually at the past civilization so it's like aztecs or so\nthey disappear from the surface of the earth and one can ask\nwhy is it the case and the way i'm thinking about it is\nyou know that definitely they had some problem that they couldn't solve and maybe there was a flat and all of a\nsudden they couldn't drink there was no potable water and they all died and\ni think that so far the best solution to such a problems is\ni guess technology so i mean if they would know that you can just boil water and then drink it after then that would\nsave their civilization and even now when we look actually at the current pandemic it seems that once again\nactually science comes to rescue and somehow science increases size of the action space and i think that's a good\nthing yeah but nature has a vastly larger action space but\nstill it might be a good thing for us to keep on increasing action space\nokay looking at past civilizations yes but looking at the destruction of human\ncivilization perhaps expanding the action space will add\nactions that are easily acted upon easily executed and as a\nresult destroy us so let's see i was pondering\n"}
{"pod": "Lex Fridman Podcast", "input": "Systems of government", "output": "why actually even we have negative impact on the globe because you know if you ask every\nsingle individual they would like to have clean air they would like healthy planet but\nsomehow it actually is not the case that as a collective we are not going this direction\ni think that there exists very powerful system to describe what we value that's capitalism it assigns actually monetary\nvalues to various activities at the moment the problem in the current system\nis that there are some things which we value there is no cost assigned to it so even though we value clean air or maybe\nwe also value lack of destruction on the internet or\nso at the moment these quantities you know companies corporations can pollute them uh for\nfree so in some sense\ni wish or like and that's i guess purpose of politics to\nalign the incentive systems and we are kind of maybe even moving in this direction the first issue is even to be\nable to measure the things that we value then we can actually assign the monetary value to them\nyeah and that's so it's getting the data and also probably through technology enabling\npeople to vote and to move money around in a way that is\naligned with their values and that's very much a technology question so like\nhaving one president and congress and voting that happens every four years\nor something like that that's a very outdated idea there could be some technological improvements to\nthat kind of idea so i'm thinking from time to time about these topics but it also feels to me\nthat it's it's a little bit like a it's hard for me to actually make correct predictions what is the\nappropriate thing to do i extremely trust uh sam altman our ceo\non these topics he um okay i'm more on the side of being i guess\nnaive hippie that yeah that's your life philosophy um\nwell like i think self-doubt and uh i think hippie implies optimism those\nthose two things are pretty pretty good way to operate i mean still it is hard for me to actually\nunderstand how the politics works or like uh how this like exactly how the things would play out\nand sam is a really excellent with it what do you think is rarest in the universe you said we might be alone\n"}
{"pod": "Lex Fridman Podcast", "input": "Life, intelligence, and consciousness", "output": "what's hardest to build is another engineering way to ask that life intelligence or consciousness so like\nyou said that we might be alone which is the thing that's hardest to get to\nis it just the origin of life is it the origin of intelligence is it the origin\nof consciousness so um let me at first explain you my kind\nof mental model what i think is needed for life to appear um so\ni imagine that at some point there was this primordial zoop of\namino acids and maybe some proteins in the ocean and you know some proteins were turning\ninto some other proteins through reaction and you can almost think about this\nuh cycle of what turns into what as there is a graph essentially describing which substance turns into some other\nsubstance and essentially life means that all the sudden in the graph has been created a cycle such that the same\nthing keeps on happening over and over again that's what is needed for life to happen and in some sense you can think\nalmost that you have this gigantic graph and it needs like a sufficient number of\nedges for the cycle to appear then um from perspective of intelligence\nand consciousness my current intuition is that they might be quite intertwined first of all it might\nnot be that it's like a binary thing that you have intelligence or consciousness it seems to be a\nmore a continuous component let's see if we look for instance on the even networks\nrecognizing images and people are able to show that the activations of these networks correlate very strongly\nwith activations in visual cortex of some monkeys the same seems to be\ntrue about language models also if you for instance\nlook if you train agent in a 3d world\nat first you know it it it it barely recognizes what is going on over the time it kind of recognizes foreground\nfrom a background over the time it kind of knows where there is a foot and it just follows it\nover the time it actually starts having a 3d perception so it is possible for instance to look inside of the head of\nan agent and ask what would it see if it looks to the right and the crazy thing is you know initially when the agents\nare very trained these predictions are pretty bad over the time they they become better and better you can still\nsee that if you ask what happens when the head is turned by 360 degrees for some\ntime they think that the different thing appears and then at some stage they understand actually that the same\nthing's supposed to appear so they get like a understanding of 3d structure it's also you know very likely that they\nhave inside some level of and of like a symbolic reasoning like they're particularly\nsymbols for other agents so when you look at dota agents they collaborate\ntogether and uh and now they they they have some anticipation of uh if if they would win\nbattle they have some some expectations with respect to other agents i might be you know too much anthropomorphizing\num the the how the things look look for me but then the fact that they\nhave a symbol for other agents and makes me believe that at some stage as the uh you know as they\nare optimizing for skills they would have also symbol to describe themselves this is like a very useful\nsymbol to have and this particularity i would call it like a self-consciousness or self-awareness\nand still it might be different from the consciousness so i guess the the way how\ni'm understanding the word consciousness let's say the experience of drinking a coffee or let's say experience of being\na butt that's the meaning of the word consciousness it doesn't mean to be awake\nyeah it feels it might be also somewhat related to memory and recurrent connections so um\nit's kind of okay if you look at anesthetic drugs they might be\nuh like they essentially they disturb\nbrain waste such that [Music] maybe memory is not not formed\nso there's a lessening of consciousness when you do that correct and so that's one way to intuit what is consciousness\nthere's also kind of another element here it could be that it's\nyou know this kind of self-awareness module that you described\nplus the actual subjective experience is a storytelling module\nthat tells us a story about uh what we're experiencing\nthe crazy thing so let's say i mean in meditation they teach people\nnot to speak story inside of the head and there is also some fraction of population\nwho doesn't have actually narrator i know people who don't have a right narrator and you know they have to use\nexternal people in order to kind of solve tasks that require internal\nnarrator so it seems that it's possible to have the experience without the talk\nwhat are we talking about when we talk about the internal narrator is that the voice when you're like yeah i thought\nthat that that's what you are referring to well i was referring more on the like\nnot an actual voice i meant like there's some kind of\nlike subjective experience feels like it's\nit's fundamentally about storytelling to ourselves it feels like\nlike the feeling is a story that is much\nmuch simpler abstraction than the raw sensory information so it feels like it's a very high level\nabstraction that is useful for me to feel like\nentity in this world most useful aspect of it is that\nbecause i'm conscious i think there's an intricate connection to me not one\nwanting to die so like it's a useful hack to really\nprioritize not dying like those seem to be somehow connected so i'm telling the story of like it's\nrichly feels like something to be me and the fact that me exists in this world i\nwant to preserve me and so that makes it a useful agent hack so i will just refer maybe to the first\npart as you said about the kind of story of describing who you are\ni was thinking about that even so you know obviously i'm i'm i\n"}
{"pod": "Lex Fridman Podcast", "input": "GPT language model", "output": "like thinking about consciousness uh i like thinking about the ai as well and i'm trying to see analogies of these\nthings in ai what would it correspond to so um\nyou know openly i trained a a model called gpt\nwhich can generate a pretty amusing text on arbitrary topic\nand um and one way to control gpd is uh by putting into prefix at the\nbeginning of the text some information what would be the story about you can have even chat with uh\nyou know with gpt by saying that the chat is with lex or elon musk or so and gpt would just\npretend to be you or elon musk or so and it almost feels that this uh\nstory that we give ourselves to describe our life it's almost like a\nthings that you put into context of gpt yeah the primary it's the and but the the context we provide to gpt\nis uh is multimodal it's so gpt itself is multimodal gpt itself uh hasn't learned\nactually from experience of single human but from the experience of humanity it's a chameleon you can turn it into\nanything and in some sense by providing context uh it you know\nbehaves as the thing that you wanted it to be and it's interesting that the you know people have a stories of who\nthey are and as i said these stories they help them to operate in the world\nbut it's also you know interesting i guess various people find it out through meditation or so that\nthere might be some patterns that you have learned when you were a kid that actually are not serving you anymore\nand you also might be thinking that that's who you are and that's actually just the story\nyeah so it's a useful hack but sometimes it gets us into trouble it's a local optima\n"}
{"pod": "Lex Fridman Podcast", "input": "Engineering consciousness", "output": "you wrote that stephen hawking he tweeted stephen hawking asked what breathes fire into equations which meant\nwhat makes given mathematical equations realize the physics of a universe\nsimilarly i wonder what breathes fire into computation what makes given computation\nconscious okay so how do we engineer consciousness\nhow do you breathe fire and magic into the machine so\nit seems clear to me that not every computation is conscious i mean you can\nlet's say just keep on multiplying one matrix over and over again and my gigantic matrix you can put a lot of\ncomputation i don't think it would be conscious so in some sense the question is what are the computations which could be\nconscious uh i mean so one assumption is that it has to do purely with\ncomputation that you can abstract away matter and other possibilities that it's very important was the realization of\ncomputation that it has to do with some uh uh force fields or so and they bring\nconsciousness at the moment my intuition is that it can be fully abstracted that way so in case of computation you can\nask yourself what are the mathematical objects or so that could bring such a properties so for instance\nif we think about the models uh ai models then what they truly\ntry to do or like models like gpt is uh\nyou know they try to predict a next word or so and this turns out to be\nequivalent to compressing text\nand because in some sense compression means that you learn the model of reality and you\nhave just to uh remember where are your mistakes the better you are in predicting the\nand and in some sense when we look at our experience also when you look for instance the car driving you know in\nwhich direction it will go you are good like a in prediction and um you know it might be the case that the\nconsciousness is intertwined with compression it might be also the case that self-consciousness\nhas to do with compressor trying to compress itself so um okay i was just wondering what are the\nobjects in you know mathematics or computer science which are mysterious\nthat could uh that that could have to do with consciousness and then i thought um\nyou know you you see in uh mathematics there is something called cadal theorem\nwhich means okay you have if you have sufficiently complicated mathematical system it is possible to point the\nmathematical system back on itself in computer sense there is uh something called helping problem it's it's\nsomewhat similar construction so i thought that you know if we believe that that the that\nunder assumption that consciousness has to do with uh with compression uh\nthen you could imagine that the the as you keep on compressing things then at\nsome point it actually makes sense for the compressor to compress itself metacompression yeah consciousness is\nmetacompression that's uh that's and i and an idea\nand in some sense you know the creation of it thank you so uh but do you think if we think of a\ntouring machine a universal touring machine can that achieve consciousness\nso is there some thing beyond our traditional definition of computation that's required so it's a\nspecific computation and i said this computation has to do with compression and\nthe compression itself maybe other way of putting it is like you are internally creating the model of reality\nin order like a it's like a you try inside to simplify reality in order to predict what's going to happen\nand that also feels somewhat similar to how i think actually about my own conscious\nexperience so clearly i don't have access to reality the only access to reality is through you know cable going\nto my brain and my brain is creating a simulation of reality and i have access to the simulation of reality\n"}
{"pod": "Lex Fridman Podcast", "input": "Is there an algorithm for intelligence?", "output": "are you by any chance uh aware of uh the harder prize marcus hutter\nhe he made this prize for compression of wikipedia pages\nand there's a few qualities to it one i think has to be perfect compression which makes\ni think that little quirk makes it much less um applicable to the general task of\nintelligence because it feels like intelligence is always going to be messy uh\nlike perfect compression is feels like it's not the right goal but it's\nnevertheless a very interesting goal so for him intelligence equals compression\nand so the smaller you make the file given a large wikipedia page\nthe more intelligent the system has to be yeah that makes sense so you can make perfect compression if you store errors\nand i think that actually what he meant is you have algorithm plus errors and by the way hooter hatter is a he was pa uh\nphd advisor of shenleck who is the mind uh uh deep mind co-founder yeah yeah so\nthere's an interesting and now he's a deep mind there's an interesting uh network of people he's\none of the people that i think seriously took on the task of what would\nan agi system look like i think for a longest time\nthe question of agi was not taken seriously or rather rigorously\nand he did just that like mathematically speaking what would the model look like\nif you remove the constraints of it having to be\nhaving to have a reasonable amount of memory reasonable amount of running time complexity uh\ncomputation time what would it look like and essentially it's it's a half math half philosophical discussion\nof uh how would like a reinforcement learning type of framework look like for an agi yeah so he developed a framework\neven to describe what's optimal with respect to reinforcement learning like there is a theoretical framework which\nis as you said under assumption there is infinite amount of memory and compute and there was actually one person before his name\nis solomonov hutter extended amount of work to reinforcement learning\nbut there exists a theoretical algorithm which is optimal\nalgorithm to build intelligence and i can actually explain you the algorithm yes\nlet's go let's go so the task itself can i just pause\nhow absurd it is for brain in a skull trying to explain the algorithm for intelligence just go\nahead it is pretty crazy it is pretty crazy that you know the brain itself is actually so small and it can ponder\nhow to design algorithms that optimally solve the problem of intelligence okay all right so what's the algorithm so\nlet's see so first of all the task itself is described as\nyou have infinite sequence of zeros and ones okay you read n bits and you are about\nto predict n plus one bit so that's the task and you could imagine that every task could be casted as such\na task so if for instance you have images and labels you can just turn every image into sequence of zeros and\nones then label you concatenate labels and you and that that's actually the the\nand you could you could start by having training data first and then afterwards you have test data\nso theoretically any problem could be casted as a problem of predicting zeros\nand ones on this infinite type so um so let's say you read already n bits and\nyou want to predict n plus one bit and i will ask you to write\nevery possible program that generates these end bits okay so\nand you can have you you choose programming language it can be in python or c\nand the difference between programming languages might be there is a difference by constant\nasymptotically your predictions will be equivalent so you you read and beats you enumerate\nall the programs that produce these and end bits in their output and then in order to predict n plus one\nbit you actually weight the programs according to their length\nand there is like some specific formula how you weight them and then the n plus\none bit prediction is the prediction uh from each of this program according to that weight\nlike statistically you statistically pick so the smaller the program the more likely you you are to pick the its\noutput so uh that's that algorithm is grounded\nin the hope or the intuition that the simple answer is the right one it's a formalization of\nit yeah um it also means like if you would ask the question after\nhow many years would you know sun explode\nyou can say it's more likely the answer is to some power because it's a shorter program\nyeah and then other well i don't have a good intuition about\nhow different the space of short programs are from the space of large programs\nlike what is the universe where short programs uh like run things\nuh so as i said the things have to agree with end beats so even if you have\nyou you need to start okay if if you have very short program and they're like uh still some as if it's not perfect\nwith prediction of n bits you have to start errors what are the errors and that gives you the full program that\nagrees on end beats oh so you don't agree perfectly with the end bits and you store\nthat's like a longer a longer program slightly longer program because it contains these extra bits of\nerrors that's fascinating what's what's your intuition about\nthe the programs that are able to do cool stuff like intelligence and consciousness are they\nuh perfectly like is is it uh is there if then statements in them so\nlike is there a lot of exceptions that they're storing so um you could imagine if there would be tremendous amount of\nif statements yeah then they wouldn't be that short in case of neural networks you could imagine that\nwhat happens is uh they when you start with an uninitialized\nneural network uh it stores internally many possibilities how the\nhow the problem can be solved and sgd is kind of magnifying some some\nsome paths which are slightly similar to the correct answer so it's\nkind of magnifying correct programs and in some sense hdd is a search algorithm\nin the program space and the program space is represented by uh you know kind\nof the wiring inside of the neural network and there's like an insane number of ways how that features can be\ncomputed let me ask you the high level basic question that's not so basic\n"}
{"pod": "Lex Fridman Podcast", "input": "Neural networks and deep learning", "output": "what is deep learning is there a way you'd like to think of it that is different than like a generic\ntextbook definition the thing that i hinted just a second ago is maybe the uh closest to how i'm\nthinking these days about um deep learning so now the statement is\nuh neural networks can represent some programs uh it seems that various modules that we\nare actually adding up to are like a you know we we want networks to be deep because we we want multiple steps of the\ncomputation and and deep learning provides the way to\nrepresent space of programs which is searchable and it's searchable with stochastic gradient descent so we have\nan algorithm to search over a humongous number of programs and gradient descent kind of bubbles up\nthe things that are tend to give correct answers so a neural network\nwith a with fixed weights that's optimized do you think of that as a\nsingle program um so there is a work by christopher olach where he\nso he works on interpretability of neural networks and he was able to\nuh to identify inside of the neural network for instance a detector of a wheel for a\ncar or the detector of a mask for a car and then he was able to separate them out and assemble them uh together using\na simple program uh for the detector for a car detector that's like uh if you\nthink of traditionally defined programs that's like a function within a program that this particular neural network was\nable to find and you can tear that out just like you can copy and paste from stack overflow\nthat so uh any program is a composition of smaller programs\nyeah i mean the nice thing about the neural networks is that it allows the things to be more fuzzy than in case of\nprograms in case of programs you have this like a branching this way or that way and the\nneural networks they they have an easier way to to be somewhere in between or to share\nthings what to use the most beautiful or surprising idea in deep learning\nin the utilization of these neural networks which by the way for people who are not familiar\nneural networks is a bunch of uh what would you say it's inspired by the human brain there's neurons there's\nconnection between those neurons there's inputs and there's outputs and there's millions or billions of those neurons\nand the learning happens uh by adjusting the weights on the edges\nthat connect these neurons thank you for giving definition that i supposed to do it but i guess you have\nenough empathy to listeners to actually know that that might be useful no that's like\nso i'm asking plato of like what is the meaning of life he's not going to answer\nyou're being philosophical and deep and quite profound talking about the space of programs which is just very\ninteresting but also for people who are just not familiar with the hell we're talking about when we talk about deep\nlearning anyway sorry what is the most beautiful or surprising idea to you in in um in\nall the time you've worked at deep learning and you worked on a lot of fascinating projects\napplications of neural networks it doesn't have to be big and profound it can be a cool trick yeah i mean i'm\nthinking about the trick but like it's still amusing to me that it works at all yeah that let's say that the extremely\nsimple algorithm stochastic gradient descent which is something that i would be able you know to derive on the piece\nof paper to high school student uh when put at the ins at the scale of you know thousands\nof machines actually uh can create the behaviors we which we called kind of\nhuman like behaviors so in general any applications to cast a gradient descent to neural networks is\nis amazing to you so that or is there a particular application in natural language\nreinforcement learning uh and also would you attribute\nthat success too is it just scale what profound insight can we take from\nthe fact that the thing works for gigantic\nuh sets of variables i mean the interesting thing is these algorithms they were\ninvented uh decades ago and people actually\ngave up on the idea yeah and um you know back then they thought that we\nneed profoundly different algorithms and they spent a lot of cycles on very different algorithms and i believe that\nyou know we have seen that various various innovations that say like transformer or or dropout or so they can\nuh you know pass the help but it's also remarkable to me that this algorithm\nfrom 60s or so or i mean you can even say that the gradient descent was invented by leibniz\nin i guess 18th century or so that actually is the core of learning\nin the past people are it's almost like a out of the maybe an\nego people are saying that it cannot be the case that such a simple algorithm is there you know\nuh could solve complicated problems so they were in search for the\nother algorithms and as i'm saying like i believe that actually we are in the game where there is there are actually\nfrankly three levels there is compute there are algorithms and there is data and if we want to build intelligent\nsystems we have to pull all three levers and they are actually multiplicative\nand it's also interesting so you ask is it only compute people internally they did the studies\nto determine how much gains they were coming from different levels and so far we have seen that more gains came from\ncompute than algorithms but also we are in the world that in case of compute there is a kind of you know exponential\nincrease in funding and at some point it's impossible to invest more it's impossible to you know\ninvest 10 trillion dollars because we are speaking about that let's say all taxes in u.s\nuh but you're talking about money there could be innovation in the compute that's that's true as\nwell so i mean they're like a few pieces so one piece is human brain is an\nincredible super computer [Music] and they're like a\nit it has 100 trillion parameters or like a if you try to count\nvarious quantities in the brain there are like a neurons synapses that small number of neurons there is a lot of\nsynapses yeah it's unclear even how to map synapses\nto two parameters of neural networks but it's clear that there are many more yeah\nso it might be the case that our networks are still somewhat small\nit also might be the case that they are more efficient than brain or less efficient by some by some huge factor\ni also believe that there will be like a you know at the moment we are at the stage that the these neural networks\nthey require 1000x or like a huge factor of more data than humans do and it will\nbe a matter of there will be algorithms that\nvastly decrease sample complexity i believe so but the place where we are heading today is dark domains which\ncontains million x more data and even though computers might be\n1 000 times slower than humans in learning that's not the problem okay for instance\ni believe that it should be possible to create super human therapies\nuh by uh and and then they're like even simple steps of of doing what of of doing it\nand you know that the core reason is there is just machine will be able to read way more\ntranscripts of therapies and then it should be able to speak simultaneously with many more people and it should be\npossible to optimize it uh all in parallel and well there's now you're touching on\nsomething i deeply care about and think is way harder than we imagined um\nwhat's the goal of a therapist what's it called therapies so okay so one goal now this is\nterrifying to me but there's a lot of people that contemplate suicide suffer from\ndepression and they could significantly be helped with therapy\nand the idea that an ai algorithm might be in charge of that\nit's like a life and death task it's uh the stakes are high\nso one goal for a therapist whether human or ai\nis to prevent suicide ideation to prevent suicide how do you achieve that\nso let's see so to be clear i don't think that the current models are good enough for such\na task because it requires insane amount of understanding and patty and the models are far from this place but it's\nbut do you think that understanding empathy that signal is in the data um i\nthink there is some signal in the data yes i mean there are plenty of transcripts of conversations\nand it is possible to it is possible from it to understand personalities it is possible from it to\nunderstand uh if conversation is a friendly uh amicable uh\nantagonistic it is i believe that the you know given the fact that the models that we train now\nthey can they can have they are chameleons that they can have\nany personality they might turn out to be better in understanding uh personality of other people than\nanyone else and they feel pathetic to be empathetic yeah interesting uh but i wonder if there's\nsome level of multiple modalities required\nto be able to be empathetic of the human experience whether language is not enough to\nunderstand death to understand fear to understand uh childhood trauma\nto understand uh wit and humor required when you're dancing with the person who\nmight be depressed or suffering both humor and hope and love and all\nthose kinds of things so there's another underlying question which is self-supervised versus\nsupervised so can you get that from the data by just reading\na huge number of transcripts i actually so i think that reading huge number of transcripts is a step one it's like the\nsame way as you cannot learn to dance if just from youtube by watching it you\nhave to actually try it out yourself yeah and so i think that here that's a similar situation i also wouldn't deploy\nthe system in the high-stakes situations right away but kind of see gradually\nwhere it goes and obviously initially it would have to go hand with a hand in\nhand with humans but at the moment we are in the situation that actually\nthere is many more people who actually would like to have a therapy or or speak with with someone then there\nare therapies out there okay you know i was so so fundamentally i was thinking what are\nthe things that can vastly increase people well-being\ntherapy is one of them i think meditation is other one i guess maybe human connection is a third one and i\nguess pharmacologically it's also possible maybe direct brain stimulation or something like that but these are pretty\nmuch options out there then let's say the way i'm thinking about the agi endeavor is by default that's an\nendeavor to increase amount of wealth and i believe that we can vastly increase amount of\nwealth for everyone and simultaneously so i mean they're like two endeavors that\nmake sense to me one is like essentially increase amount of wealth and second one is uh increase overall human well-being\nand those are coupled together and they they can okay i would say these are different topics one can help another\n"}
{"pod": "Lex Fridman Podcast", "input": "Human reward functions", "output": "and uh you know therapist is a funny word because i see friendship and love\nas therapy i mean so therapist broadly defined as just friendship as a friend\nso like therapist is has a very kind of clinical sense to it but\nwhat is human connection you're like uh\nnot to get all camus and dostoyevsky on you but you know life is suffering and we draw\nwe seek connection with other humans as we desperately try to make sense of this\nworld in the deep overwhelming loneliness that we feel inside\nso i think connection has to do with understanding and i think that almost like a lack of\nunderstanding causes suffering if you speak with someone and you do you feel ignored that actually causes\npain if you are feeling deeply understood that actually they they might not even tell you what\nto do in life but like a pure understanding or just being heard understanding is a kind of\nit's a lot you know just being heard feel like you're being heard like somehow\nthat's uh alleviation temporarily of the loneliness that if somebody\nknows you're here with their body language with the way they are with the way they look at you\nwith the way they talk you feel less alone for a brief moment\nyeah very very much agree so i thought in the past about uh somewhat similar\nquestion to yours which is what is love uh rather what is connection yes and um\nand obviously i think about these things from ai perspective what would it mean um so i said that the you know intelligence\nhas to do with some compression which is more or less like i can say almost understanding of what is going around it\nseems to me that uh other aspect is there seem to be reward functions and\nyou can have a you know reward for uh food for maybe human connection for\nuh let's say warmth uh sex and so on and um\nand it turns out that the various people might be optimizing slightly different reward functions they essentially might\ncare about different things and um in case of\nlove at least the love between two people you can say that the um you know boundary between people dissolves to\nsuch extent that they end up optimizing each other reward functions\nyeah oh that's interesting um the success of each other yeah in some\nsense i would say love means uh helping others to optimize their uh reward functions not your reward\nfunctions not the things that you think are important but the things that the person cares about you try to help them\nto optimize it so love is uh if you think of two reward functions you\njust it's a condition yeah you combine them together yeah pretty much maybe like with a weight and it depends like\nthe dynamic of the relationship yeah i mean you could imagine that if you are fully uh optimizing someone's reward\nfunction without yours then yeah then maybe are creating code dependency or something like that yeah\ni'm not sure what's the appropriate weight but the interesting thing is i even i even think that the\nindividual person we ourselves we are actually\nless of a unified insight so for instance if you look at the donut on the one level you\nmight think oh this like it looks tasty i would like to eat it on another level you might tell yourself i shouldn't be\ndoing it because i want to gain muscles so and you know you might do it regardless kind of\nagainst yourself so it seems that even within ourselves they're almost like a kind of intertwined personas\nand i believe that the self-love means that the love between all these persons which\nalso means being able to love love yourself when we are angry or stressed\nor so combining all those reward functions of the different selves you have yeah and accepting that they are\nthere okay you know often people they have a negative self-talk or they say i don't like when i'm angry and like i try\nto imagine try to imagine if there would be like a\nsmall baby alex like a five years old who's angry angry and then you're like\nyou shouldn't be angry like stop being angry yeah but like instead actually you want the legs to come over give him a\nhug and he's like i say it's fine okay you can't be angry as long as you want yeah then he would stop\nor or maybe not or maybe not but you cannot expect it even yeah but still that doesn't explain the why\n"}
{"pod": "Lex Fridman Podcast", "input": "Love is part of the human condition", "output": "of love like why is love part of the human condition why is it useful to combine the reward functions\nit seems like that doesn't i mean i don't think reinforcement learning frameworks can give us answers to why\neven even the hudder framework has an objective function that's static so we came to existence as\na consequence of evolutionary process and in some sense the purpose of evolution is survival and then the\nthis complicated optimization objective baked into us let's say compression\nwhich might help us operate in the real world and it bake into us various reward functions yeah\nand then to be clear at the moment we are operating in the regime which is somewhat out of distribution where the\nevent evolution optimized us it's almost like love is a consequence of cooperation that we've discovered is\nuseful correct in some way it's even the case if you i just love the idea that love is like the out of distribution\nor it's not out of distribution it's like as you that it evolved for cooperation yes and i believe that the cop like a in\nsome sense cooperation ends up helping each of us individually so it makes sense evolutionary and there is a in\nsome sense and you know love means there is this dissolution of boundaries that you have a shared reward function and we\nevolve to actually identify ourselves with larger groups so we we can identify\nourselves you know with a family we can identify ourselves with a country to such an extent that people are willing\nto give away their life for country [Music] so there is we are wired actually even\nuh for love and at the moment i guess the\nmaybe it would be somewhat more beneficial if you will if we would identify ourselves\nwith all the humanity as a whole so so you can clearly see when people travel around the world when they run into\nperson from the same country they say oh which ctr and all this like all of a sudden they find all these similarities\nthey they they find some they befriend those folks earlier than others so there\nis like a sense some sense of the belonging and i would say i think it would be overall good thing to the word\nfor people to move towards i think it's even called open\nindividualism and move toward the mindset of a larger and larger groups so\n"}
{"pod": "Lex Fridman Podcast", "input": "Expanding our circle of empathy", "output": "the challenge there that's a beautiful vision and i share it to expand that circle of empathy that\ncircle of love towards the entirety of humanity but then you start to ask well where do you draw the line\nbecause why not expand it to other conscious beings and then at the finally\nfor our discussion something i think about is why not expand it to ai systems\nlike we we start respecting each other when the other the person the entity on the other side\nhas the capacity to suffer because then we develop a capacity to sort of empathize\nand so i could see ai systems that are interacting with humans more and more having conscious like\ndisplays so like they display consciousness through language and through other means\nand so then the question is like well is that consciousness because they're acting conscious\nand so you know the reason we don't like torturing animals\nis because they look like they're suffering when they're tortured and if ai looks like it's suffering\nwhen it's tortured how is that not\nrequiring of the same kind of empathy from us and respect and rights\nthat animals do and other humans do i think it requires empathy as well i mean i would like\ni guess us or humanity or so make a progress in understanding what consciousness is\nbecause i don't want just to be speaking about that the philosophy but rather actually make a scientific uh to have a\nlike a you know there was a time that people thought that there is a force of life\nand the things that have this force they are alive\nand i think that there is actually a path to understand exactly what consciousness is\nand um in some sense it might require essentially putting probes inside of a\nhuman brain what neuralink does so the goal there i mean there's several things with consciousness that\nmake it a real discipline which is one is rigorous measurement of consciousness\nand then the other is the engineering of consciousness which may or may not be related i mean you could also run into\ntrouble like for example in the united states for the department d.o.t department of\ntransportation and a lot of different places put a value on human life i think dot's\nuh values nine million dollars per person sort of in that same way you can get\ninto trouble if you put a number on how conscious a being is\nbecause then you can start making policy if a cow is uh 0.1\nor like um 10 as conscious as a human then you can start making calculations and might get\nyou into trouble but then again that might be a very good way to do it i would like uh\nto move to that place that actually we have scientific understanding what consciousness is yeah and then we'll be\nable to actually assign value and i believe that there is even the path for the experimentation in it so uh you know\nwe said that you know you could put the probes inside of the brain there is actually few other things that you could\ndo with devices like neuralink so you could imagine that the way even to measure if ai system is conscious\nis by literally just plugging into the brain and i mean that that seems that's kind of easy but the plugging into the brain\nand asking person if they feel that their consciousness expanded this direction of course has some issues\nyou can say you know if someone takes a psychedelic drug they might feel that their consciousness expanded even though\nthat drug itself is not conscious right so like you can't fully trust the self-report of a person saying their\ntheir consciousness is expanded or not let me ask you a little bit about\n"}
{"pod": "Lex Fridman Podcast", "input": "Psychedelics and meditation", "output": "psychedelics because uh there's been a lot of excellent research on uh different psychedelics psilocybin mdma\nyeah even dmt drugs in general marijuana too\nuh what do you think psychedelics do to the human mind it seems they take\nthe human mind to some interesting places is that just a little uh hack\na visual hack or is there some profound expansion of the mind so let's see i i don't believe in magic\ni believe in that i believe in in science in\nin causality still let's say and then as i said like i think that the brain\nthat the our subjective experience of reality is uh\nwe live in the simulation run by our brain and the simulation that our brain runs\nthey can be very pleasant or very hellish drugs they are changing some hyper\nparameters of the simulation it is possible thanks to change of these hyper parameters to actually look back on your\nexperience and even see that the given things that we took for granted they are\nchangeable so they allow to have a amazing perspective there is also\nfor instance the fact that after dmt people can see the full movie inside of their head\ngives me further belief that the brain can generate that full movie that the brain is actually\nlearning the model of reality to such extent that it tries to predict what's going to happen next yeah very high\nresolution so it can replay realities actually extremely high resolution and it's also kind of interesting to me\nthat somehow there seems to be some similarity between\nthese uh drugs and meditation itself and i actually started even these days to\nthink about meditation as a psychedelic and do you practice meditation\ni i practice meditation i mean i once few times on the retreats and it feels after like after\nsecond or third day of meditation\nthere is a there is almost like a sense of you know tripping what does the meditation retreat entail\nso i mean you you wake up early in the morning and you meditate for extended\nperiod of time and alone yeah so it's optimized even though there\nare other people it's optimized for isolation so you don't speak with anyone you don't actually look into other\npeople's eyes and you know you sit on the chair and\nsay the passage meditation tells you uh to focus on the breath so you try to put\nall the all attention into breathing and breathing in and breathing out\nand the crazy thing is that as you focus attention like that\nafter some time their stamps starts coming back like some\nmemories that you completely forgotten it almost feels like um that you have a\nmailbox and then you you know you are just like a archiving email one by one\nand at some point at some point there is like a amazing feeling of getting to mailbox zero\nzero emails and uh it's very pleasant it's it's kind of it's it's\nit's crazy to me that that once\nyou resolve these inner stories or like inner traumas\nthen once there is nothing uh left the default state of human mind is\nextremely peaceful and happy extreme like some sense it it feels that\nit feels at least to me in the way how when i was a child that i can look at any object and\nit's very beautiful i have a lot of curiosity about the simple things and that's where usually meditation takes me\nare you what are you experiencing are you just taking in simple sensory\ninformation and they're just enjoying the rawness of that sensory information so there's no\nthere's no memories all that kind of stuff you're just enjoying being\nyeah pretty much i mean still there is a there it's it's thoughts are slowing\ndown sometimes they pop up but it's also somehow the extended meditation takes\nyou to the space that they are way more friendly you know way more positive um\nthere is also this uh this thing that we've actually\nit almost feels that the it almost feels that the we are\nconstantly getting a little bit of a reward function and we are just spreading this reward function on\nvarious activities but if you stay still for extended period of time it kind of\naccumulates accumulates accumulates and there is a there is a sense there is a\nsense that at some point it passes some threshold and it feels as\ndrop is falling into kind of ocean of love and bliss and that's like a this is like a very pleasant and as i'm\nsaying okay that corresponds to the subjective experience some people\nuh i guess in spiritual community they describe it that that's the reality and\ni would say i believe that they're like all sorts of subjective experience that one can have and\ni believe that for instance meditation might take you to the subjective experiences which are very pleasant collaborative and i would like a word to\nmove toward a more collaborative uh place\nyeah i would say that's very pleasant that i enjoy doing stuff like that i i i wonder how that maps to your uh\nmathematical model of love with the the reward function combining a bunch of things\nit seems like our life then is we're just we have this reward\nfunction and we're accumulating a bunch of stuff in it with weights\nit's like um like multi-objective and\nwhat meditation is is you just remove them remove them until the weight on one\nor just a few is is very high and that's where the pleasure comes from yeah so\nsomething similar how i'm thinking about this so i told you that there is like a\nthere is a story of who you are and i think almost about it as a you know text prepended to gpt\nyeah and some people refer to it as ego okay it's like a story\nwho who you are okay so ego is the prompt for gpt three gpg yes yes and\nthat's description of you and then with meditation you can get to the point that actually you experience things without\nthe prompt and you experience things like as they are you are not biased over the\ndescription how they supposed to be uh that's very pleasant and then with respect to the reward function uh it's\npossible to get to the point that the there is dissolution of self and therefore you can say that they are\nyou you're having a you're or like your brain attempts to simulate the reward function of everyone else or like\neverything that's there is this like a love which feels like a oneness with everything\nand that's also you know very beautiful very pleasant at some point you might have a lot of altruistic\nthoughts during that moment and then the self uh always comes back how would you recommend\nif somebody is interested in meditation like a big thing to take on as a project would you recommend a meditation retreat\nhow many days what kind of thing would you recommend i think that actually retreat is the way to go and it almost\nfeels that as i said like a meditation is a psychedelic but\nwhen you take it in the small dose you might barely feel it once you get the high dose actually you're gonna feel it\num so even cold turkey if you haven't really seriously meditated for a prolonged period of time just go to a\nretreat yeah how many days how many days start the weekend one weekend so like two three days\nand it's like it's interesting that first or second day it's hard and at\nsome point it becomes easy there's a lot of seconds in a day how hard is the meditation retreat just\nsitting there in a chair so the thing is actually\nit literally just depends on your uh on death your own framing like if you\nare in the mindset that you are waiting for it to be over or you are waiting for nirvana to happen it will be very\nunpleasant yeah and in some sense even the difficulty it's not even in\nthe lack of being able to speak with others like you are sitting there your\nlegs will hurt from sitting in terms of like the practical things do you experience kind of discomfort like\nphysical discomfort of just sitting like your your butt being numb your\nlegs being sore all that kind of stuff yes you experience it and then the they teach you to observe it\nrather and it's like a the crazy thing is you at first might have a feeling toward trying to escape it yeah and that\nbecomes very apparent that that's extremely unpleasant and then you just just observe it and\nat some point it it just becomes uh it just is it's like a i remember with ilya told me\nsome time ago that uh you know he takes a cold shower and his mindset of taking a court cold shower was to\nembrace suffering yeah excellent i do the same there's the art style yes my style\ni like this so my style is actually i also sometimes take cold showers it is purely observing\nhow the water goes through my body like a purely being present not trying to escape from there yeah and i would say\nthen it actually becomes pleasant it's not like ah well that that's\ninteresting um i i'm also that mean that's that's the\nway to deal with anything really difficult especially in the physical space is to observe it\nto say it's pleasant it's a i would use a different word\nyour uh you're accepting of the full beauty of\nreality i would say because say pleasant but yeah i mean in some sense it is\npleasant that's the only way to deal with a cold shower is to to become an observer and to find\njoy in it same with like really difficult physical uh exercise or like running for a really\nlong time endurance events just anytime you're exhausted any kind of pain i think the only way to survive\nit is not to resist it just to observe it you mentioned ilya elias discover\n"}
{"pod": "Lex Fridman Podcast", "input": "Ilya Sutskever", "output": "he's very he's our chief scientist but also he's very close friend of mine he co-founded open air with you i've spoken\nwith him a few times he's brilliant i really enjoy talking to him\nhis mind just like yours works in fascinating ways now both of you are not able to define\ndeep learning simply uh what's it like having him\nas somebody you have technical discussions with on in space machine learning\ndeep learning ai but also life what's it like when these two uh agents\nget into a self-play situation in in a room what's it like collaborating with him\nso i believe that we have extreme uh respect to each other so\num i mean i love ilia's insight both like uh\ni guess about consciousness uh life ai but uh in terms of the it's interesting\nto me because you're a brilliant uh\nthinker in the space of machine learning like intuition like digging deep in what works\nwhat doesn't why it works why it doesn't and so is ilia i'm wondering if there's\ninteresting deep discussions you've had with him in the past or disagreements that were very\nproductive so i can say i also understood over the time where\nare my strengths so obviously we have plenty of ai discussions and\num and you know i myself have plenty of ideas but like i consider ilya\none of the most prolific ai scientists in the entire world and i think that\num i realized that maybe my super skill is being able to bring people to\ncollaborate together that i have some level of empathy that is unique in ai world and that might come you know from\neither meditation psychedelics or let's say i read just hundreds of books on this topic so and i also went through a\njourney of you know i develop all sorts of algorithms so i think that\nmaybe i can that's my super human skill uh\nilia is one of the best ai scientists but then i'm pretty good in assembling teams and\ni'm also not holding two people like i'm growing people and then people become managers that open yeah there's room any\nof them like a research manager so you you find you find places where you're excellent\nand and he finds like his his deep scientific insights is where he is and\nyou find ways you can the puzzle pieces fit together correct okay you know ultimately for instance\nlet's say ilia he doesn't manage people uh that's not what he likes or so um\ni i like i like hanging out with people by default i'm an extrovert and i care about people oh interesting okay\nokay cool so that that fits perfectly together but i i mean uh i also just like your intuition about various\nproblems in machine learning he's definitely one i really enjoy i remember talking to him\nabout something i was struggling with which is coming up with a good model for\npedestrians for human beings across the street in the context of autonomous vehicles\nand he immediately started to like formulate a framework within which you can evolve a model for pedestrians like\nthrough self-play all that kind of mechanisms the depth of thought on a particular\nproblem especially problems he doesn't know anything about is fascinating to watch it makes you realize like um\nyeah the the limits of the that the human intellect might be limitless\nor it's just impressive to see a descent on the vape come up with clever ideas yeah i mean so even in the space of deep\nlearning when you look at various people there are people you know who invented\nsome breakthroughs once but there are very few people who did it multiple times and you can think if someone\ninvented it once that might be just a shared luck and if someone invented it multiple\ntimes you know if a probability of inventing it once is one over a million then probability of inventing it twice\nor three times would be one over a million square or to the power of three which which would be just impossible so\nit literally means that it's it's given that uh it's not the luck yeah and ilea\nis one of these few people who um who have uh a lot of these inventions in\nhis arsenal it also feels that the now for instance if you think about folks like gauss or euler\nand you know at first they read a lot of books and then they did thinking and then they\nfigure out math and that's how it feels with ilya yeah you know at first he read stuff and then\nlike he spent his thinking cycles and that's a really good way to put it\nwhen i talk to him [Music] i i see thinking\nhe's actually thinking like he makes me realize that there's like deep thinking that the human mind\ncan do like most of us are not thinking deeply like you really have to put a lot of\neffort to think deeply like i have to really put myself in a place where i think deeply about a problem it takes a\nlot of effort it's like a it's like an airplane taking off or something you have to achieve deep focus he he's just\nuh he's what is it his brain is like a vertical takeoff\nin terms of airplane analogy so it's interesting but it i mean cal newport talks about this\nas ideas of deep work it's you know most of us don't work much at all in terms of like\nlike deeply think about particular problems whether it's math engineering all that kind of stuff\nyou want to go to that place often and that's real hard work and some of us are better than others at that so i think\nthat the big piece has to do with actually even engineering your environment such that it's conducive to\nthat yeah so um see both ilia and i uh on the frequent\nbasis we kind of disconnect ourselves from the world in order to be able to do extensive amount of thinking yes so ilia\nusually he just leaves ipad at hand he loves his ipad\nand for me i'm even sometimes you know just going for a few days to different location to airbnb i'm\nturning off my phone and there is no access to me yeah and\nthat's extremely important for me to be able to actually just formulate new thoughts to do deep work rather than to\nbe reactive and the the older i am the more of these like random tasks are at\nhand before i go on to that uh thread let me return\n"}
{"pod": "Lex Fridman Podcast", "input": "How does GPT work?", "output": "to our friend gpt let me ask you another ridiculously big question\ncan you give an overview of what gpt 3 is or like you say in your twitter bio gpt\nn plus one how it works and why it works so um gpt 3 is a\nhumongous neural network and let's assume that we know what is neural network okay by the definition\nand it is trained on the entire internet and just to predict\nnext word so let's say it sees part of the uh article and it the only task that\nit has at hand it is to say what would be the next word uh what would be the next word\nand it becomes uh really exceptional at the task of figuring out what's the next word so you\nmight ask why would this be an important task why\nwould it be important to predict what's the next word and it turns out that a lot of problems\nuh can be formulated uh as a text completion problem so gpt is\npurely uh learning to complete the text and you could imagine for instance if you are asking a question who is a\npresident of united states then gpt can give you an answer to it it turns out that many more things can\nbe formulated this way you can format text in the way that you have sentence in english\nyou make it even look like a some content of a website uh elsewhere which would be teaching people how to\ntranslate things between languages so it would be en colon text in english fr colon and then you uh\nand then you ask people and then you ask model to to continue and it turns out that the such a model is predicting\ntranslation from english to french the crazy thing is that\nthis model can be used for way more sophisticated tasks so you can format text such that\nit looks like a conversation between two people and that might be a conversation between you and elon musk and because\nthe model read all the texts about elon musk it will be able to predict elon musk\nwords as it would be elon musk it will speak about colonization of mars about sustainable future and so on and\nit's also possible to to even give arbitrary personality to\nthe model you can say here is a conversation with a friendly ai bot\nand the model uh will complete the text as a friendly ai bot so i mean\nhow do i express how amazing this is so just to clarify\na conversation generating a conversation between me and elon musk it wouldn't just generate good\nexamples of what elon would say it would get the syntax all correct so like interview style you would say like\nelon colon and lex con like it it's not just like uh inklings of\nsemantic correctness it's like the whole thing grammatical\nsyntactic semantic it's just really really impressive\nuh generalization yeah i mean i also want to you know provide some caveats so it can generate\nfew paragraphs of coherent text but as you go to uh longer pieces it actually\ngoes off the rails okay if you would uh try to write a book it won't work out uh this way what way does it go off the\nrails by the way is there interesting ways in which it goes off the rails like what falls apart first so the model is\ntrained on the all the existing data that is out there which means that it is\nnot trained on its own mistakes so for instance if it would make a mistake then\nuh i kept so to give give you an example so let's say i have a conversation with\na model pretending that is elon musk and then i start putting some i'm start\nactually making up things which are not factual um i would say like twitter\nbut i gotcha sorry yeah um okay i don't know i would say that elon is my\nwife and the model will just keep on carrying it on and as if it's\ntrue yes and in some sense if you would have a normal conversation with elon he would\nbe what the [ __ ] yeah there would be some feedback between so the the model is trained on\nthings that humans have written but through the generation process there's no human in the loop feedback correct\nthat's fascinating makes sense so it's magnified it's like the errors get magnified and magnified right and it's a\nit's also interesting i mean first of all humans have the same problem it's just that we\nuh we make fewer errors and magnify the errors slower i think that actually what\nhappens with humans is if you have a wrong belief about the world as a kid then very quickly you will learn that\nit's not correct because you are grounded in reality and you are learning from your new experience yes\nbut do you think the model can correct itself too it through the power of the\nrepresentation and so the absence of elon musk being your wife\ninformation on the internet want to correct itself there won't be examples like that so the\nerrors would be subtle at first saddle at first and in some sense\nyou can also say that the data that is not out there is the data which would represent how the human learns\nthat's an a and and maybe model would be trained on such a data then it would be better off how intelligent is gpt 3 do\nyou think like when you think about the nature of intelligence it seems exceptionally\nimpressive but then if you think about the big agi problem is this footsteps along the way\nto agi so let's see seems that intelligence itself is there are multiple axis of it and\ni would expect that the the systems that we are building they\nmay end up being super human on some axis and sub human on some other axis it\nwould be surprising to me on all axis simultaneously they would become superhuman\nof course people ask this question is gpt a spaceship that that would take us to moon or are we\nputting a building a ladder to heaven that we are just building bigger and bigger ladder and we don't know in some\nsense uh which one of these two which one is better\ni'm trying to i like stairway to heaven that's a good song so i'm not exactly sure which one is better but you're\nsaying like the the spaceship to the moon is actually effective correct so people who criticize gpt yeah\nthey say jarga is just building a taller a ladder\nand it will never reach the moon and at the moment i would say the way i'm\nthinking is this like a scientific question and i'm also in heart i'm a builder\ncreator and like i'm thinking let's try out let's see how far it goes and so far\nwe see constantly that there is a progress yeah so what do you think\ngpt4 gpt5 gpt n plus one\nwill uh there'll be a phase shift like a transition to a to a place where\nwe'll be truly surprised then again like gpt3 is already very like truly surprising the people that criticize\ngpg3 as it's there as a what is it ladder to heaven i think too quickly get accustomed to\nhow impressive it is that the prediction of the next word can achieve such\ndepth of semantics accuracy of syntax grammar and semantics\num do you do you think gpt four and five and six will continue\nto surprise us i mean definitely there will be more impressive models there is a question of\ncourse if there will be a phase shift and\nthe also even the way i'm thinking about the about these models is that when we build these models\nyou know we see some level of the capabilities but we don't even fully understand everything that the model can\ndo and actually one of the best things to do is to allow other people to probe the model to\neven see what is possible hence the using gpg as an api\nand opening it up to the world yeah i mean so when i'm thinking from perspective of\nthere like a obviously various people are that have concerns about agi including myself\nand then when i'm thinking from perspective what's the strategy even to deploy these things to the world\nthe the one strategy that i have seen many times working is the iterative deployment that you deploy\num slightly better versions and you allow other people to criticize you so you actually are tried out you see where\nare their fundamental issues and it's almost you don't want to be in that situation that you are holding into\npowerful system and there's like a huge overhang then you deploy it and it might have a random chaotic impact on the\nworld so you actually want to be in the situation that they are gradually deploying systems\n"}
{"pod": "Lex Fridman Podcast", "input": "AI safety", "output": "i asked this question of ilio let me ask you you this question i've been reading a lot\nabout stalin and power\nif you're in possession of a system that's like agi that's exceptionally powerful\ndo you think your character integrity might become corrupted like famously power corrupts and\nabsolute power corrupts absolutely so i believe that you want at some point to\nwork toward distributing the power i think that you want to be in the situation\nthat actually agi is not controlled by a small number of people but\nessentially by a larger collective so the thing is that requires a george washington style\nmove in the ascent to power there's always a moment when somebody gets a lot of power\nand they have to have the integrity and uh the moral compass to give away\nthat power that humans have been good and bad throughout history at this\nparticular step and i wonder i wonder we like blind ourselves in uh\nfor example between nations a race uh towards uh\nyeah ai race between nations we might blind ourselves and justify to ourselves the development of ai without\ndistributing the power because we want to defend ourselves against china against russia that kind\nof that kind of logic and i wonder how we um\nhow we design governance mechanisms that um prevent us from\nbecoming power hungry and in the process destroying ourselves so let's see i have been thinking about\nthis topic quite a bit but i also want to admit that uh once again i actually want to rely\nway more on sam outman on it hero than a heroed an excellent block\non how even to distribute wealth and his proper he proposed in his block\nto tax equity of the companies rather than profit and to distribute it and this is\nthis is an example of uh washington move\ni guess i personally have insane trust in some he already spent plenty of money running\na universal basic income project that like gives me i guess\nmaybe some level of trust to him but i also i guess\nlove him as a friend yeah i wonder because we're sort of summoning a new set of technologies\ni wonder if we'll be cognizant like you're describing the process of open ai but it could also be\nat other places like in the us government right both china and the us are now\nfull steam ahead on autonomous weapons systems development and that's really worrying to me because\nin the framework of something being a national security danger or military\ndanger you can do a lot of pretty dark things that blind our moral compass\nand i think ai will be one of those things in some sense the the mission\nand the work you're doing at openai is like the counterbalance to that so you want to have more open ai and less\nautonomous weapon systems i i i like these statements like to be clear like this interesting and i'm thinking about\nit myself but uh this is a place that i i okay i put my trust actually\nin some hence because it's extremely hard for me to reason about it yeah i mean one important statement to make is\num it's good to think about this yeah no question about right no question even\nlike low-level quote-unquote engineer like there's such a\ni remember i i programmed a car uh our rc car\nthey went really fast like 30 40 miles an hour and i remember i was like sleep deprived\nso i programmed it pretty crappily and it like uh the the code froze so it's doing some\nbasic computer vision and it's going around on track but it's going full speed\nand uh there's a bug in the code that uh the car just went it didn't turn it went straight\nfull speed and smashed into the wall i remember thinking the seriousness with which you need to\napproach the design of artificial intelligence systems and the programming of artificial intelligence systems\nis high because the consequences are high like that little car smashing it to the wall\nfor some reason i immediately thought of like an algorithm that controls nuclear weapons\nhaving the same kind of bug and so like the lowest level engineer and the ceo of a company all need to have the\nseriousness in approaching this problem and thinking about the worst case consequences so i\nthink that is true i mean the what i also recognize in myself and\nothers even asking this question is that it evokes a lot of fear and fear itself ends up being actually\nquite debilitating the place where i arrived at the moment\nmight sound cheesy or so but it's almost to build things out of love rather than\nfear yeah i can focus on how i can you know maximize the value how\nthe systems that i'm building might be uh useful i'm not saying that the fear doesn't\nexist out there and like it totally makes sense to minimize it but i don't want to be working because\nuh i'm scared i want to be working out of passion out of curiosity out of the\nyou know looking forward for the positive future with uh the definition of love arising from a\nrigorous practice of empathy so not just like your own conception of what is good for the world but uh always listening to\nothers correct like at the love where i'm considering reward functions of others\nothers to infil limit to infinity is like a sum like one to n where n is uh seven\nbillion or whatever it is not not projecting my reward functions on others yeah exactly okay\n"}
{"pod": "Lex Fridman Podcast", "input": "OpenAI Codex", "output": "can we just take a step back to something else super cool which is uh opening up codex\ncan you give an overview of what open-air codecs and github co-pilot is\nhow it works and why the hell it works so well so with gpd3 we noticed that the\nsystem um you know that system training all the language out there started having some\nrudimentary coding capabilities so we're able to ask it you know to\nimplement addition function between two numbers and indeed it can write python or javascript code for that and then we\nthought um we might as well just go full steam ahead and try to create a system\nthat is actually good at what we are doing every day ourselves which is programming\nwe optimize models for proficiency in coding we actually even created models that both have a\ncomprehension of language and code and codex is api for these models so\nit's first pre-trained on language and then i don't know if you can say fine-tuned\nbecause there's a lot of code but it's language and code it's language and code\nit's also optimized for various things like let's say low latency and so on codex is the api that's similar to gpd3\nwe expect that there will be proliferation of the potential products that can use coding capabilities and i\ncan i can speak about it in a second compiled is the first product\nand developed by github so as we're building uh models we wanted to make sure that these models are useful\nand we work together with github on building the first product co-pilot is actually as you code it suggests you\ncode completions and we have seen in the past they're like a various tools that can suggest how to like a few characters\nof the code or the line of code the the thing about copilot is it can generate 10 lines of code you\nit's often the way how it works is you often write in the comment what you want to happen because\npeople in comments they describe what happens next so um these days when i code instead of\ngoing to google to search for the appropriate code to solve my problem i say oh for this array could\nyou smooth it and then you know it imports some appropriate libraries and say it uses numpy convolution or so i\nthat i was not even aware that exists and it does the appropriate thing um so you you write a comment maybe the\nheader of a function and it completes the function of course you don't know what is the space of all the possible\nsmall programs it can generate what are the failure cases how many edge cases how many subtle\nerrors there are how many big errors there are it's hard to know but the fact that it works at all on in a large\nnumber of cases is incredible it's like a it's a kind of search engine\ninto code that's been written on the internet correct so for instance when you search things online then\nusually you get to the some particular case like if you go to stack overflow\npeople describe that one particular situation uh and then they seek for a\nsolution but in case of uh co-pilot it's aware of your entire context and in\ncontexts oh these are the libraries that they are using that's the set of the variables that is initialized and on the\nspot it can actually tell you what to do so the interesting thing is and we think that the copilot is one\npossible product using codex but there is a place for many more so internally we tried out you know to\ncreate other fun products so it turns out that a lot of tools out there\nlet's say google calendar or microsoft word or so they all have uh internal api to build\nplugins around them so there is a way in the sophisticated way to control calendar or microsoft\nword today if you want if you want more complicated behaviors from these programs you have to add a\nnew button for every behavior but it is possible to use codex and\ntell for instance to calendar could you schedule an appointment with\nblacks next week after 2 pm and either writes corresponding piece of code\nand that's the thing that actually you want so interesting so what you figure out is there's a lot of\nprograms with which you can interact through code and so there you can generate that code\nfrom natural language that's fascinating and that's somewhat like also closest to\nuh what was the promise of siri or alexa yeah so previously all these behaviors they were had\nhard coded yeah and it seems that codex on the fly can pick up the api of let's\nsay given software yeah and then it can turn the language into use of this api without hard coding you can find it can\ntranslate to machine language correct it to uh so for example this would be really exciting for me like for um adobe\nproducts like photoshop uh which is the i think actionscript i think there's a scripting language that\ncommunicates with them same with premiere and you could imagine that that allows event to\ndo coding by voice on your phone so for instance in the past okay as of\ntoday i'm not editing word documents on my phone because it's just the keyboard\nis too small but if i would be able to tell to my phone you know uh make the header\nlarge and then move the paragraphs around and it does actually what i want so i can tell you one more cool thing or\neven how i'm thinking about codex so if you look actually at the evolution\nof of computers we started with very primitive\ninterfaces which is a punch card and punch card essentially you make a holes in the\nin the plastic card to indicate zeros and ones and during that time there was a small\nnumber of specialists who were able to use computers and by the way people even suspected that there is no need for many\nmore people to use computers but then we moved from punch cards to\nat first assembly then c and these programming languages they were slightly higher level they allowed\nmany more people to code and they also led to more of a proliferation of\ntechnology and you know further on there was a jump to say from c plus plus to java and python\nand every time it has happened more people are able to code and we build more technology and it's even you\nknow hard to imagine now if someone will tell you that you should write code in\nassembly instead of let's say python or or or java or javascript and codex is yet\nanother step toward kind of bringing computers closer to humans such that you communicate with a computer\nwith your own language rather than with a specialized language and i think that it will lead to\nan increase of number of people who can code yeah and then and the kind of technologies that those people will\ncreate is like it's innumerable it could you know it could be a huge number of technologies we're not predicting at all\nbecause that's less and less requirement of uh having a technical mind a programming mind you're not opening it\nto the world of um other kinds of minds creative minds\nartistic minds all that kind of stuff i would like for instance biologists who work on dna to be able to program and\nnot to need to spend a lot of time uh learning it and i i believe that's a good thing to the word and i would\nactually add out that so at the moment i'm a managing codex team and also\nlanguage team and i believe that there is like a plenty of brilliant people out there and they should apply\noh okay yeah awesome so what's the language in the codexes so those are kind of they're overlapping teams so it's like\ngpt the raw language and then the codex is like applied to programming\ncorrect and they are quite intertwined there are many more teams involved making these uh\nmodels extremely efficient and deployable for instance there are people who are working to you know\nmake our data centers uh amazing or there are people who work on pro putting these models into production\nor uh or even pushing it at the very limit of the scale\nso all aspects from from the infrastructure to the actual machine learning so i'm just saying that multiple teams while the\nand the team working on codex and language uh i guess i'm i'm directly managing them i would like i would love\nto hire yeah if you're interested in machine learning this is probably one of the most exciting uh problems and like systems to\nbe working on because it's actually it's it's pretty cool like what what uh the\nprogram synthesis like generating of programs is very interesting very interesting problem that has echoes of\nreasoning and intelligence in it it and i think there's a lot of fundamental questions that you might be\nable to sneak sneak up to by generating programs yeah\nthe one more exciting thing about the programs is that so i said that the um you know the in case of language that\none of the troubles is even evaluating language so when the things are made up you you need somehow\neither a human to say that this doesn't make sense or so in case of program there is one extra\nlevel that we can actually execute programs and see what they evaluate to so that process might be somewhat\nmore automated in in order to improve the uh qualities of generations and\nthat's not saying so like the wow that's really interesting so for the language that you know the simulation to actually\nexecute it as a human mind yeah for programs there is a there is a computer\non which you can evaluate it wow that's a brilliant little\ninsight that the thing compiles and runs that's first\nand second you can evaluate on a like do automated unit testing\nand in some sense it seems to me that we will be able to make a tremendous progress you know\nwe are in the paradigm that there is way more data and there is like a\ntranscription of millions of uh of uh software engineers yeah\nyeah so i mean you just me because i was going to ask you about reliability the thing\nabout programs is you don't know if they're going to like a program that's controlling a\nnuclear power plant has to be very reliable so i i wouldn't start with controlling nuclear power plant can i be\none day but that that's not actually that's not on the current roadmap that's not that's step one and you know it's\nthe russian thing you just want to go to the most powerful destructive thing right away run by javascript but i got you so it's\na lower impact but nevertheless what you're making me realize it is possible to achieve some levels of\nreliability by doing testing and i thought you could imagine that them you know maybe there are ways for a\nmodel to write even code for testing itself and so on and there exists a ways to create the\nfeedback loops that the model could keep on improving\nby writing programs that generate tests for the instance for instance\nand that's how we get consciousness because it's meta compression that's what you're going to write that's the\ncomment that's the prompt that generates consciousness compressor of compressors you just write\nthat do you think the code that generates consciousness would be simple\nso let's see i mean ultimately the core idea behind will be simple but there\nwill be also decent amount of engineering involved like in some sense\nit seems that you know spreading these models on many machines and it's not that trivial yeah and\nwe find all sorts of innovations that make our models more efficient\ni believe that first models that i guess are conscious are like a\ntruly intelligent they will have all sorts of tricks\nbut then again there's uh which is certain argument that maybe the tricks are temporary thing yeah they\nmight be temporary things and in some sense it's also even important to um\nto know that even the cost of a trick so sometimes people are eager to put the\ntrick while forgetting that there is a cost of maintenance or like a long-term cost long-term cost\nor maintenance or maybe even flexibility of code to actually implement new ideas so even if you have\nsomething that gives you 2x but it requires you know 1000 lines of code i'm not sure if it's actually worth it so in\nsome sense you know if it's five lines of code and 2x i would take it\nand and we we we see many of this but also you know that requires some level\nof i guess lack of attachment to code that we are willing to remove it yeah\n"}
{"pod": "Lex Fridman Podcast", "input": "Robotics", "output": "so you led the open ai robotics team can you give an overview of of the cool\nthings you're able to accomplish what are you most proud of so when we started robotics we knew that actually reinforcement learning works\nand it is possible to solve very complicated problems like for instance alphago is an evidence\nthat it is possible to to build superhuman and gold players dota 2 is a\nan evidence that is possible to build superhuman uh\nagents playing dota so i asked myself a question you know what about robots out there could we train machines to solve\narbitrary tasks in the physical world our approach was i guess let's pick a\ncomplicated problem that if we would solve it that means that we made some uh significant progress in the\ndomain and then we went after the problem so um we noticed that actually the\nrobots out there they are kind of at the moment optimized per task so you can have a robot that it's like if you have\na robot opening a battle it's very likely that the end factor is a battle opener\nand and in some sense that's a hack to be able to solve a task which makes any task easier and um ask myself so what\nwould be a robot that can actually solve many tasks yeah and we conclude that that\nlike a human hands have such a quality that indeed they are you know you have\nfive kind of tiny arms attached individually they can manipulate\npretty broad spectrum of objects so we went after a single hand like a trying\nto solve rubik's cube single-handed we picked this task because we thought that there is no way to\nharcode it and it's also we picked the robot on which it would be hard to hardcode it and\nwe went after the solution such that it could generalize to other problems and just to clarify it's\none robotic hand solving the rubik's cube the hard part isn't the solution to the rubik's cube is the manipulation of\nthe uh of like having it not fall out of the hand having it use the uh\nfive baby arms to uh what is it like rotate different parts of the rubik's cube to achieve the\nsolution correct yeah so what uh what was the hardest part about that\nwhat was the approach taken there what are you most proud of obviously we have like a strong belief in reinforcement\nlearning and uh you know one path it is to do reinforcement learning the real world\nother path is to the simulation in some sense the tricky part about the real world is at\nthe moment our models they require a lot of data there is essentially no data\nand i did we decided to go through the path of the simulation and in simulation\nyou can have infinite amount of data the tricky part is the fidelity of the simulation and also can you in\nsimulation represent everything that you represent otherwise in the real world and you know it turned out that uh\nthat you know because there is lack of fidelity it is possible to that what we\nwhat we arrived at is training a model that doesn't solve one simulation but it\nactually solves the entire range of simulations which uh vary uh in terms of like uh what's the\nexactly the friction of that cube or the weight or so and the single ai that can solve all of them\nends up working well with the reality how do you generate the different simulations so\nyou know there's plenty of parameters out there we just pick them randomly and and in simulation model just goes for\nthousands of years and keeps on solving rubik's cube in each of them and the thing is the neural network that we used\nit has a memory and as it presses for instance the side\nof the of the cube it can sense oh that's actually this side was\nuh difficult to press i should press it stronger and throughout this process kind of\nlearns even how to how to solve this particular instance of the rubik's cube back even mass it's\nkind of like a you know sometimes when you go to a gym and after\nafter bench press you try to lift the\nand you kind of forgot uh and and your hand goes like yeah right away because\nkind of you got this to maybe different weight yeah and it takes a second to adjust yeah\nand this kind of of a memory that model gained through the process of interacting with the cube in the\nsimulation i appreciate you speaking to the audience with the bench press all the bros in the audience\nprobably working out right now there's probably somebody listening to this actually doing bench press\nso maybe uh put the bar down and pick up the water bottle and you'll know exactly\nwhat uh what check is talking about okay so what uh\nwhat was the hardest part of getting the whole thing to work so the hardest part is\nat the moment when it comes to a physical world when it comes to robots\nthey require maintenance it's hard to replicate a million times it's\nit's also it's hard to replay things exactly i remember this situation that\none guy at our company he had like a model that performs way better than other models in\nsolving rubik's cube and you know we kind of didn't know what's going on\nwhy it's that and it turned out that you know he was running it from his\nlaptop that had better cpu or uh or better or maybe local gpu as well\nand uh because of that there was less of a latency and the model was the same\nand that actually made solving rubik's cube more reliable so in some sense there might be some\nsaddlebacks like that when it comes to running things in the real world even hinting on that\nyou could imagine that the initial models you would like to have models which are insanely huge neural networks\nand you would like to give them even more time for thinking and when you have these real-time\nsystems then you might be constrained actually by the amount of latency\nand ultimately i would like to build the system that it is worth for you to wait five minutes\nbecause it gives you the answer that you are willing to wait for five minutes so latency is a very unpleasant\nconstraint underwish to operate correct and also there is actually one more thing which is tricky about robots\nthere is actually no not much data so the data that i'm speaking about would be a data of\nfirst person experience from the robot and like a gigabytes of data like that if we would have gigabytes of data like\nthat of robot solving various problems it would be very easy to make a progress on robotics and you can see that in case\nof text or code there is a lot of data like a first person perspective data on the writing code\nyeah so you had this you mentioned this really interesting idea that\nif you were to build like a successful robotics company so open as mission is much bigger than robotics this is one of\nthe one of the things you've worked on but if it was a robotics company they\nyou wouldn't so quickly dismiss supervised learning i correct that you would build a robot\nthat was perhaps one like um an empty shell like dumb and they\nwould operate under tele operation so you would invest that's just one way to do it invest in\nhuman super like direct human control of the robots as it's learning and over time add more and more automation\nthat's correct so let's say that's how i would build a robotics company today if i would be building a robotics\ncompany which is you know spent 10 million dollars or so recording human trajectories controlling\na robot after you find a thing that the robot should be doing\nthat there's a market fit for like that you can make a lot of money with that product correct correct yeah\nso i would record data and then i would essentially train supervised learning model on it\nthat might be the path today long term i think that actually what is needed is to train powerful models over\nvideo so um you have seen maybe a models that can generate images like dali\nand people are looking into models generating videos they're like various algorithmic questions even how to do it\nand it's unclear if there is enough compute for this purpose but i i suspect that the models that which\nwould have a level of understanding of video same as gpt has the level of understanding of\ntext could be used to train robots to solve tasks they\nwould have a lot of common sense if one day i'm pretty sure one day\n"}
{"pod": "Lex Fridman Podcast", "input": "Developing self driving cars and robots", "output": "there will be a robotics company by robotics company i mean the primary\nsource of income is is from robots that is worth over\n1 trillion dollars what do you think that company will do i think self-driving cars no\nit's interesting because my mind went to personal robotics robots in the home it seems like there's much more market\nopportunity there i think it's very difficult to achieve\ni mean this this this might speak to something important which is i understand self-driving much\nbetter than understand robotics in the home so i understand how difficult it is to actually solve self-driving\nto uh to a level not just the actual computer vision and the control problem and just the basic problem self-driving\nbut creating a product that would undeniably be um\nthat will cost less money like it will save you a lot of money like orders the magnitude less money that could replace\nuber drivers for example so car sharing that's autonomous that creates a similar or better experience in terms\nof how quickly you get from a to b or just whatever the the pleasantness of the experience\nthe efficiency of the experience the value of the experience and at the same time the car itself costs cheaper\ni think that's very difficult to achieve i think there's a lot more um low hanging fruit in the home\nthat that could be i also want to give you perspective on like how challenging it would be at home\nor like it maybe kind of depends on the exact problem that you'd be solving okay if we are speaking about these robotic\narms and hence these things they cost tens of thousands of dollars or maybe 100k\nand you know maybe obviously maybe there would be economy of scale these things\nwould be cheaper but actually for any household to buy the price would have to go down to maybe\nthousand bucks yeah i personally think that uh\nso self-driving car it provides a clear service i don't think robots in the home\nthey'll be a trillion dollar company will just be all about service meaning it will not necessarily be about\nlike a robotic arm that helps you i don't know open a bottle\nor wash the dishes or any of that kind of stuff it has to be able to take care of that whole the\ntherapist thing you mentioned i i think that's um of course there's a line between what is a robot and what is\nnot like doesn't really need a body but you know some uh ai system with some embodiment i\nthink so the tricky part when you think actually what's the difficult part is um\nwhen the robot has like when there is a diversity of the environment with which the robot has to\ninteract that becomes hard so you know on one spectrum you have industrial robots as they are doing over\nand over the same thing it is possible to some extent to prescribe the movements and with very small amount of\nintelligence the the movement can be repeated millions of times um the it\nthere are also you know various pieces of industrial robots where it becomes harder and harder like for instance in\ncase of tesla it might be a matter of putting a a rack inside of a car\nand you know because the rack kind of moves around it's it's not that easy it's not exactly the same every time it\nends up being the case that you need actually humans to do it and while you know welding cars together\nit's a very repetitive process and then in case of self-driving itself\nthe difficulty has to do with the diversity of the environment but still\nthe car itself and the problem that you are solving is you try to avoid even interacting with\nthings you are not touching anything around because touching itself is hard and then if you would have in the home\nuh robot that you know has to touch things and like if these things they change the shape if there is a huge\nvariety of things to be touched then that's difficult if you are speaking about the robot which there is you know\nhead that is smiling in some way with cameras that it doesn't you know touch things that's relatively simple\nokay so to both agree and to push back so you're referring to touch like\nsoft robotics like the actual touch but i would argue that you could formulate\njust basic interaction between um like non-contact interaction\nis also a kind of touch and that might be very difficult to solve that's the basic this not disagreement but that's\nthe basic open question to me with self-driving cars and disagreement with elon which is how much interaction\nis required to solve self-driving cars how much touch is required you said that\nin your intuition touch is not required and my intuition to create a product\nthat's compelling to use you're going to have to uh interact with pedestrians not just avoid\npedestrians but interact with them when we drive around in major cities\nwe're constantly threatening everybody's life with our movements and that's how they respect us there's a\ngame theoretically going on with pedestrians and i am afraid you can't just\nformulate autonomous driving as a collision avoidance problem so i i think it goes\nbeyond like a collision avoidance is the first order approximation but then at least in case of tesla they\nare gathering data from people driving their cars and i believe that's an example of supervised learning data that they can\ntrain their models uh on and they are doing it which you know can give the model this\nlike another level of of a behavior that is needed to actually\ninteract with the real world yeah it's interesting how much data is required to achieve that\num what do you think of the whole tesla autopilot approach the computer vision based approach with multiple cameras and\nthere's a data engine it's a multi-task multi-headed neural network and it's this fascinating process of uh similar\nto what you're talking about with the the robotics approach uh which is you know you deploy neural\nnetwork and then there's humans that use it and then it runs into trouble in a bunch of places and that stuff is sent back so\nlike the deployment discovers a bunch of edge cases and those edge cases are sent back\nfor supervised annotation thereby improving the neural network and that's deployed again\nit goes over and over until the the network becomes really good at the task of driving becomes safer and safer what\ndo you think of that kind of approach to robotics i believe that's the way to go so in some sense even when i was\nspeaking about you know collecting trajectories from humans that's like a first step and then you deploy the\nsystem and then you have humans revising the all the issues and in some sense\nlike this approach converges to system that doesn't make mistakes because for the cases where there are mistakes you\ngot their data how to fix them and the system will keep on improving so there's a very\nto me difficult question of how hard that you know how long that converging takes how hard it is\nuh the other aspect of autonomous vehicles this probably applies to certain robotics applications\nis society right they put as as the quality of the system\nconverges so one there's a human factors perspective of psychology of humans being able to supervise those uh even\nwith teleoperation those robots and the other society willing to accept robots\ncurrently society is much harsher on self-driving cars than it is on human driven cars in terms of the expectation\nof safety so the bar is set much higher than for humans and we're so if there's\na death in an autonomous vehicle that's seen as much more\nmuch more dramatic than a death in a human driven vehicle part of the success of deployment of\nrobots is figuring out how to make robots part of society both on the just\nthe human side on the media journalist side and also on the policy government side and that seems to be uh\nmaybe you can put that into the objective function to optimize but that is that is definitely um\na tricky one and i wonder if that is actually the trickiest part for self-driving cars or any system that's\nsafety critical it's not the algorithm it's the society accepting it\nyeah i i would say i believe that the part of the process of deployment is\nactually showing people that the given things can be trusted yeah and you know\ntrust is also like a glass that is actually really easy to crack it yeah\nand damage it and i think that's actually very common with uh\nwith innovation that there is some resistance toward it yeah and\nit's just the natural progression so in some sense people will have to keep on proving that indeed these systems are\nworth being used and i would say i also found out that\noften the best way to convince people is by letting them experience it yeah\nabsolutely that's the case for tesla autopilot for example that's the case with uh yeah with\nbasically robots in general it's it's kind of funny to hear people talk about robots like\nthere's a lot of fear even like legged robots but when they actually interact with them\nthere's joy i love interacting with them and the same with the car with the robot\nif it starts being useful i think people immediately understand and if the product is designed well they\nfall in love you're right it's actually even similar when i'm thinking about co-pilot the github\nco-pilot there was a spectrum of responses that people had and uh ultimately\nuh the important piece was to let people try it out and then many people just\nloved it especially like programmers yeah programmers but like some of them you know they came with a\nfear yeah but then you try it out and you think actually that's cool okay and you know you can try to resist the same way\nas you know you could resist moving from punch cards to let's say\nc plus or so and it's a little bit futile\n"}
{"pod": "Lex Fridman Podcast", "input": "What is the benchmark for intelligence?", "output": "so we talked about generation program generation of language\neven self-supervised learning in the visual space for robotics and then reinforcement learning what do you and\nlike this whole beautiful spectrum of ai do you think is a good\nbenchmark a good test to strive for to achieve intelligence that's a strong\ntest of intelligence you know it started with alan turing and the touring test maybe you think natural language\nconversation is a good test so you know it would be nice if for instance machine would be able to solve\nriemann hypothesis in math that would be i think that would be very\nimpressive so theorem proving is that to you proving theorems is a good\noh oh like one thing that the machine did you would say damn exactly\nokay that would be quite quite impressive i mean the the tricky\npart about the benchmarks is um you know as we are getting closer with them we have to invent new\nbenchmarks there is actually no ultimate benchmark out there yeah see my thought with the riemann hypothesis would be\nthe moment the machine proves it would say okay well then the problem was easy\nthat's what happens and i mean in some sense um that's actually what happens over the years in ai that like uh\nwe get used to things very quickly you know something i talked to rodney brooks i don't know if you know that is\nhe called alpha zero homework problem because he was saying like there's nothing special about it it's not a big\nleap and i i didn't well he's coming from one of the aspects that we referred to as he was part of uh\nthe founding of irobot which deployed now tens of millions of robot in the home so\nif you see robots that are actually in the homes of people\nas the legitimate instantiation of artificial intelligence then yes maybe an ai that plays a silly\ngame like going chess is not a real accomplishment but to me it's it's a fundamental leap but i think we as\nhumans then say okay well then that uh that game of chess or go wasn't that difficult compared to the thing\nthat's currently unsolved so my intuition is that from perspective of the evolution of\nyou know these ai systems we'll at first see the tremendous progress in digital space and the you know the main thing\nabout digital space is also that you can everything is that there is a lot of recorded data plus you can very rapidly\ndeploy things to billions of people while in case of uh physical space the\ndeployment part takes multiple years you have to manufacture things and\nyou know delivering it to actual people it's very hard so i'm expecting that the first and the\nprices in digital space of goods they would go you know down to\nthe let's say marginal costs are to zero and also the question is how much of our life will be in digital because it seems\n"}
{"pod": "Lex Fridman Podcast", "input": "Will we spend more time in virtual reality?", "output": "like we're heading towards more and more of our lives being in the digital space so like\ninnovation in the physical space might become less and less significant like why do you need to drive anywhere\nif most of your life is spent in virtual reality i still would like you know to\nat least at the moment my impression is that i would like to have a physical contact with other people and that's very important to me and we don't have a\nway to replicate it in the computer it might be the case that over the time it will change like in 10 years from now why not have\nlike an arbitrary infinite number of people you can interact with some of them are real some are not\nwith uh arbitrary characteristics that you can define based on your own\npreferences i think that's maybe where we are heading and maybe i'm resisting the future yeah\ni'm telling you i if i got to choose\nif i could live in elder scrolls skyrim versus the real world i'm not so sure i\nwould stay with the real world yeah i mean the question is so will vr be sufficient to get us there or do do\nyou need to you know plug electrodes in the brain and it would be nice if these electrodes\nwouldn't be invasive yeah or at least like provably non-destructive\nbut in in the digital space do you do you think we'll be able to solve the touring test the spirit of the touring\ntest which is do you think we'll be able to achieve compelling natural language\nconversation between people like have friends that are ai systems on the internet\ni thought i think it's doable do you think the current approach of gbt will take us there so there is you know\nthe the part of at first learning all the content out there and i i think that steel system should keep on learning as\nit speaks with you yeah and i think that should work the question is how exactly to do it and you\nknow obviously we have people at open air asking these questions\nand kind of at first pre-training on all existing content is like a backbone and\nit's a decent backbone do you think ai needs a body\n"}
{"pod": "Lex Fridman Podcast", "input": "AI Friendships", "output": "connecting to our robotics question to uh truly connect with humans or can can most of the connection be in the\ndigital space so let's see we know that there are people who met\neach other online and they felt in love yeah so it seems that it's conceivable to\nestablish connection which is purely through internet\nand of course it might be more compelling than more modalities you add\nso it would be like you're proposing like a tinder but for ai are you like swipe right and left and\nhalf the systems are ai and the other is uh humans and you don't know which is which\nthat would be ours that would be our formulation of touring test the the moment ai is able to achieve more swipe\nright or left whatever the the moment is able to be more attractive than other humans\nit passes the torrent test then you would pass the turing test in attractiveness that's right well no like attractiveness just declare conversation\nnot just visual right it's also attractiveness with wit and humor and uh whatever\nwhatever makes conversations pleasant for humans\nokay all right um so so you're saying uh it's possible to\nachieve in the digital space in some sense i would almost ask that question why wouldn't that be possible\nright well i have this argument with my dad all the time he thinks that touch and smell are\nreally important so they can be very important and i'm saying the initial systems they won't\nhave it still i wouldn't like their people being born\nwithout these senses and you know i believe that they can still fall in love and have meaningful life\nyeah i wonder if it's uh possible to go close to all the way by just training on\ntranscripts of conversations like i wonder how far that takes us so i i think that actually still you want\nimages like i would like so i don't have kids but like i could imagine the having ai tutor it has to see you know\nkids drawing some pictures on their paper and and also facial expressions and all\nthat kind of stuff we use uh dogs and humans use their eyes and uh to communicate with each other i\nthink this that's that's a really powerful mechanism of communication body language too that uh words are much uh lower\nbandwidth and for body language we still you know we kind of have a system that displays an image\nof its or facial expression on the computer it doesn't have to move you know mechanical pieces or so so i think\nthat uh you know there is like kind of a progression you can imagine that text might be the simplest to tackle\nbut this is not a complete human experience at all you expand it to\nlet's say images both for input and output and what you describe is actually the final\ni guess frontier what makes us human the fact that we can touch each other or smell or so and it's the hardest from\nperspective of data and deployment and i okay i believe that these things might\nhappen gradually are you excited by that possibility this particular application of\nhuman to ai friendship and interaction so let's see\nlike would you uh do you look forward to a world you you said you're living with a few folks and you're very close\nfriends with them do you look forward to a day where one or two of those friends are ai systems so if the system would be truly wishing\nme well rather than being in the situation that it optimizes for my time to interact\nwith the system the line between those is it's a gray\nit's a gray area i i think that's the distinction between love and possession and these things\nthey might be often correlated for humans but it's it like like a you you\nmight find that there like some friends with whom you haven't spoken for months yeah and then you know you pick up the\nphone it's as the time hasn't passed they are not holding to you\nand i will i wouldn't like to have ai system that you know it's it's\ntrying to convince me to spend time with it i would like the system to optimize\nfor what i care about and help me in achieving my own goals\nbut there's some i mean i don't know there's some manipulation there's some possessiveness there's some insecurities\nthis fragility all those things are necessary to form a close friendship over time to\ngo through some dark [ __ ] together some bliss and happiness together i feel like\nthere's a lot of greedy self-centered behavior within that process my intuition but i might be wrong is\nthat human computer interaction doesn't have to go through uh\ncomputer being greedy possessive and so on it is possible to train systems maybe\nthat they actually you know they are i guess prompted or fine-tuned or so\nto truly optimize for what you care about and you could imagine that you know\nthat the way how the process would look like is at some point\nwe as a human as we look at the transcript of the conversation or like an entire interaction and we say\nactually here there was more loving way to go about it and we supervise system\ntoward being more loving or maybe we train the system such that it has a reward function toward being\nmore loving yeah or maybe the possibility of the system being an [ __ ]\nand manipulative and possessive every once in a while is a feature not a bug\nbecause some of the happiness that we experience when two\nsouls meet each other when two humans meet each other is a kind of break from the [ __ ] in the world\nand so you need [ __ ] and ai as well because like it'll be like a breath of fresh air to\ndiscover an ai that the three previous ais you had are too\nfriendly or no no or or cruel or whatever it's like some kind of mix\nand then this one is just right but you need to experience the full spectrum like i think you need to be able to\nengineer [ __ ] so let's see\nbecause there's some level to us of being appreciate to appreciate the human\nexperience we need the dark and the light so that kind of reminds me\num i met a while ago at the meditation retreat uh one woman and\num you know beautiful beautiful woman and she had a she had a crutch okay she\nhad the trouble uh walking on one deck i asked her what has happened\nand she said that five years ago she was in maui hawaii\nand she was eating a salad and some snail fell into the salad and apparently\nthere are neurotoxic snails over there and she got into coma for a year okay oh wow\nand apparently there is you know high chance of even just dying but she was in the coma at some point\nshe regained partially consciousness she was able to hear people in the room\npeople behave as she wouldn't be there you know at some point she started being\nable to speak but she was mumbling like a barely able to to express herself and\nat some point she got into wheelchair then at some point she actually noticed that she can move her uh\na toe and then she knew that she will be able to walk and then you know that's where she was\nfive years after and she said that since then she appreciates the fact that she can move her toe\nand i was thinking do i need to go through such experience to appreciate that i have i can move my\ntoe well that's really good story a really deep example yeah and in some sense it might be the case\nthat we don't see light if we haven't went through the darkness but i wouldn't say that we\nshould we shouldn't assume that that's the case which may we maybe will do engineer shortcuts\nyeah ilia had this you know belief that maybe one has to go for a week or six months\nto some challenging camp yeah to just experience you know a lot of\ndifficulties and then comes back and actually everything is bright everything is beautiful i'm with iliana it must be a\nrussian thing where are you from originally i'm i'm polish polish okay\ni'm tempted to say that explains a lot but uh yeah there's something about the russian the necessity of suffering i\nbelieve i believe suffering or rather struggle is necessary i believe that\nstruggle is necessary i mean in some sense you even look at the story of any superhero\nin that movie it's not that it was like everything like it goes easy easy i like how that's your ground truth\nit's the story of superheroes okay uh you mentioned that you used to do research at night and go to bed at like\n"}
{"pod": "Lex Fridman Podcast", "input": "Sleep", "output": "6 a.m or 7 a.m i still do that often\num what uh sleep schedules have you tried to make for a productive and happy life\nlike is there um is there some interesting wild sleeping patterns that you engaged that\nyou found that works really well for you i tried at some point decreasing number of hours of sleep like\ngradually like a half an hour every few days less you know i was hoping to just save time\nthat clearly didn't work for me like at some point there's like a phase shift and i felt tired all the time\nuh you know there was a time that i used to work during the nights the nice thing\nabout the nights is that no one disturbs you and even i remember\nwhen i was meeting for the first time with greg brookman his cto and chairman of openai\nour meeting was scheduled to 5 pm and i overstepped for the meeting\nover slept for the meeting yeah 5 p.m yeah now you sound like me that's hilarious okay yeah and uh at the moment\nin some sense uh my sleeping schedule also has to do with the fact that i'm\ninteracting with people i sleep without an alarm so\nso yeah the the team thing you mentioned extrovert thing because most humans operate during a certain set\nof hours you're forced to then operate at the same set of hours\nbut i'm not quite there yet i found a lot of joy just like you said\nworking through the night because it's quiet because the world doesn't disturb you\nand there's some aspect counter to everything you're saying there's some joyful aspect to sleeping\nthrough the mess of the day because uh people are having meetings and sending emails and there's drama\nmeetings i can sleep through all the meetings you know i have meetings every day and they prevent me from having\nsufficient amount of time for focus work and\nthen i modified my calendar and i said that i'm out of office wednesday thursday and\nfriday every day and i'm having meetings only monday and tuesday and that vastly\npositively influenced my mood that i have literally like had three days for fully focused work yeah so there's\nbetter solutions to this problem than staying awake all night okay you've been part of development of some\n"}
{"pod": "Lex Fridman Podcast", "input": "Generating good ideas", "output": "of the greatest ideas in artificial intelligence what would you say is your process for developing good novel ideas\nyou have to be aware that clearly there are many other brilliant people around so\nyou have to ask yourself a question why the given idea\nlet's say wasn't uh tried by someone else and in some sense it has to\ndo with you know kind of simple it might sound simple but like i'm thinking outside of\nthe box and what do i mean here so for instance for a while people in academia they assumed\nthat you have a fixed data set and then you optimize the algorithms\nin order to get the best performance and that was so in great assumption\nthat no one thought about training models on anti-internet\nor like that that maybe some people thought about it but if it felt too too\nmany as unfair and in some sense that's almost like a it's not my idea or so but that's an\nexample of breaking a typical assumption so you want to be in the paradigm that\nyou are breaking a typical assumption in the context of the ai community\ngetting to pick your dataset as cheating correct and in some sense so that was a that was assumption that many people had\nout there and then if you free yourself from assumptions\nthen they are likely to achieve something that others cannot do and in some sense if you are\ntrying to do exactly the same things as others it's very likely that you're gonna have the same results yeah i\nbut there's also that kind of tension which is uh asking yourself the question why\nhaven't others done this because um\ni mean i get a lot of good ideas but i think probably most of them suck\nwhen they meet reality so so actually i think the other big piece\nis uh getting into habit of generating ideas training your brain toward generating ideas and not even\nsuspending judgment of the ideas so in some sense i noticed myself that\neven if i'm in the process of generating ideas if i tell myself oh that was a bad idea\nthen that actually interrupts the process and i cannot generate more ideas because i'm actually focused on the\nnegative part why it won't work yes but i created also environment in the way\nthat it's very easy for me to to store new ideas so for instance next to my bed\ni have a voice recorder and it happens to me often like i wake\nup in that during the night and i have some idea in the past i was writing them down on my phone but that\nmeans you know turning off this turning on the screen and that wakes me up or like pulling a paper which requires you\nknow turning on the light these days i just start recording it\nwhat do you think i don't know if you know who jim keller is i know team color he's a big proponent of thinking hard on\na problem right before sleep so that he can sleep through it and solve it in a sleep\nor like come up with radical stuff in his sleep he was trying to get me to do this so\nit happened from my experience perspective it happened to me many times during the high school\ndays when i was doing mathematics that i had the solution to my problem as\ni woke up at the moment regarding thinking hard\nabout the given problem is i'm trying to actually devote substantial amount of time to think\nabout important problems not just before the sleep like i'm organizing amount of the huge\nchunks of time such that i'm not constantly working on the urgent problems but i actually have time to\nthink about the important one so you do it naturally but his idea is that you kind of\nprime your brain to make sure that that's the focus you know oftentimes people have other worries in their life that's not\nfundamentally deep problems like i don't know uh just stupid drama in your life\nand even at work all that kind of stuff he wants to kind of pick the most important problem\nthat you're thinking about and go to bed on that i think that's why i mean the other thing that comes to my mind is\nalso i feel the most fresh in the morning so during the morning i try to work on\nthe most important things rather than i'm just being pulled by urgent things or checking email or so\nwhat do you do with the cause i've been doing the voice recorder thing too but i end up recording so many messages it's\nhard to organize i have the same problem now i have heard that google pixel is really good in\ntranscribing text and i might get a google pixel just for the sake of transcribing text yeah people listening\nto this if you have a good voice recorder suggestion that transcribed please let me know i it's some of it is uh this has to do\nwith uh uh open ai codex too like some of it is\nsimply like the friction i need uh apps that remove that friction between\nvoice and the organization of the resulting transcripts and all that kind of stuff\num but yes you're right absolutely like during uh for me it's walking sleep too\nbut walking and running especially running get a lot of thoughts during running and\nthere's there's no good mechanism for recording thoughts so one more thing that i do i have a\nseparate phone uh which i which has no apps and maybe it has like a\naudible or let's say kindle no one has this phone number this kind of my meditation phone yeah and\ni try to expand the amount of time that that's the phone that i'm having i it has also\ngoogle maps if i need to go somewhere and i also use this phone to write down ideas\nah that's really good idea that's a really good idea often actually what i end up doing is even sending a\nmessage from that phone to the other phone so that's actually my way of recording messages or i just put them\ninto notes i love it what advice would you give to a young person high school\n"}
{"pod": "Lex Fridman Podcast", "input": "Advice for young people", "output": "college about how to be successful you've done a lot of incredible things in the past\ndecade so maybe maybe of some something there might be something there might be something\ni mean might sound like a simplistic or so but i would say literally just\nfollow your passion double down on it and if you don't know what's your passion just figure out what could be a\nwhat could be a passion so this that might be an exploration when i was in elementary school was math\nand chemistry and i remember for some time i gave up on math because\nmy school teacher she told me that i'm dumb and i i i guess maybe an advice would be\njust ignore people if they tell you that you're dumb you mentioned something offline about\nchemistry and explosives um what was that about so let's see\nso a story goes like that i can\ni got into chemistry maybe i was like a second grade of my elementary school\nthird grade uh i started going to chemistry classes uh\ni i really love building stuff and i did all the experiments that they\ndescribed in the book okay you know how to create oxygen with vinegar and\nand baking soda so okay so i did all the experiments and at some point i was you know so\nwhat's next what can i do and uh explosives they also it's like a you\nhave a clear reward signal you know if the thing worked or not so i remember\nat first i got i got interested in producing hydrogen that was kind of funny experiment from school you can\njust burn it and then i moved to uh nitroglycerin so that's also\nrelatively easy to synthesize i started producing essentially dynamite and detonating with it with my\nfriend i remember there was a you know there was at first like maybe two attempts that i went with a friend\nto detonate what we built and it didn't work out and like a third time he was like ah it won't work like\nuh let's don't waste time and um now we were\ni was carrying this uh this you know that tube with dynamite i don't\nknow pound or so dynamite in my backpack or like riding on the bike to the edges of the city\n[Laughter] yeah and attempt number three\nthis would be to number three attempt number three and uh now we we dig a hole to\nuh put it inside it actually had the uh you know electrical detonator\nwe we draw a cable behind the tree i even i never had i haven't ever seen\nlike a explosion before so i thought that there will be a lot of sound and but you know we're like laying down\nand i'm holding the cable and the battery at some point you know it kind of like a three to one\nand uh i just connected it and it felt like at the ground shake it was like a more like\na sound and then the soil started kind of lifting up and\nstarted falling on us yeah wow and then uh now the friends said let's let's make\nsure next time we have helmets but also you know i'm happy that nothing happened to me it\ncould have been the case that i i lost the limb or so yeah but that's childhood\nof an engineering mind with a strong reward signal of an explosion\ni love it my there's some aspect of uh chemists the the the chemist i know like my dad\nwith plasma chemistry plasma physics he was very much into explosives too it's a worrying quality of\npeople that work in chemistry that they love i think it is that exactly is the\nthe strong signal that the thing worked there is no doubt there's no doubt there's some magic it's almost like a\nreminder that physics works that chemistry works it's cool it's almost\nlike a little glimpse at nature that you yourself engineer i that's why i really\nlike artificial intelligence especially robotics is you create a little piece of nature\nand in some sense even for me with explosives the motivation was creation rather than distraction yes exactly\n"}
{"pod": "Lex Fridman Podcast", "input": "Getting started with machine learning", "output": "in terms of advice i forgot to ask about just machine learning and deep learning for people who are specifically\ninterested in machine learning how would you recommend they get into the field so um i would say implement everything\nand also there is plenty of courses so like from scratch um so on different levels of abstraction in some sense but\ni would say brain or implement something from scratch or implement something from a paper or implement something you know\nfrom podcasts that you have heard about i would say that's a powerful way to understand things so it's often the case\nthat you read the description and you think you understand but you truly\nunderstand once you build it then you actually know what really meant that in the description\nis there particular topics that you find people just fall in love with so i i've seen\ni tend to uh really enjoy reinforcement learning because it's it's much more\nit's much easier to get to a point where you feel like you created something special\nlike like fun games kind of things that are rewarding it's rewarding yeah uh as opposed to like\nuh reimplementing from scratch more like supervised learning kind of things it's it's yeah so you know if if\nsomeone would optimize for things to be rewarding then it feels that the things that are somewhat generative they have\nsuch a property so yes you have for instance yes adversarial networks or you have just even generated language models\nand you could you can even see um internally we have seen this thing with our releases so we have a we\nreleased recently two models there is one model called dali that generates images and there is other model called\nclip that actually uh you provide various possibilities what could be the\nanswer to what is on the picture and it can tell you which one is the most likely okay and in some sense in case of the\nfirst one dali it is very easy for you to understand that actually there is magic going on uh\nand in the in case of the second one even though it is insanely powerful and you know people from a vision community\nthey as they started probing it inside they actually understood\nhow far it goes it's difficult for person at first to see\nhow well it works and that's the same as you said that in case of supervised learning models you\nmight not kind of see or it's not that easy for you to understand the the strength\neven though you don't believe in magic to see the magic let's say that magic it's a generative that's really\nbrilliant so anything that's generative because then you are at the core of the creation you get to\nexperience creation without much effort unless you have to do it from scratch but and it feels that\nyou know humans are wired there is some level of reward for creating stuff yeah\nlike of course different people have a different weight on this reward yeah in the big objective function in the big\nobjective of a person of a person uh you wrote that beautiful\n"}