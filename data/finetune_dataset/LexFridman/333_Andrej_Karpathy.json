{"pod": "Lex Fridman Podcast", "input": "Introduction", "output": "- I think it's possible that physics has exploits and we should be trying to find them. Arranging some kind of a crazy quantum mechanical system\nthat somehow gives you buffer overflow, somehow gives you a rounding error in the floating point. Synthetic intelligence is kind of like\nthe next stage of development. And I dunno where it leads to, at some point\nI suspect the universe is some kind of a puzzle. These synthetic AIs will uncover that puzzle and solve it.\n- The following is a conversation with Andrej Karpathy, previously the director of AI at Tesla.\nAnd before that, at OpenAi and Stanford. He is one of the greatest scientists, engineers,\nand educators in the history of artificial intelligence. This is the Lex Fridman Podcast.\nTo support it, please check out our sponsors. And now, dear friends, here's Andrej Karpathy.\n"}
{"pod": "Lex Fridman Podcast", "input": "Neural networks", "output": "What is a neural network and why does it seem to do such a surprisingly good job of learning?\n- What is a neural network? It's a mathematical abstraction of the brain.\nI would say that's how it was originally developed. At the end of the day, it's a mathematical expression and it's a fairly simple mathematical expression\nwhen you get down to it. It's basically a sequence of meter multipliers,\nwhichever really dot products mathematically and some nonlinearity is thrown in. And so it's a very simple mathematical expression\nand it's got knobs in it. - Many knobs. - Many knobs. And these knobs are loosely related to basically\nthe synapses in your brain. They're trainable. They're modifiable. And so the idea is we need to find the setting of the knobs that makes the neural net\ndo whatever you want it to do, like classify images and so on. And so there's not too much mystery I would say in it.\nYou might think that, basically, you don't want to endow it with too much meaning with respect to the brain and how it works.\nIt's really just a complicated mathematical expression with knobs. And those knobs need a proper setting for it to do something desirable.\n- Yeah. But poetry is just the collection of letters with spaces, but it can make us feel a certain way.\nAnd in that same way, when you get a large number of knobs together, whether it's inside the brain or inside a computer,\nthey seem to surprise us with their power. - Yeah. I think that's fair.\nSo basically, I think I'm underselling it by a lot because you definitely do get very surprising emergent behaviors out of these neural nets\nwhen they're large enough and trained on complicated enough problems. Like say, for example, the next-word prediction\nin a massive dataset from the internet. And then these neural nets take on pretty surprising magical properties.\nYeah, I think it's kind of interesting how much you can get out of even very simple mathematical formalism. - When your brain right now is talking,\nis it doing next-word prediction or is it doing something more interesting? - Well, it's definitely some kind of a generative model\nthat's GPT like and prompted by you. - [Lex] Yes. - So you're giving me a prompt\nand I'm kind of like responding to it in a generative way. - And by yourself perhaps a little bit, like are you adding extra prompts from your own memory\ninside your head or no? - Well, it definitely feels like you're referencing some kind of a declarative structure\nof memory and so on. And then you're putting that together with your prompt\nand giving away some answers. - How much of what you just said has been said by you before.\n- Nothing, basically right? - No, but if you actually look at all the words you've ever said in your life and you do a search,\nyou'll probably have said a lot of the same words in the same order before. - Yeah.\nCould be. I mean, I'm using phrases that are common, et cetera, but I'm remixing it into a pretty unique sentence\nat the end of the day. But you're right, definitely, there's like a ton of remixing.\n- It's like Magnus Carlson said I'm rated 2,900, whatever, which is pretty decent.\nI think you're talking very, you're not giving enough credit to neural nets here.\nWhat's your best intuition about this emergent behavior? - I mean, it's kind of interesting\nbecause I'm simultaneously underselling them, but I also feel like there's an element to which I'm over-\nit's actually kind of incredible that you can get so much emergent magical behavior out of them despite them being so simple mathematically.\nSo I think those are two surprising statements that are juxtaposed together.\nAnd I think, basically, what it is, is we are actually fairly good at optimizing these neural nets. And when you give them a hard enough problem,\nthey are forced to learn very interesting solutions in the optimization. And those solutions basically have these emergent properties\nthat are very interesting. - There's wisdom and knowledge in the knobs.\n- [Andrej] Yes. - And so this representation that's in the knobs does it make sense to you intuitively, that a large number of knobs can hold a representation\nthat captures some deep wisdom about the data it has looked at. It's a lot of knobs.\n- It's a lot of knobs. And somehow, so speaking concretely, one of the neural nets\nthat people are very excited about right now are GPTs, which are basically just next-word prediction networks.\nSo you consume a sequence of words from the internet and you try to predict the next word.\nAnd once you train these on a large enough data set,\nyou can basically prompt these neural nets in arbitrary ways and you can ask them to solve problems. And they will.\nSo you can just tell them, you can make it look like you're trying to solve some kind of a mathematical problem.\nAnd they will continue what they think is the solution based on what they've seen on the internet. And very often those solutions\nlook very remarkably consistent. Look correct, potentially even. - Do you still think about the brain side of it?\nSo as neural nets as an abstraction, a mathematical abstraction of the brain, do you still draw wisdom\nfrom the biological neural networks or even the bigger question.\nSo you're a big fan of biology and biological computation. What impressive thing is biology doing to you\n"}
{"pod": "Lex Fridman Podcast", "input": "Biology", "output": "that computers are not yet, that gap? - I would say I'm definitely on,\nI'm much more hesitant with the analogies to the brain than I think you would see potentially in the field.\nAnd I feel like certainly, the way neural networks started is everything stemmed from inspiration by the brain.\nBut at the end of the day, the artifacts that you get after training, they are arrived at by a very different optimization process\nthan the optimization process that gave rise to the brain. And so I think of it as a very complicated alien artifact.\nIt's something different. - [Lex] The brain? - Oh no, sorry. The neural nest that we're training. - [Lex] Okay. - They are a complicated alien artifact.\nI do not make analogies to the brain because I think the optimization process that gave rise to it is very different from the brain.\nSo there was no multi-agent, self-play setup and evolution.\nIt was an optimization that is basically what amounts to a compression objective on a mass amount of data.\n- Okay. So artificial neural networks are doing compression and biological neural networks-\n- [Andrej] Are trying to survive. - Are not really doing anything, they're an agent in a multi-agent, self-play system\nthat's been running for a very, very long time. - Yes. That said, evolution has found that it is very useful\nto predict and have a predictive model in the brain. And so, I think our brain utilizes something\nthat looks like that as a part of it, but it has a lot more catches and gizmos and value functions and ancient nuclei\nthat are all trying to like make it survive and reproduce and everything else. - And the whole thing through embryogenesis is built\nfrom a single-cell. I mean, it's just the code is inside the DNA and it just builds it up like the entire organism\nwith arms- - [Andrej] It's definitely crazy. - And the head and legs. - [Andrej] Yes. - And it does it pretty well.\n- [Andrej] It should not be possible. - So there's some learning going on. There's some kind of computation\ngoing through that building process. I mean, I don't know where, if you were just to look\nat the entirety of history of life on earth, where do you think is the most interesting invention?\nIs it the origin of life itself? Is it just jumping to Eukaryotes?\nIs it mammals? Is it humans themselves, Homo sapiens? The origin of intelligence or highly complex intelligence?\nOr is it all just a continuation of the same kind of process? - Certainly, I would say it's an extremely remarkable story\nthat I'm only briefly learning about recently all the way from, actually, you almost have to start\nat the formation of earth and all of its conditions and the entire solar system and how everything is arranged with Jupiter and moon and the habitable zone and everything.\nAnd then you have an active earth that's turning over material and then you start with a biogenesis and everything.\nAnd so it's all a pretty remarkable story. I'm not sure that I can pick a single unique piece of it\nthat I find most interesting. I guess for me, as an artificial intelligence researcher,\nit's probably the last piece. We have lots of animals that are not building technological society but we do.\nAnd it seems to have happened very quickly. It seems to have happened very recently. And something very interesting happened there\nthat I don't fully understand. I almost understand everything else I think intuitively, but I don't understand exactly that part\nand how quick it was. - Both explanations would be interesting. One is that this is just a continuation\nof the same kind of process. There's nothing special about humans. Deeply understanding that would be very interesting\nthat we think of ourselves as special. But it was obvious, it was already written in the code\nthat you would have greater and greater intelligence emerging. And then the other explanation,\nwhich is something truly special happened, something like a rare event, whether it's like crazy rare event like a \"Space Odyssey\",\nwhat would it be? See if you say like the invention of fire or as Richard Rankin says, the beta males deciding\na clever way to kill the alpha males by collaborating. So just optimizing the collaboration, the multi-agent,\naspect of the multi-agent and that really being constrained on resources and trying to survive the collaboration aspect\nis what created the complex intelligence. But it seems like it's a natural algorithm to the evolution process.\n- [Andrej] Yeah. - What could possibly be a magical thing that happened, like a rare thing that would say that humans are actually,\nhuman-level intelligence is actually a really rare thing in the universe?\n- Yeah, I'm hesitant to say that it is rare by the way, but it definitely seems like it's like a punctuated equilibrium where you have\nlots of exploration and then you have certain leaps, sparse leaps in between. So of course, like origin of life would be one,\nDNA, sex, Eukaryotic life, the endosymbiosis event\nwhere the archon ate little bacteria, just the whole thing. And then of course, emergence of consciousness and so on.\nSo it seems like definitely there are sparse events where massive amount of progress was made. But yeah, it's kind of hard to pick one.\n- So you don't think humans are unique? To that I ask you how many intelligent alien civilizations\n"}
{"pod": "Lex Fridman Podcast", "input": "Aliens", "output": "do you think are out there and is their intelligence different or similar to ours?\n- Yeah, I've been preoccupied with this question quite a bit recently. Basically, the Fermi paradox and just thinking through.\nAnd the reason actually that I am very interested in the origin of life is fundamentally trying to understand\nhow common it is that there are technological societies out there in space.\nAnd the more I study it, the more I think that\nthere should be quite a few, quite a lot. - Why haven't we heard from them? 'Cause I agree with you. It feels like, I just don't see why\nwhat we did here on earth is so difficult to do. - Yeah. And especially when you get into the details of it. I used to think origin of life was very,\nit was this magical rare event. But then you read books like for example Nick Lane,\n\"The Vital Question\", \"Life Ascending\", et cetera. And he really gets in and he really makes you believe\nthat this is not that rare. - Basic chemistry. - You have an active earth and you have your alkaline vents and you have lots of alkaline waters mixing\nwhere there is a devotion and you have your proton gradients and you have these little porous pockets of these alkaline vents that concentrate chemistry.\nAnd basically, as he steps through all of these little pieces, you start to understand that actually this is not that crazy.\nYou could see this happen on other systems and he really takes you from just a geology\nto primitive life. And he makes it feel like this is actually pretty plausible. And also like the origin of life was actually fairly fast\nafter formation of earth, if I remember correctly, just a few hundred million years or something like that after basically when it was possible, life actually arose.\nAnd so that makes me feel like that is not the constraint, that is not the limiting variable and that life should actually be fairly common.\nAnd then where the drop-offs are is very interesting to think about.\nI currently think that there's no major drop-offs basically. - [Lex] Yeah. - And so there should be quite a lot of life. And basically, where that brings me to then\nis the only way to reconcile the fact that we haven't found anyone and so on is that we can't see them, we can't observe them.\n- Just a quick brief comment, Nick Lane and a lot of biologists I talk to, they really seem to think that the jump from bacteria\nto more complex organisms is the hardest jump. - [Andrej] The Eukaryotic life, basically. - Yeah.\nI get it. They're much more knowledgeable than me about the intricacies of biology.\nBut that seems crazy 'cause how many single-cell organisms are there?\nAnd how much time you have surely it's not that difficult. And a billion years is not even that long\nof a time really, just all these bacteria under constrained resources battling it out.\nI'm sure they can invent more complex. I don't understand. It's like how to move from a \"Hello, World!\" program\nto invent a function or something like that. I don't- - Yeah.\n- Yeah, so I'm with you. I just feel like I don't see any, if the origin of life, that would be my intuition, that's the hardest thing.\nBut if that's not the hardest thing 'cause it happened so quickly, then it's gotta be everywhere and yeah, maybe we're just too dumb to see it.\n- Well, it's just we don't have really good mechanisms for seeing this life.\nSo I'm not an expert just to preface this but just from what- - On aliens? I wanna meet an expert on alien intelligence\nand how to communicate. - I'm very suspicious of our ability to find these intelligences out there and to find these earths like radio waves,\nfor example, are terrible. Their power drops off as basically 1 over R-squared. So I remember reading that our current radio waves\nwould not be, the ones that we are broadcasting, would not be measurable by our devices today only like,\nwas it like one 10th of a light year away? Not even, basically, tiny distance because you really need like a targeted transmission\nof massive power directed somewhere for this to be picked up on long distances.\nAnd so I just think that our ability to measure is not amazing. I think there's probably other civilizations out there.\nAnd then the big question is why don't they build one man probes and why don't they interstellar travel across the entire galaxy?\nAnd my current answer is, it's probably interstellar travel is really hard. You have the interstellar medium if you wanna move\nat close to speed of light, you're going to be encountering bullets along the way because even like tiny hydrogen atoms\nand little particles of dust have massive kinetic energy at those speeds.\nAnd so, basically, you need some kind of shielding, you have all the cosmic radiation, it's just brutal out there.\nIt's really hard. And so my thinking is maybe interstellar travel is just extremely hard. You have to learn slow.\n- Like billions of years to build hard? It feels like we're not a billion years away\nfrom doing that. - It just might be that it's very, you have to go very slowly potentially, as an example, through space.\n- Right. As opposed to close to the speed of light. - Yeah. So I'm suspicious basically of our ability to measure life and I'm suspicious of the ability to just permeate\nall of space in the galaxy or across galaxies. And that's the only way that I can currently see away around it.\n- Yeah, it's kind of mind-blowing to think that there's trillions of intelligent alien civilizations out there\nslowly traveling through space. - [Andrej] Maybe. - To meet each other. And some of them meet, some of them go to war,\nsome of them collaborate. - Or they're all just independent. They're all just like little pockets.\nI don't know. - Well, statistically if there's trillions of them,\nsurely some of them, some of the pockets are close enough together. - Some of them happen to be close. Yeah. - And close enough to see each other.\nSee, once you see something that is definitely complex life, if we see something.\n- [Andrej] Yeah. - We're probably going to be intensely aggressively motivated to figure out what the hell that is and try to meet them.\nBut what would be your first instinct, to try to, at a generational-level, meet them or defend against them?\nOr what would be your instinct as a president of the United States and a scientist?\nI don't know which hat you prefer in this question. - Yeah, I think the question, it's really hard.\nI will say like for example, for us, we have lots of primitive life forms on earth next to us.\nWe have all kinds of ants and everything else and we share a space with them and we are hesitant to impact on them and we're trying to protect them\nby default, because they are amazing, interesting dynamical systems that took a long time to evolve. And they are interesting and special\nand I don't know that you wanna destroy that by default.\nAnd so I like complex dynamical systems that took a lot of time to evolve.\nI think I'd like to preserve it if I can afford to.\nAnd I'd like to think that the same would be true about the galactic resources and that they would think\nthat we're kind of incredible interesting story that took time, it took a few billing years to unravel\nand you don't want to just destroy it. - I could see two aliens talking about earth right now and saying I'm a big fan of complex dynamical systems.\nSo I think it was a value to preserve these and who basically are a video game they watch\nor show, a TV show that they watch. - Yeah. I think you would need like a very good reason I think to destroy it.\nWhy don't we destroy these end farms and so on? It's because we're not actually really in direct competition with them right now.\nWe do it accidentally and so on, but there's plenty of resources. And so why would you destroy something\nthat is so interesting and precious? - Well, from a scientific perspective you might probe it. - [Andrej] Yeah.\n- You might interact with it lightly. - Exactly. You might wanna learn something from it. Right. - So I wonder, there could be certain physical phenomena\nthat we think is a physical phenomena, but it's actually interacting with us to poke the finger and see what happens.\n- Yeah. I think it should be very interesting to scientists, other alien scientists, what happened here\nand what we're seeing today is a snapshot, basically, it's a result of a huge amount of computation\nof over billion years or something like that. - It could have been initiated by aliens.\nThis could be a computer running a program. Okay. If you had the power to do this wouldn't you-\nOkay, for sure. At least I would, I would pick an earth-like planet\nthat has the conditions, base my understanding of the chemistry prerequisites for life. And I would seed it with life and run it, right?\n- [Andrej] Yeah. - Wouldn't you 100% do that and observe it and then protect? - [Andrej] Yeah. - I mean that's not just a hell of a good TV show.\nIt's a good scientific experiment. - [Andrej] Yeah. - And it's physical simulation.\nRight. Maybe, evolution is the most, actually running it,\nis the most efficient way to understand computation or to compute stuff.\n- Or to understand life or what life looks like and what branches it can take. - It does make me kind of feel weird\nthat we're part of a science experiment, but maybe everything's a science experiment,\ndoes that change anything for us, if we're a science experiment? - [Andrej] I don't know.\n- Two descendants of apes talking about being inside of a science experiment. - I'm suspicious of this idea of a deliberate panspermia\nas you described it, sort of. - Yes. - I don't see a divine intervention in some way in the historical record right now.\nI do feel like the story in these books, like Nick Lane's books and so on, sort of makes sense and it makes sense how life arose\non earth uniquely. And yeah, I don't need to reach for more exotic explanations right now.\n- Sure. But NPCs inside a video game, don't observe any divine intervention either.\nWe might just be all NPCs running a kind of code. - Maybe eventually they will, currently, NPCs are really dumb.\nBut once they're running GPTs, maybe they will be like, \"Hey, this is really suspicious. What the hell?\"\n"}
{"pod": "Lex Fridman Podcast", "input": "Universe", "output": "- So you famously Tweeted, \"It looks like if you bombard earth with photons\nfor a while, you can emit a Roadster.\" So if like in \"Hitchhiker's Guide to the Galaxy\",\nwe would summarize the story of earth. So in that book it's mostly harmless.\nWhat do you think is all the possible stories, a paragraph long or sentence long\nthat earth could be summarized as, once it's done it's computation?\nSo all the possible full, if earth is a book, right? - Yeah.\n- Probably there has to be an ending. I mean there's going to be an end to earth and it could end in all kinds of ways. It can end soon.\nIt can end later. - [Andrej] Yeah. - What do you think are the possible stories? - Well definitely, there seems to be, yeah, you're sort of,\nit's pretty incredible that these self-replicating systems will basically arise from the dynamics\nand then they perpetuate themselves and become more complex and eventually, become conscious and build a society.\nAnd I feel like in some sense it's a deterministic wave\nthat just happens on any sufficiently well-arranged system like earth.\nAnd so I feel like there's a certain sense of inevitability in it and it's really beautiful.\n- And it ends somehow, right? So it's a chemically diverse environment\nwhere complex dynamical systems can evolve and become more, further, and further complex.\nBut then there's a certain, what is it? There's certain terminating conditions.\n- Yeah. I dunno what the terminating conditions are, but definitely, there's a trend line of something and we're part of that story. And where does that, where does it go?\nSo, we're famously described often as a biological boot loader for AIs and that's because humans,\nI mean, we're an incredible biological system and we're capable of computation and love and so on,\nbut we're extremely inefficient as well. We're talking to each other through audio. It's just embarrassing honestly\nthat we're manipulating like seven symbols, serially, we're using vocal chords.\nIt's all happening over multiple seconds. - [Lex] Yeah. - It's just embarrassing when you step down to the frequencies at which computers operate\nor are able to cooperate on. And so basically, it does seem like synthetic intelligences\nare the next stage of development. And I dunno where it leads to, at some point I suspect\nthe universe is some kind of a puzzle and these synthetic AIs will uncover that puzzle\nand solve it. - And then what happens after, right?\n'Cause if you just like fast forward earth, many billions of years, it's quiet and then it's turmoil,\nyou see city lights and stuff like that. And then what happens at the end? Is it a, or is it a calming, is it explosion?\nIs it like earth open like a giant. 'Cause you said emit Roadsters. Will it start emitting a giant number of satellites?\n- Yeah. Some kind of a crazy explosion. And we're living, we're stepping through a explosion\nand we're living day-to-day and it doesn't look like it. But it's actually, I saw a very cool animation of earth\nand life on earth and, basically, nothing happens for a long time. And then the last like two seconds, basically cities and everything and just,\nand the lower orbit just gets cluttered and just the whole thing happens in the last two seconds and you're like, \"This is exploding. This is a state of explosion.\"\n- Yeah, yeah. If you play it a normal speed. - [Andrej] Yeah. - It'll just look like an explosion. - It's a firecracker.\nWe're living in a firecracker. - Where it's going to start emitting all kinds of interesting things. - [Andrej] Yeah.\n- And then, so explosion doesn't- it might actually look like a little explosion with lights and fire and energy emitted,\nall that kind of stuff. But when you look inside the details of the explosion, there's actual complexity happening where there's like,\nyeah, human life or some kind of life. - We hope it's not a destructive firecracker. It's kind of like a constructive firecracker.\n- [Lex] All right. So given that. - I think- - [Lex] Hilarious discussion. - It is really interesting to think about what the puzzle of the universe is.\nDid the creator of the universe give us a message? For example in the book \"Contact\", Carl Sagan,\nthere's a message for any civilization in the digits\nin the expansion of Pi and base 11, eventually, which is kind of an interesting thought. Maybe we're supposed to be giving a message to our creator,\nmaybe we're supposed to somehow create some kind of a quantum mechanical system that alerts them to our intelligent presence here.\n'Cause if you think about it from their perspective, it's just say like quantum field theory, massive cellular automaton-like thing.\nAnd how do you even notice that we exist? You might not even be able to pick us up in that simulation.\nAnd so how do you prove that you exist, that you're intelligent, and that you're part of the universe?\n- So this is like a touring test for intelligence from earth. - [Andrej] Yeah. - I mean maybe this is like trying to complete\nthe next word in a sentence. This is a complicated way of that. earth is basically sending a message back.\n- Yeah. The puzzle is basically alerting the creator that we exist. - [Lex] Yeah. - Or maybe the puzzle is just to just break out\nof the system and just stick it to the creator in some way. Basically, like if you're playing a video game,\nyou can somehow find an exploit and find a way to execute on the host machine in arbitrary code.\nFor example, I believe someone got a game of Mario to play pong just by exploiting it\nand then basically writing code and being able to execute\narbitrary code in the game. And so maybe we should be, maybe that's the puzzle is that we should find a way to exploit it.\nSo, I think like some of these synthetic AIs will eventually find the universe to be some kind of a puzzle and then solve it in some way.\nAnd that's kind of like the end game somehow. - Do you often think about it as a simulation?\nSo as are the universe being a kind of computation that might have bugs and exploits?\n- Yes. Yeah, I think so. - [Lex] Is that what physics is, essentially? - I think it's possible that physics has exploits\nand we should be trying to find them. Arranging some kind of a crazy quantum mechanical system that somehow gives you buffer overflow\nsomehow gives you a rounding error and the floating point. - Yeah, that's right.\nAnd more and more sophisticated exploits, those are jokes, but that could be actually very close to reality.\n- Yeah. We'll find some way to extract infinite energy. For example, when you train reinforcement learning agents\nin physical simulations and you ask them to say, run quickly on the flat ground, they'll end up doing\nall kinds of weird things in part of that optimization, right? They'll get on their back leg and they'll slide across the floor.\nAnd it's because the optimization, the enforcement learning optimization on that agent has figured out a way to extract infinite energy\nfrom the friction forces and, basically, their poor implementation. And they found a way to generate infinite energy\nand just slide across the surface. And it's not what you expected, it's sort of like a perverse solution.\nAnd so maybe we can find something like that. Maybe we can be that little dog in this physical simulation.\n- That cracks or escapes the intended consequences of the physics that the universe came up with.\n- [Andrej] Yeah. - We'll figure out some kind of shortcut to some weirdness. - [Andrej] Yeah. - And then, oh man, but see the problem with that weirdness\nis the first person to discover the weirdness, like sliding on the back legs, that's all we're gonna do.\n- [Andrej] Yeah. - It's very quickly become everybody does that thing. So the paperclip maximizer is a ridiculous idea,\nbut that very well could be what then we'll just all switch to that 'cause it's so fun.\n- Well, no person will discover it, I think by the way, I think it's going to have to be some kind of a super-intelligent AGI of a third generation.\nWe're building the first-generation AGI, maybe. - Third generation.\nYeah. So the boot loader for an AI, that AI will be a boot loader for another AI.\n- [Andrej] Better Ai. Yeah. - And then there's no way for us to introspect what that might even.\n- I think it's very likely that these things, for example, say you have these AGIs, it's very likely for example, they will be completely inert.\nI like these kinds of sci-fi books sometimes where these things are just completely inert, they don't interact with anything.\nAnd I find that kind of beautiful because they've probably figured out the meta-game\nof the universe in some way, potentially. They're doing something completely beyond our imagination\nand they don't interact with simple chemical life forms. Why would you do that?\nSo I find those kinds of ideas compelling. - What's their source of fun? What are they doing?\nWhat's the source of pleasure? - Well, probably puzzle-solving in the universe? - But inert, so can you define what it means inert?\nSo they escape the interaction with physical reality? - They will appear inert to us, as in\nthey will behave in some very strange way to us because they're beyond, they're playing the meta-game.\nAnd the meta-game is probably say, like arranging quantum mechanical systems in some very weird ways to extract infinite energy,\nsolve the digital expansion of Pi to whatever amount, they will build their own little fusion reactors\nor something crazy. They're doing something beyond comprehension and not understandable to us and actually brilliant under the hood.\n- What if quantum mechanics itself is the system and we're just thinking it's physics\nbut we're really parasites on or not parasite. We're not really hurting physics,\nwe're just living on this organism and we're like trying to understand it.\nBut really it is an organism and with a deep, deep intelligence maybe physics itself is the organism\nthat's doing the super interesting thing and we're just like one little thing. - [Andrej] Yeah. - Ant sitting on top of it trying to get energy from it.\n- Yeah. We're just like these particles in the wave that I feel like is mostly deterministic and takes universe from some kind of a big bang\nto some kind of a super-intelligent replicator, some kind of a stable point in the universe\ngiven these laws of physics. - You don't think, as Einstein said, God doesn't play dice?\nSo you think it's mostly deterministic? There's no randomness in the thing? - I think it's deterministic. Oh, there's tons of, well, I'm gonna be careful\nwith randomness. - [Lex] Pseudo-random? - Yeah, I don't like random. I think maybe the laws of physics are deterministic.\nYeah, I think they're deterministic. - You just got really uncomfortable with the question. Do you have anxiety about whether the universe\nis random or not? Is it a source? - [Andrej] There's no randomness, no.\n- You said you like \"Good Will Hunting\". It's not your fault Andrej. It's not your fault, man.\nSo you don't like the randomness? - Yeah, I think it's unsettling. I think it's a deterministic system.\nI think that things that look random, like say the collapse of the wave function, et cetera, I think they're actually deterministic,\njust entanglement and so on and some kind of a multiverse theory something, something. - Okay.\nSo why does it feel like we have a free will? Like if I raise this hand, I chose to do this now.\nThat doesn't feel like a deterministic thing. It feels like I'm making a choice. - [Andrej] It feels like it.\n- Okay. So it's all feelings. It's just feelings. - [Andrej] Yeah. So when our RL agent is making a choice is that,\nit's not really making a choice, the choice was already there. - Yeah. You're interpreting the choice and you're creating a narrative\nfor having made it. - Yeah. And now we're talking about the narrative, it's very meta. Looking back, what is the most beautiful\n"}
{"pod": "Lex Fridman Podcast", "input": "Transformers", "output": "or surprising idea in deep learning or AI in general that you've come across?\nYou've seen this field explode and grow in interesting ways. Just what cool ideas, like what made you sit back and go\nhmm, big or small? - Well, the one that I've been thinking about recently\nthe most probably is the transformer architecture.\nSo basically, neural networks have a lot of architectures that were trendy have come and gone\nfor different sensory modalities. Like for vision, audio, text, you would process them with different-looking neural nets.\nAnd recently, we've seen this convergence towards one architecture, the transformer and you can feed it video, or you can feed it images,\nor speech or text and it just gobbles it up. And it's a bit of a general-purpose computer\nthat is also trainable and very efficient to run in our hardware. And so this paper came out in 2016, I wanna say.\n- [Lex] \"Attention is all you need\". - \"Attention is all you need\". - You criticized the paper title in retrospect that it wasn't, it didn't foresee the bigness\nof the impact that it was going to have. - Yeah. I'm not sure if the authors were aware of the impact that that paper would go on to have.\nProbably they weren't but I think they were aware of some of the motivations and design decisions behind the transformer and they chose not to, I think,\nexpand on it in that way in the paper. And so I think they had an idea that there was more\nthan just the surface of just like, oh, we're just doing translation and here's a better architecture. You're not just doing translation. This is like a really cool differentiable, optimizable,\nefficient computer that you've proposed. And maybe they didn't have all of that foresight but I think it's really interesting.\n- Isn't it funny, sorry to interrupt, that that title is memeable, that they went\nfor such a profound idea. I don't think anyone used that kind of title before, right?\n- \"Attention is all you need\"? Yeah. It's like a meme or something, basically. - Yeah. Isn't it funny that when, maybe if it was\na more serious title it wouldn't have the impact. - Honestly, yeah, there is an element of me that honestly agrees with you and prefers it this way.\n- [Lex] Yes. - If it was too grand it would over-promise and then under-deliver potentially.\nSo you want to just meme your way to greatness? - That should be a T-shirt.\nSo you Tweeted, \"The Transformer is a magnificent neural network architecture because it is a general-purpose\ndifferentiable computer. It is simultaneously expressive in the forward pass, optimizable via back-propagation gradient dissent,\nand efficient high parallelism compute graph.\" Can you discuss some of those details,\nExpressive, optimizable, efficient? - [Andrej] Yeah. - From memory or in general, whatever comes to your heart.\n- You want to have a general-purpose computer that you can train on arbitrary problems like say the task of next-work prediction\nor detecting if there's a cat in a image or something like that. And you want to train this computer so you want to set its weights.\nAnd I think there's number of design criteria that overlap in the transformer simultaneously\nthat made it very successful. And I think the authors were deliberately trying to\nmake this really powerful architecture. And so basically, it's very powerful in the forward pass\nbecause it's able to express very general computation as something that looks like message passing.\nYou have nodes and they all store vectors and these nodes get to basically look at each other,\neach other's vectors and they get to communicate and basically, nodes get to broadcast,\n\"Hey, I'm looking for certain things.\" And then other nodes get to broadcast, \"Hey, these are the things I have.\" Those are the keys and the values.\n- So it's not just attention. - Yeah, exactly. Transformer is much more than just the attention component. It's got many pieces, architectural that went into it,\nthe residual connection, the way it's arranged, there's a multilayer perceptron and they are the way it's stacked and so on.\nBut basically, there's a message-passing scheme where nodes get to look at each other, decide what's interesting, and then update each other.\nAnd so I think when you get to the details of it, I think it's a very expressive function\nso it can express lots of different types of algorithms in a forward pass. Not only that but the way it's designed with the residual connections, layer normalizations,\nthe Softmax, attention, and everything, it's also optimizable. This is a really big deal because there's lots of computers\nthat are powerful that you can't optimize or that are not easy to optimize using the techniques that we have, which is back-propagation and gradient descent,\nthese are first-order methods, very simple optimizers really. And so you also need it to be optimizable.\nAnd then lastly, you want it to run efficiently in our hardware. Our hardware is a massive throughput machine like GPUs,\nthey prefer lots of parallelism. So you don't want to do lots of sequential operations, you want to do a lot of operations serially\nand the transformer is designed with that in mind as well. And so it's designed for our hardware and is designed to both be very expressive\nin a forward pass, but also very optimizable in the backward pass. - And you said that the residual connection support,\nan ability to learn short algorithms fast and first and then gradually extend them longer during training.\n- [Andrej] Yeah. - What's the idea of learning short algorithms? - Right. Think of it as a, so basically a transformer\nis a series of blocks, right? And these blocks have attention and a little multilayer perceptron,\nand so you go off into a block and you come back to this residual pathway and then you go off and you come back and then you have\na number of layers arranged sequentially. And so the way to look at it I think is because of the residual pathway in the backward pass,\nthe gradients sort of flow along it uninterrupted because addition distributes the gradient equally\nto all of its branches. So the gradient from the supervision at the top just floats directly to the first layer.\nAnd all these residual connections are arranged so that in the beginning, during initialization, they contribute nothing to the residual pathway.\nSo what it looks like is, imagine the transformer is like a Python function, like a def,\nand you get to do various lines of code. Say you have a hundred layers-deep transformer,\ntypically they would be much shorter, say 20. So you have 20 lines of code then you can do something in them. And so think of, during the optimization\nbasically what it looks like is first you optimize the first line of code, and then the second line of code can kick in, and the third line of code can kick in.\nAnd I feel like because of the residual pathway and the dynamics of the optimization, you can sort of learn a very short algorithm\nthat gets the approximate answer, but then the other layers can sort of kick in and start to create a contribution. And at the end of it you're optimizing over an algorithm\nthat is 20 lines of code. Except these lines of code are very complex because it's an entire block of a transformer.\nYou can do a lot in there. Well, what's really interesting is that this transformer architecture actually has been remarkably resilient.\nBasically, the transformer that came out in 2016 is the transformer you would use today except you reshuffle some of the layer norms.\nThe layer normalizations have been reshuffled to a prenorm formulation and so it's been remarkably stable\nbut there's a lot of bells and whistles that people have attached on it and try to improve it. I do think that basically, it's a big step\nin simultaneously optimizing for lots of properties of a desirable neural network architecture. And I think people have been trying to change it\nbut it's proven remarkably resilient. But I do think that there should be even better architectures potentially.\n- But you admire the resilience here? - [Andrej] Yeah. - There's something profound about this architecture\nthat leads to resilience. - [Andrej] Yeah. - So maybe everything can be turned into a problem\nthat transformers can solve. - Currently, definitely looks like the transformers taking over AI and you can feed basically\narbitrary problems into it and it's a general differentiable computer and it's extremely powerful. And this conversions in AI has been really interesting\nto watch for me personally. - What else do you think could be discovered here about transformers?\nLike what surprising thing or is it a stable, out in a stable place?\nIs there something interesting we might discover about transformers? Like aha moments, maybe has to do with memory,\nmaybe knowledge representation, that kind of stuff. - Definitely, the zeitgeist today is just pushing,\nbasically, right now the zeitgeist is do not touch the transformer. - [Lex] Yeah. - Touch everything else. - [Lex] Yes.\n- So people are scaling up the data sets, making them much, much bigger. They're working on the evaluation, making the evaluation much, much bigger. And they're basically keeping the architecture unchanged.\nAnd that's how we've, that's the last five years of progress in AI. - What do you think about one flavor of it,\n"}
{"pod": "Lex Fridman Podcast", "input": "Language models", "output": "which is language models? Have you been surprised, has your imagination\nbeen captivated by, you mentioned GPT and all the bigger, and bigger, and bigger language models\nand what are the limits of those models do you think?\nSo just for the task of natural language. - Basically, the way GPT is trained, right, is you've just download a massive amount of text data\nfrom the internet and you try to predict the next word in a sequence, roughly speaking you're predicting\nlittle word chunks but roughly speaking that's it. And what's been really interesting to watch is\nbasically, it's a language model. Language models have actually existed for a very long time. There's papers on language modeling from 2003, even earlier.\n- Can you explain in that case, what a language model is? - Yeah, so language model, just basically the rough idea\nis just predicting the next word in a sequence, roughly speaking. So there's a paper from, for example, Bengio and the team\nfrom 2003, where for the first time they were using a neural network to take say like three or five words\nand predict the next word. And they're doing this on much smaller data sets and the neural net is not a transformer,\nit's a multilayer perceptron but it's the first time that a neural network has been applied in that setting.\nBut even before neural networks there were language models except they were using n-gram models.\nSo n-gram models are just count-based models. So if you try to take two words and predict a third one,\nyou just count up how many times you've seen any two-word combinations and what came next.\nAnd what you predict as coming next is just what you've seen the most of in the training set. And so language modeling has been around for a long time.\nNeural networks have done language modeling for a long time. So really what's new or interesting or exciting\nis just realizing that when you scale it up with a powerful enough neural net, a transformer,\nyou have all these emergent properties where basically what happens is if you have a large enough data set of text,\nyou are in the task of predicting the next word. You are multitasking a huge amount of different kinds of problems.\nYou are multitasking, understanding of chemistry, physics, human nature, lots of things are clustered\nin that objective. It's a very simple objective but actually, you have to understand a lot about the world to make that prediction. - You just said the U word understanding, are you,\nin terms of chemistry, and physics, and so on, what do you feel like it's doing? Is it searching for the right context in,\nwhat is the actual process happening here? - Yeah, so basically, it gets a thousand words\nand it's trying to predict a thousand and first. And in order to do that very, very well over the entire data set available on the internet,\nyou actually have to basically understand the context of what's going on in there.\n- [Lex] Yeah. - And it's a sufficiently hard problem that if you have a powerful enough computer,\nlike a transformer, you end up with interesting solutions. And you can ask it to do all kinds of things\nand it shows a lot of emergent properties like in-context learning, that was the big deal with GPT\nand the original paper when they published it, is that you can just prompt it in various ways and ask it to do various things\nand it will just kind of complete the sentence. But in the process of just completing the sentence it's actually solving all really interesting problems\nthat we care about. - Do you think it's doing something like understanding, like when we use the word understanding for us humans?\n- I think it's doing some understanding, in its weights it understands I think a lot about the world and it has to in order to predict the next word\nin a sequence. - So it's trained on the data from the internet.\nWhat do you think about this approach in terms of data sets, of using data from the internet?\nDo you think the internet has enough structured data to teach AI about human civilization?\n- Yeah, so I think the internet has a huge amount of data. I'm not sure if it's a complete enough set. I dunno that text is enough for having\na sufficiently powerful AGI as an outcome. - Of course, there is audio, and video, and images,\nand all that kind of stuff. - Yeah. So text by itself I'm a little bit suspicious about, there's a ton of things we don't put in text, in writing\njust because they're obvious to us about how the world works and the physics of it and that things fall. We don't put that stuff in text because why would you,\nwe share that understanding. And so text is a communication medium between humans and it's not a all-encompassing medium of knowledge\nabout the world. But as you pointed out, we do have video, and we have images, and we have audio. And so I think that definitely helps a lot.\nBut we haven't trained models sufficiently across all those modalities yet.\nSo I think that's what a lot of people are interested in. - But I wonder what that shared understanding of what we might call common sense\nhas to be learned, inferred in order to complete the sentence correctly.\nSo maybe the fact that it's implied on the internet the model's gonna have to learn that\nnot by reading about it, by inferring it in the representation. So common sense, just like we,\nI don't think we learn common sense, like nobody says, tells us explicitly, we just figure it all out\nby interacting with the world. - [Andrej] Right. - And so here's a model of reading about the way people interact with the world.\nIt might have to infer that. I wonder. - [Andrej] Yeah. - You briefly worked on a project called World of Bits,\ntraining an RL system to take actions on the internet versus just consuming the internet like we talked about.\n- [Andrej] Yeah. - Do you think there's a future for that kind of system interacting with the internet to help the learning?\n- Yes. I think that's probably the final frontier for a lot of these models, so as you mentioned,\nwhen I was at OpenAI, I was working on this project World of Bits and basically, it was the idea of giving neural networks access to a keyboard and a mouse.\nAnd the idea is that- - What could possibly go wrong? - So basically, you perceive the input of the screen pixels\nand basically, the state of the computer is visualized for human consumption in images of the web browser\nand stuff like that. And then you give the neural network the ability to press keyboards and use the mouse and we're trying to get it to, for example,\ncomplete bookings and interact with user interfaces. And- - What'd you learn from that experience?\nLike what was some fun stuff? 'Cause, that's a super cool idea. - [Andrej] Yeah. - I mean it's like, yeah, I mean\nthe step between observer to actor. - [Andrej] Yeah. - Is a super fascinating step. - Yeah.\nWell, it's the universal interface in the digital realm, I would say. And there's a universal interface in the physical realm,\nwhich in my mind is a humanoid form factor kind of thing. We can later talk about optimist and so on, but I feel like they're a similar philosophy in some way\nwhere the physical world is designed for the human form and the digital world is designed for the human form\nof seeing the screen and using keyboard and mouse. And so it's the universal interface\nthat can basically command the digital infrastructure we've built up for ourselves. And so it feels like a very powerful interface to command\nand to build on top of. Now, to your question as to what I learned from that, it's interesting because the World of Bits\nwas basically too early I think at OpenAI, at the time. This is around 2015 or so.\nAnd the zeitgeist at that time was very different in AI from the zeitgeist today. At the time everyone was super excited\nabout reinforcement learning from scratch. This is the time of the Atari paper where neural networks were playing Atari games\nand beating humans in some cases, AlphaGo, and so on. So everyone's very excited about training neural networks from scratch,\nusing reinforcement learning directly. It turns out that reinforcement learning is extremely inefficient way of training neural networks\nbecause you're taking all these actions and all these observations and you get some sparse rewards once in a while.\nSo you do all this stuff based on all these inputs and once in a while you're told you did a good thing,\nyou did a bad thing and it's just an extremely hard problem, you can't learn from that. You can burn a forest and you can brute force through it.\nAnd we saw that I think with Go and Dota and so on, and it does work, but it's extremely inefficient\nand not how you want to approach problems, practically speaking. And so that's the approach that at the time we also took to World of Bits.\nWe would have an agent initialize randomly, so he would keyboard mash, and mouse mash, and try to make a booking.\nAnd it just revealed the insanity of that approach very quickly, where you have to stumble by the correct booking\nin order to get a reward of you did it correctly. And you're never gonna stumble by it by chance at random.\n- So even with a simple web interface there's too many options. - There's just too many options and it's two spars of a reward signal.\nAnd you're starting from scratch at the time and so you don't know how to read, you don't understand pictures, images, buttons.\nYou don't understand what it means to make a booking. But now what's happened is it is time to revisit that\nand OpenAi is interested in this, companies like Adept are interested in this, and so on.\nAnd the idea is coming back because the interface is very powerful but now you're not training an agent from scratch.\nYou are taking the GPT as an initialization. So GPT is pre-trained on all of text\nand it understands what's a booking, it understands what's a submit, it understands quite a bit more.\nAnd so it already has those representations. They are very powerful and that makes all the training significantly more efficient\nand makes the problem tractable. - Should the interaction be the way humans see it, with the buttons and the language,\nor should it be with the HTML, JavaScript, and the CSS? - [Andrej] Yeah. - What do you think is the better?\n- So today all this interaction is mostly on the level of HTML, CSS, and so on. That's done because of computational constraints.\nBut I think ultimately, everything is designed for human visual consumption and so at the end of the day\nthere's all the additional information is in the layout of the webpage, and what's next to you, and what's a red background, and all this kind of stuff.\nAnd what it looks like visually. So I think that's the final frontier is we are taking in pixels and we're giving out keyboard,\nmouse commands, but I think it's impractical still today. - Do you worry about bots on the internet given these ideas,\n"}
{"pod": "Lex Fridman Podcast", "input": "Bots", "output": "given how exciting they are? Do you worry about bots on Twitter being not the stupid bots that we see now with the crypto bots,\nbut the bots that might be out there actually that we don't see, that they're interacting in interesting ways.\nSo this kind of system feels like it should be able to pass the, I'm not a robot click button, whatever.\nDo you actually understand how that test works? I don't quite, there's a checkbox or whatever\nthat you click. - [Andrej] Yeah. - It's presumably tracking. - [Andrej] Oh, I see. - Like mouse movement and the timing and so on.\n- [Andrej] Yeah. - So exactly this kind of system we're talking about should be able to pass that. So yeah.\nWhat do you feel about bots that are language models\nplus have some interactability and are able to Tweet and reply and so on? Do you worry about that world?\n- Yeah, I think it's always been a bit of an arms race between the attack and the defense,\nso the attack will get stronger but the defense will get stronger as well. Our ability to detect that. - How do you defend, how do you detect,\nhow do you know that your Karpathy account on Twitter is human?\nHow would you approach that, like if people were to claim, how would you defend yourself in the court of law\nthat I'm a human, this account is human? - Yeah, at some point I think it might be,\nI think society will evolve a little bit. We might start signing, digitally signing some of our correspondence or things that we create.\nRight now it's not necessary but maybe in the future, it might be. I do think that we are going towards the world\nwhere we share the digital space with AIs. - [Lex] Synthetic beings.\n- Yeah. And they will get much better and they will share our digital realm and they'll eventually share our physical realm as well.\nIt's much harder but that's kind of like the world we're going towards. And most of them will be benign and helpful\nand some of them will be malicious. And it's going to be an arms race trying to detect them. - So, I mean the worst isn't the AIs,\nthe worst is the AIs pretending to be human. So, I don't know if it's always malicious.\nThere's obviously a lot of malicious applications, but it could also be if I was an AI\nI would try very hard to pretend to be human because we're in a human world. - [Andrej] Yeah.\n- I wouldn't get any respect as an AI. - [Andrej] Yeah. - I wanna get some love and respect. - I don't think the problem is intractable.\nPeople are thinking about the proof of personhood. - [Lex] Yes. - And we might start digitally signing our stuff\nand we might all end up having like, yeah, basically some solution for proof of personhood.\nIt doesn't seem to me intractable, it's just something that we haven't had to do until now. But I think once the need really starts to emerge,\nwhich is soon, I think people will think about it much more. - But that too will be a race because obviously\nyou can probably spoof or fake the proof of personhood.\nSo you have to try to figure out how to- - [Andrej] Probably. - I mean it's weird that we have social security numbers,\nand passports, and stuff. It seems like it's harder to fake stuff\nin the physical space. But in the digital space, it just feels like it's gonna be very tricky.\nVery tricky to out, 'cause it seems to be pretty low cost to fake stuff.\nWhat are you gonna put an AI in jail for trying to use a fake personhood proof?\nI mean, okay, fine, you'll put a lot of AIs in jail, but there'll be more AIs, like exponentially more.\nThe cost of creating a bot is very low unless there's some kind of way to track accurately.\nLike you're not allowed to create any program without tying yourself to that program.\nAny program that runs on the internet, you'll be able to trace every single human programming\nthat was involved with that program. - [Andrej] Right. Yeah. Maybe you have to start declaring when, we have to start drawing those boundaries\nand keeping track of, okay, what are digital entities versus human entities and what is the ownership\nof human entities and digital entities and something like that.\nI don't know but I think I'm optimistic that this is possible and in some sense\nwe're currently in the worst time of it because all these bots suddenly have become very capable\nbut we don't have defenses yet built up as a society but I think that doesn't seem to me intractable, it's just something that we have to deal with.\n- It seems weird that the Twitter bot, like really crappy Twitter bots, are so numerous.\n- [Andrej] Yes. - So I presume that the engineers at Twitter are very good.\nSo it seems like what I would infer from that is it seems like a hard problem.\nThey're probably catching, alright, if I were to sort of steel-man the case, it's a hard problem and there's a huge cost\nto false positive to removing a post by somebody\nthat's not a bot, that creates a very bad user experience. So they're very cautious about removing.\nAnd maybe the bots are really good at learning what gets removed and not such that they can stay ahead\nof the removal process very quickly. - My impression of it honestly, is there's a lot of longing for it.\nI mean. - [Lex] Yeah. - It's not subtle, is my impression of it. It's not subtle.\n- But you have, yeah, that's my impression as well. But it feels like maybe you're seeing\nthe tip of the iceberg, maybe the number of bots is in the trillions and you have to like, just it's a constant assault of bots\nand you, I don't know, you have to steel-man the case. 'Cause the bots I'm seeing are pretty like obvious.\nI could write a few lines of code that catch these bots. - Yeah. I mean definitely, there's a lot of longing for it. But I will say I agree that if you are a sophisticated actor\nyou could probably create a pretty good bot right now using tools like GPTs because it's a language model.\nYou can generate faces that look quite good now and you can do this at scale.\nAnd so I think, yeah, it's quite plausible and it's going to be hard to defend. - There was a Google engineer that claimed\n"}
{"pod": "Lex Fridman Podcast", "input": "Google's LaMDA", "output": "that the LaMDA was sentient. Do you think there's any inkling of truth to what he felt?\nAnd more importantly, to me at least, do you think language models will achieve sentience or the illusion of sentience soonish?\n- Yeah. To me, it's a little bit of a canary in a coal mine moment. Honestly, a little bit because,\nso this engineer spoke to a chatbot at Google and became convinced that this bot is sentient.\n- He asked it some existential philosophical questions. - And it gave reasonable answers and looked real and so on.\nSo to me, it's a, he wasn't sufficiently trying\nto stress the system I think and exposing the truth of it as it is today.\nBut I think this will be increasingly harder over time. So yeah, I think more and more people will basically become,\nyeah, I think there will be more people like that over time as this gets better. - Like form an emotional connection to an AI?\n- Yeah. Perfectly plausible in my mind. I think these AIs are actually quite good at human connection, human emotion.\nA ton of text on the internet is about humans, and connection, and love, and so on.\nSo I think they have a very good understanding in some sense of how people speak to each other about this.\nAnd they're very capable of creating a lot of that kind of text.\nThere's a lot of like sci-fi from fifties and sixties that imagined AIs in a very different way. They are calculating, cold, Vulkan-like machines.\nThat's not what we're getting today. We're getting pretty emotional AIs that actually are very competent and capable\nof generating plausible-sounding text with respect to all these topics. - See I'm really hopeful about AI systems\nthat are companions that help you grow, develop as a human being, help you maximize long-term happiness.\nBut I'm also very worried about AI systems that figure out from the internet that humans get attracted to drama.\nAnd so these would just be like shit-talking AIs that just constantly, did you hear? They'll do gossip, they'll try to plant seeds\nof suspicion to other humans that you love and trust. And just kind of mess with people\n'cause that's going to get a lot of attention. So drama, maximize drama. - [Andrej] Yeah. - On the path to maximizing engagement\nand us humans will feed into that machine. - [Andrej] Yeah. - And it'll be a giant drama shit storm-\nSo I'm worried about that. So as the objective function really defines the way\nthat human civilization progresses with AIs in it. - Yeah. I think right now, at least today, it's not correct to really think of them\nas goal-seeking agents that want to do something. They have no long-term memory or anything,\na good approximation of it is you get a thousand words and you're trying to predict a thousand of them first and then you continue feeding it in\nand you are free to prompt it in whatever way you want. So in text. So you say okay you are a psychologist and you are very good\nand you love humans and here's the conversation between you and another human, human column something, you something,\nand then it just continues the pattern and suddenly you're having a conversation with a fake psychologist who's trying to help you.\nAnd so it's still kind of a the realm of a tool, people can prompt it in arbitrary ways and it can create really incredible text\nbut it doesn't have long-term goals over long periods of time. So it doesn't look that way right now.\n- Yeah. But you can do short-term goals that have long-term effects. - [Andrej] Yeah. - So if my prompting short-term goal\nis to get Andrej Karpathy to respond to me on Twitter when I, I think AI might, that's the goal,\nbut it might figure out that talking shit to you, it would be the best in a highly sophisticated interesting way.\n- [Andrej] Right. - And then you build up a relationship when you respond once and then over time, it gets to not be sophisticated\nand just talk shit, and okay, maybe you won't get to Andrej\nbut it might get to another celebrity, it might get into other big accounts. - [Andrej] Yeah.\n- So with just that simple goal, get them to respond. - [Andrej] Yeah. - Maximize the probability of actual response.\n- Yeah. I mean you could prompt a powerful model like this with its opinion about how to do\nany possible thing you're interested in. - [Lex] Yes. - And they're kind of on track to become these oracles, I could think of it that way.\nThey are oracles currently it's just text but they will have calculators, they will have access to Google search, they will have all kinds of gadgets and gizmos.\nThey will be able to operate the internet and find different information and yeah,\nin some sense that's kinda like currently what it looks like in terms of the development. - Do you think it'll be an improvement eventually\nover what Google is for access to human knowledge?\nIt'll be a more effective search engine to access human knowledge? - I think there's definite scope in building a better search engine today.\nAnd I think Google, they have all the tools, all the people, they have everything they need. They have all the possible pieces, they have people training transformers at scale,\nthey have all the data. It's just not obvious if they are capable as an organization to innovate on their search engine right now\nand if they don't someone else will. There's absolute scope for building a significantly better search engine built on these tools.\n- It's so interesting a large company where the search, there's already an infrastructure, it works,\nads brings out a lot of money. So where structurally inside a company is their motivation to pivot.\n- [Andrej] Yeah. - To say we're going to build a new search engine. - [Andrej] Yep. - That's really hard. - So it's usually going to come from a startup, right?\n- Yeah or some other more competent organization. So I don't know.\nSo currently for example, maybe Bing has another shot at it, as an example. - [Lex] There you go, Microsoft Edge\nas we're talking offline. - It's really interesting because search engines\nused to be about okay here's some query, here's web pages that look like the stuff that you have.\nBut you could just directly go to answer and then have supporting evidence. And these models, basically, they've read all the texts\nand they've read all the web pages. And so sometimes when you see yourself going over to search results and getting a sense of the average answer\nto whatever you're interested in, that just directly comes out, you don't have to do that work.\nSo they're kind of like- Yeah, I think they have a way to of distilling all that knowledge into some level of insight, basically.\n- Do you think of prompting as a teaching and learning, like this whole process?\nLike another layer? 'Cause maybe that's what humans are, you already have that background model\nand then the world is prompting you. - Yeah, exactly. I think the way we are programming these computers now,\nlike GPTs, is converging to how you program humans. I mean, how do I program humans via prompt?\nI go to people and I prompt them to do things, I prompt them for information. And so natural language prompt is how we program humans\nand we're starting to program computers directly in that interface. It's pretty remarkable honestly. - So you've spoken a lot about the idea of Software 2.0.\n"}
{"pod": "Lex Fridman Podcast", "input": "Software 2.0", "output": "All good ideas become cliches so quickly, like the terms, it's kind of hilarious.\nIt's like, I think Eminem once said that if he gets annoyed by a song he's written very quickly,\nthat means it's gonna be a big hit 'cause it's too catchy. But can you describe this idea\nand how you're thinking about it has evolved over the months and years since you coined it?\n- Yeah. Yeah. So I had a blog post on Software 2.0, I think several years ago now.\nAnd the reason I wrote that post is because I saw something remarkable happening\nin software development and how a lot of code was being transitioned to be written\nnot in C++ and so on, but it's written in the weights of a neural net. Basically just saying that neural nets\nare taking over software, the realm of software and taking more and more and more tasks. And at the time, I think not many people understood this\ndeeply enough that this is a big deal. This is a big transition. Neural networks were seen as one of multiple classification algorithms you might use\nfor your dataset problem on Kaggle. This is not that, this is a change in how we program computers.\nAnd I saw neural nets as this is going to take over, the way we program computers is going to change,\nit's not going to be people writing software in C++ or something like that and directly programming the software.\nIt's going to be accumulating training sets and data sets and crafting these objectives by which we train these neural nets.\nAnd at some point, there's going to be a compilation process from the dataset and the objective and the architecture specification into the binary,\nwhich is really just the neural net weights and the forward pass of the neural net\nand then you can deploy that binary. And so I was talking about that transition and that's what the post is about.\nAnd I saw this play out in a lot of fields, autopilot being one of them,\nbut also just a simple image classification. People thought originally, in the eighties and so on,\nthat they would write the algorithm for detecting a dog in an image and they had all these ideas about how the brain does it and first, we detected corners\nand then we detect lines and then we stitched them up and they were really going at it. They were thinking about how they're gonna write the algorithm\nand this is not the way you build it. And there was a smooth transition where, okay,\nfirst we thought we were gonna build everything, then we were building the features, so HOG features and things like that\nthat detect these little statistical patterns from image patches. And then there was a little bit of learning on top of it,\na support vector machine or binary classifier for cat versus dog and images on top of the features.\nSo we wrote the features but we trained the last layer, as the classifier.\nAnd then people are like, actually, let's not even design the features because we can't, honestly, we're not very good at it. So let's also learn the features.\nAnd then you end up with basically a compilation neural net where you're learning most of it. You're just specifying the architecture.\nAnd the architecture has tons of filled-in blanks, which is all the knobs and you let the optimization\nwrite most of it. And so this transition is happening across the industry everywhere. And suddenly we end up with a ton of code\nthat is written in neural net weights. And I was just pointing out that the analogy is actually pretty strong and we have a lot of developer environments\nfor Software 1.0. We have IDEs, how you work with code, how you debug code, how do you run code,\nhow do you maintain code? We have GitHub. So I was trying to make those analogies in the new realm, what is the GitHub of Software 2.0?\nTurns out it's something that looks like Hugging Face right now? And so I think some people took it seriously\nand built cool companies and many people originally attacked the post. It actually was not well received when I wrote it\nand I think maybe it has something to do with the title, but the post was not well received and I think more people have been coming around to it over time.\n- Yeah. So you were the Director of AI at Tesla where I think this idea was really implemented at scale,\nwhich is how you have engineering teams doing Software 2.0. So can you linger on that idea of,\nI think we're in the really early stages of everything you just said, which is like GitHub, IDEs,\nhow do we build engineering teams that work in Software 2.0 systems and the data collection\nand the data annotation, which is all part of that Software 2.0.\nWhat do you think is the task of programming Software 2.0? Is it debugging in the space of hyper-parameters\nor is it also debugging the space of data? - Yeah, the way by which you program the computer\nand influence its algorithm is not by writing the commands yourself.\nYou're changing mostly the data set. You're changing the loss functions\nof what the neural net is trying to do, how it's trying to predict things. But basically the data sets and the architectures of the neural net.\nAnd so in the case of the autopilot, a lot of the data sets have to do with, for example,\ndetection of objects and lane line markings and traffic lights and so on. So you accumulate massive data sets of, here's an example, here's the desired label\nand then here's roughly what the algorithm should look like. And that's a compilation neural net.\nSo the specification of the architecture is like a hint as to what the algorithm should roughly look like. And then the fill in the blanks process of optimization\nis the training process. And then you take your neural net that was trained, it gives all the right answers on your data set\nand you deploy it. - So in that case, perhaps at all machine learning cases,\nthere's a lot of tasks. So is coming up formulating a task\nfor a multi-headed neural network, is formulating a task part of the programming? - [Andrej] Yeah, pretty much so.\n- How you break down a problem into a set of tasks. - Yeah. On a high-level, I would say\nif you look at the software running in the autopilot, I give a number of talks on this topic.\nI would say originally a lot of it was written in Software 1.0, imagine lots of C++, right?\nAnd then gradually, there was a tiny neural net that was, for example, predicting given a single image,\nis there a traffic light or not? Or is there a lane line marking or not? And this neural net didn't have too much to do\nin the scope of the software, it was making tiny predictions on an individual little image and then the rest of the system stitched it up.\nSo okay, we don't have just a single camera, we have eight cameras, we actually have eight cameras over time.\nAnd so what do you do with these predictions? How do you put them together? How do you do the fusion of all that information and how do you act on it?\nAll of that was written by humans in C++. And then we decided, okay, we don't actually want\nto do all of that fusion in the C++ code because we're actually not good enough to write that algorithm. We want the neural nets to write the algorithm\nand we want to port all of that software into the 2.0 stack. And so then we actually had neural nets\nthat now take all the eight camera images simultaneously and make predictions for all of that.\nSo, and actually, they don't make predictions in the space of images.\nThey now make predictions directly in 3D and, actually, in three dimensions around the car.\nAnd now, actually, we don't manually fuse the predictions in 3D over time we don't trust ourselves\nto write that tracker. So actually, we give the neural net the information over time. So it takes these videos now and makes those predictions.\nAnd so you're just like putting more and more power into the neural net processing and at the end of it, the eventual goal is to have most of the software\npotentially be in the 2.0 end because it works significantly better.\nHumans are just not very good at writing software, basically. - So the prediction is happening in this 4D land.\n- [Andrej] Yeah. - Was three-dimensional world over time. - [Andrej] Yeah. - How do you do annotation in that world?\nSo data annotation, whether it's self-supervised or manual by humans is a big part\nof this Software 2.0 world. - I would say by far in the industry, if you're talking about the industry\nand what is the technology of what we have available? Everything is supervised learning. So you need data sets of input, desired output\nand you need lots of it. And there are three properties of it that you need. You need it to be very large,\nyou need it to be accurate, no mistakes and you need it to be diverse. You don't want to just have a lot\nof correct examples of one thing. You need to really cover the space of possibility as much as you can. And the more you can cover the space of possible inputs,\nthe better the algorithm will work at the end. Now once you have really good data sets that you're collecting, curating and cleaning,\nyou can train your neural net on top of that. So a lot of the work goes into cleaning those data sets.\nNow, as you pointed out, the question is how do you achieve a ton of-\nIf you want to basically predict in 3D, you need data in 3D to back that up. So in this video, we have eight videos\ncoming from all the cameras of the system and this is what they saw and this is the truth of what actually was around, there was this car\nand there was this car, this car, these are the lane line markings, this is the geometry of the road. There's a traffic light in this three-dimensional position,\nyou need the ground truth. And so the big question that team was solving, of course, is how do you arrive at that ground truth?\nBecause once you have a million of it and it's large, clean and diverse, then training a neural net on it works extremely well\nand you can ship that into the car. And so there's many mechanisms by which we collected that training data.\nYou can always go for human annotation, you can go for simulation as a source of ground truth, you can also go for what we call the offline tracker\nthat we've spoken about at the AI Day and so on, which is basically an automatic reconstruction process\nfor taking those videos and recovering the three-dimensional reality of what was around that car.\nSo basically, think of doing a three-dimensional reconstruction as an offline thing and then understanding that okay,\nthere's 10 seconds of video, this is what we saw and therefore here's all the lane lines, cars and so on.\nAnd then once you have that annotation, you can train neural nets to imitate it. - And how difficult is the 3D reconstruction?\n- [Andrej] It's difficult but it can be done. - So there's overlap between the cameras and you do the reconstruction\nand perhaps if there's any inaccuracy so that's caught in the annotation step. - Yes.\nThe nice thing about the annotation is that it is fully offline. You have infinite time, you have a chunk of one minute\nand you're trying to just offline in a super-computer somewhere. Figure out where were all the positions of all the cars,\nof all the people, and you have your full one minute of video from all the angles and you can run all the neural nets you want and they can be very efficient, massive neural nets,\nthey can be neural net that can't even run in the car later at test time. So they can be even more powerful neural nets than what you can eventually deploy.\nSo you can do anything you want, three-dimensional reconstruction, neural nets, anything you want just to recover that truth\nand then you supervise that truth. - What have you learned? You said no mistakes about humans doing annotation\n"}
{"pod": "Lex Fridman Podcast", "input": "Human annotation", "output": "'cause there's like a range of things they're good at\nin terms of clicking stuff on screen. How interesting is that to you of a problem of designing\nan annotator where humans are accurate, enjoy it, what are they even the metrics, are efficient,\nare productive, all that kind of stuff? - Yeah, so I grew the annotation team at Tesla from, basically, zero to a thousand while I was there.\nThat was really interesting. My background is a PhD student researcher. So growing that kind of organization was pretty crazy.\nBut yeah, I think it's extremely interesting and part of the design process very much behind the autopilot as to where you use humans.\nHumans are very good at certain kinds of annotations. They're very good, for example, at two-dimensional annotations of images. They're not good at annotating cars over time\nin three-dimensional space. Very, very hard. And so that's why we're very careful to design the tasks that are easy to do for humans\nversus things that should be left to the offline tracker. Maybe the computer will do all the triangulation and 3D construction but the human will say\nexactly these pixels of the image are car. Exactly these pixels are human. And so co-designing the data annotation pipeline\nwas very much bread and butter what I was doing daily. - Do you think there's still a lot of open problems\nin that space? Just in general annotation where the stuff the machines are good at, machines do\nand the humans do what they're good at and there's maybe some iterative process? - Right.\nI think to a very large extent, we went through a number of iterations and we learned a ton about how to create these data sets.\nI'm not seeing big open problems. Originally, when I joined I was really not sure\nhow this would turn out. - [Lex] Yeah. - But by the time I left I was much more secure and actually, we understand the philosophy\nof how to create these data sets and I was pretty comfortable with where that was at the time. - So what are strengths and limitations of cameras\n"}
{"pod": "Lex Fridman Podcast", "input": "Camera vision", "output": "for the driving task in your understanding when you formulate the driving task as a vision task\nwith eight cameras, you've seen that the entire, most of the history of the computer vision field\nwhen it has to do with neural networks. Just if you step back, what are the strengths and limitations of pixels, of using pixels to drive?\n- Yeah, pixels I think are a beautiful sensory, beautiful sensor I would say. The thing is like cameras are very, very cheap\nand they provide a ton of information, ton of bits. So it's a extremely cheap sensor for a ton of bits.\nAnd each one of these bits is a constraint on the state of the world. And so you get lots of megapixel images, very cheap\nand it just gives you all these constraints for understanding what's actually out there in the world. So vision is probably the highest bandwidth sensor.\nIt's a very high bandwidth sensor. - I love that pixels is a constraint on the world.\nIt's this highly complex, high bandwidth constraint\non the stage of the world. That's fascinating. - It's not just that, but again this real importance of it's the sensor that humans use,\ntherefore everything is designed for that sensor. - [Lex] Yeah. - The text, the writing, the flashing signs,\neverything is designed for vision and so, and you just find it everywhere. And so that's why that is the interface you want to be in\ntalking again about these universal interfaces and that's where we actually want to measure the world as well and then develop software for that sensor.\n- But there's other constraints on the state of the world that humans use to understand the world.\nI mean vision ultimately is the main one. But we're referencing our understanding of human behavior\nand some common-sense physics that could be inferred from vision, from a perception perspective.\nBut it feels like we're using some kind of reasoning to predict the world.\n- [Andrej] Yeah, hundred percent. - Not just the pixels. - I mean you have a powerful prior service for how the world evolves over time, et cetera.\nSo it's not just about the likelihood term coming up from the data itself telling you about what you are observing,\nbut also the prior term of what are the likely things to see and how do they likely move and so on.\n- And the question is how complex is the range of possibilities that might happen\nin the driving task. - [Andrej] Right. - Is that to you still an open problem of how difficult is driving, philosophically speaking?\nOf al the time you worked on driving, do you understand how hard driving is? - Yeah, driving is really hard\nbecause it has to do with the predictions of all these other agents and the theory of mind and what they're gonna do. And are they looking at you?\nWhere are they looking? What are they thinking? - [Lex] Yeah. - There's a lot that goes there at the full tail-off,\nthe expansion of the nines that we have to be comfortable with eventually the final problems are of that form. I don't think those are the problems that are very common.\nI think eventually they're important but it's really in the tail end. - In the tail end, the rare edge cases.\n- [Andrej] Yes. - From the vision perspective, what are the toughest parts of the vision problem of driving?\n- Well, basically, the sensor is extremely powerful but you still need to process that information.\nAnd so going from brightnesses of these pixel values to, hey, here are the three-dimensional world,\nis extremely hard and that's what the neural networks are fundamentally doing. And so the difficulty really is in just\ndoing an extremely good job of engineering the entire pipeline, the entire data engine,\nhaving the capacity to train these neural nets, having the ability to evaluate the system and iterate on it.\nSo I would say just doing this in production at scale is the hard part, it's an execution problem. - So the data engine but also the deployment of the system\nsuch that has low latency performance. So it has to do all these steps. - Yeah. For the neural nets specifically just making sure\neverything fits into the chip on the car. - [Lex] Yeah. - And you have a finite budget of flops that you can perform and memory bandwidth\nand other constraints and you have to make sure it flies and you can squeeze in as much computer as you can into the tiny.\n- What have you learned from that process? Because maybe that's one of the bigger, new things,\ncoming from a research background, where there's a system that has to run under heavily constrained resources.\nHas to run really fast. What insights have you learned from that?\n- Yeah, I'm not sure if there's too many insights, you're trying to create a neural net that will fit in what you have available\nand you're always trying to optimize it. And we talked a lot about it on the AI Day and, basically, the triple backflips\nthat the team is doing to make sure it all fits and utilizes the engine. So I think it's extremely good engineering\nand then there's all kinds of little insights peppered in on how to do it properly. - Let's actually zoom out\n"}
{"pod": "Lex Fridman Podcast", "input": "Tesla's Data Engine", "output": "'cause I don't think we talked about the data engine, the entirety of the layouts of this idea\nthat I think is just beautiful with humans in the loop. Can you describe the data engine?\n- Yeah, the data engine is what I call the almost biological feeling process\nby which you perfect the training sets for these neural networks.\nSo because most of the programming now is in the level of these data sets and make sure they're large, diverse and clean, basically you have a data set\nthat you think is good, you train your neural net, you deploy it, and then you observe how well it's performing\nand you're trying to always increase the quality of your data set. So you're trying to catch scenarios,\nbasically, that are, basically, rare. And it is in these scenarios that neural nets will typically struggle in\nbecause they weren't told what to do in those rare cases in the data set. But now you can close the loop because if you can now collect all those at scale,\nyou can then feed them back into the reconstruction process I described and reconstruct the truth in those cases\nand add it to the dataset. And so the whole thing ends up being a staircase of improvement of perfecting your training set\nand you have to go through deployments so that you can mine the parts that are not yet represented well on the dataset.\nSo your dataset is basically imperfect. It needs to be diverse, it has pockets that are missing and you need to pat out the pockets.\nYou can sort of think of it that way in the data. - What role do humans play in this? So what's this biological system like a human body\nmade up of cells? What role? How do you optimize the human system?\nThe multiple engineers collaborating, figuring out what to focus on, what to contribute,\nwhich task to optimize in this neural network. Who's in charge of figuring out which task needs more data?\nCan you speak to the hyperparameters, the human system? - It really just comes down to extremely good execution\nfrom an engineering team that knows what they're doing. They understand intuitively the philosophical insights underlying the data engine and the process\nby which the system improves and how to, again, delegate the strategy of the data collection\nand how that works. And then just making sure it's all extremely well executed. And that's where most of the work, it's not even the philosophizing or the research\nor the ideas of it. It's just extremely good execution is so hard when you're dealing with data at that scale. - So your role in the data engine executing well\nand it is difficult and extremely important. Is there a priority of a vision board of saying like,\nwe really need to get better at stoplights? - [Andrej] Yeah. - The prioritization of tasks?\n- [Andrej] Yes. - Is that essentially, and that comes from the data? - That comes to, a very large extent\nto what we are trying to achieve in the product roadmap. The release we're trying to get out and the feedback\nfrom the QA team where the system is struggling or not, the things we're trying to improve. - And the QA team gives some signal, some information\nin aggregate about the performance of the system in various conditions. - That's right. And then of course all of us drive it\nand we can also see it. It's really nice to work with a system that you can also experience yourself. It drives you home.\n- Is there some insight you can draw from your individual experience that you just can't quite get from an aggregate statistical analysis of data?\n- I would say so, yeah. - [Lex] It's so weird, right? - Yes. - It's not scientific in a sense\n'cause you're just one anecdotal sample. - Yeah, I think there's a ton of, it's a source of truth.\nIt's your interaction with the system. - [Lex] Yeah. - And you can see it, you can play with it, you can perturb it, you can get a sense of it,\nyou have an intuition for it. I think numbers and plots and graphs are much harder.\nIt hides a lot of- - It's like if you train a language model,\nit's a really powerful way is by you interacting with it. - [Andrej] Yeah, a hundred percent. - Start try to build up an intuition.\n- Yeah, I think Elon also, he always wanted to drive the system himself. He drives a lot and I don't wanna say almost daily.\nSo he also sees this as a source of truth, you driving the system and it performing and yeah.\n"}
{"pod": "Lex Fridman Podcast", "input": "Tesla Vision", "output": "- So what do you think? Tough questions here. So, Tesla, last year removed radar from the sensor suite\nand now just announce that it's gonna remove all ultrasonic sensors relying solely on vision,\nso camera only, does that make the perception problem harder or easier?\n- I would almost reframe the question in some way. So the thing is basically, you would think that additional sensors.\n- Wait, wait, wait, can I just interrupt? - [Andrej] Go ahead. - I wonder if a language model will ever do that if you prompt it.\nLet me reframe your question. That would be epic. That's the wrong prompt. Sorry.\n- Yeah, so it's a little bit of a wrong question because, basically, you would think that these sensors are an asset to you.\n- [Lex] Yeah. - But if you fully consider the entire product in its entirety, these sensors\nare actually potentially a liability because these sensors aren't free. They don't just appear on your car.\nSuddenly you have an entire supply chain, you have people procuring it, there can be problems with them, they may need replacement.\nThey are part of the manufacturing process. They can hold back the line in the production. You need to source them, you need to maintain them,\nyou have to have teams that ride the firmware, all of it. And then you also have to incorporate them,\ninfuse them into the system in some way. And so it actually bloats a lot of it. And I think Elon is really good at simplify, simplify,\nbest part is no part. And he always tries to throw away things that are not essential because he understands the entropy\nin organizations and an approach. And I think in this case the cost is high and you're not potentially seeing it\nif you're just a computer vision engineer and I'm just trying to improve my network and is it more useful or less useful?\nHow useful is it? And the thing is, if once you consider the full cost of a sensor, it actually is potentially a liability\nand you need to be really sure that it's giving you extremely useful information. In this case, we looked at using it or not using it\nand the delta was not massive. And so it's not useful. - Is it also bloat in the data engine,\nlike having more sensors? - Hundred percent. - Is it a distraction? - And these sensors, they can change over time.\nFor example, you can have one type of say radar, you can have other type of radar. They change over time. Now suddenly you need to worry about it.\nNow suddenly you have a column in your sequel light telling you, oh, what sensor type was it? And they all have different distributions\nand then they contribute noise and entropy into everything\nand they bloat stuff. And also organizationally, it's been really fascinating to me that it can be very distracting.\nIf all you wanna get to work is vision, all the resources are on it and you're building out a data engine\nand you're actually making forward progress because that is the sensor with the most bandwidth, the most constraints on the world.\nAnd you're investing fully into that. And you can make that extremely good. You have only a finite amount of sort of spend of focus\nacross different facets of the system. - And this reminds me of Rich Sutton, \"The Bitter Lesson\"\nthat just seems like simplifying the system. - [Andrej] Yeah. - In the long run. And of course, you don't know what the long run is\nand it seems to be always the right solution. - Yeah. Yes. - In that case, it was for RL but it seems to apply generally\nacross all systems that do computation. - [Andrej] Yeah. - So what do you think about the LiDAR as a crutch debate?\nThe battle between point clouds and pixels? - Yeah, I think this debate is always slightly confusing\nto me because it seems like the actual debate should be about do you have the fleet or not. That's the really important thing\nabout whether you can achieve a really good functioning of an AI system at this scale. - [Lex] So data collection systems.\n- Yeah. Do you have a fleet or not is significantly more important whether you have LiDAR or not. It's just another sensor.\nAnd yeah, I think similar to the radar discussion, basically, yeah, I don't think it,\nit basically doesn't offer extra information. It's extremely costly.\nIt has all kinds of problems. You have to worry about it, you have to calibrate it, et cetera. It creates bloat and entropy. You have to be really sure that you need this sensor.\nIn this case, I basically don't think you need it. And I think honestly, I will make a stronger statement. I think some of the other companies who are using it\nare probably going to drop it. - Yeah. So you have to consider the sensor in the full,\nin considering can you build a big fleet that collects a lot of data and can you integrate that sensor with that data,\nand that sensor into a data engine that's able to quickly find different parts of the data\nthat then continuously improves whatever the model that you're using. - Yeah. Another way to look at it is like, vision is necessary\nin a sense that the world is designed for human visual consumption. So you need vision, it's necessary.\nAnd then also it is sufficient because it has all the information that you need for driving.\nAnd humans obviously use vision to drive. So it's both necessary and sufficient. So you want to focus resources and you have to be really sure\nif you're going to bring in other sensors. You could add sensors to infinity, at some point you need to draw the line.\nAnd I think in this case, you have to really consider the full cost of any one sensor that you're adopting,\nand do you really need it? And I think the answer, in this case, is no. - So what do you think about the idea\nthat the other companies are forming high-resolution maps and constraining heavily the geographic regions\nin which they operate? Is that approach, in your view, not going to scale over time\nto the entirety of the United States? - [Andrej] Yeah. I think- - It'll take too long- - As you've mentioned like they pre-map all the environments\nand they need to refresh the map and they have a perfect centimeter-level-accuracy map of everywhere they're gonna drive.\nIt's crazy. How are you going to, when we're talking about autonomy actually changing the world, we're talking about\nthe deployment on the global scale of autonomous systems for transportation.\nAnd if you need to maintain a centimeter-accurate map for earth or for many cities and keep them updated,\nit's a huge dependency that you're taking on, a huge dependency. It's a massive, massive dependency\nand now you need to ask yourself, do you really need it? And humans don't need it, right?\nSo it's very useful to have a low-level map of like, okay, the connectivity of your road, you know that there's a fork coming up.\nWhen you drive in an environment, you have that high-level understanding. It's like a small Google map and Tesla uses Google map,\nsimilar resolution information in its system, but it will not pre-map environments\nto centimeter-level accuracy. It's a crutch, it's a distraction, it causes entropy, and it diffuses the team,\nit dilutes the team and you're not focusing on what's actually necessary, which is a computer vision problem.\n"}
{"pod": "Lex Fridman Podcast", "input": "Elon Musk", "output": "- What did you learn about machine learning, about engineering, about life, about yourself\nas one human being from working with Elon Musk? - I think the most I've learned is about\nhow to run organizations efficiently and how to create efficient organizations\nand how to fight entropy in an organization. - So human engineering in the fight against entropy.\n- Yeah, I think Elon is a very efficient warrior in the fight against entropy in organizations.\n- What does entropy in an organization look like exactly? - It's process. It's process and it's-\n- Inefficiencies in the form meetings and that kind of stuff? - Yeah. Meetings, he hates meetings, he keeps telling people\nto skip meetings if they're not useful. He basically runs the world's biggest startups,\nI would say, Tesla, SpaceX are the world's biggest startups. Tesla actually is multiple startups,\nI think it's better to look at it that way. And so I think he's extremely good at that.\nAnd yeah, he is a very good intuition for streamlining process. He's making everything efficient. Best part is no part, simplifying,\nfocusing, and just kind of removing barriers, moving very quickly, making big moves.\nAll this is very startupy sort of seeming things but at scale. - So strong drive to simplify.\n- [Andrej] Yeah. - From your perspective, I mean, that also probably applies to just designing systems\nand machine learning, and otherwise. - Yeah. - [Lex] like simplify, simplify. - Yes. - What do you think is the secret to maintaining\nthe startup culture in a company that grows? Is there, can you introspect that?\n- I do think he needs someone in a powerful position with a big hammer like Elon who's the cheerleader\nfor that idea, and ruthlessly pursues it. If no one has a big enough hammer,\neverything turns into committees, democracy within the company, process,\ntalking to stakeholders, decision-making, Just everything just crumbles. - [Lex] Yeah. - If you have a big person who is also really smart\nand has a big hammer, things move quickly. - So you said your favorite scene in \"Interstellar\"\nis the intense docking scene with the AI and Cooper talking, saying, \"Cooper, what are you doing?\nDocking. It's not possible. No, it's necessary.\" Such a good line, by the way, just so many questions there.\nWhy an AI in that scene presumably\nis supposed to be able to compute a lot more than the human is saying it's not optimal, why are the human,\nI mean that's a movie, but shouldn't the AI know much better than the human?\nAnyway, what do you think is the value of setting seemingly impossible goals?\nSo like our initial intuition, which seems like something that you have taken on\nthat Elon espouses that where the initial intuition of the community might say this is very difficult\nand then you take it on anyway, with a crazy deadline. You, just from a human engineering perspective,\nhave you seen the value of that? - I wouldn't say that setting impossible goals exactly\nis a good idea but I think setting very ambitious goals is a good idea. I think there's a, what I call sublinear scaling\nof difficulty, which means that 10x problems are not 10x hard. Usually, 10x harder problem is like two or three x\nharder to execute on. Because if you wanna actually, like if you wanna improve a system by 10%, it costs some amount of work.\nAnd if you wanna 10x improve the system, it doesn't cost you know, a 100x amount of the work. And it's because you fundamentally change the approach.\nAnd if you start with that constraint, then some approaches are obviously dumb and not going to work and it forces you to reevaluate.\nAnd I think it's a very interesting way of approaching problem-solving. - But it requires a weird kind of thinking.\nIt's just going back to your PhD days. It's like how do you think which ideas\nin the machine learning community are solvable? - [Andrej] Yes.\n- It requires, what is that? I mean there's the cliche of first principles thinking but it requires to basically ignore\nwhat the community is saying. 'Cause doesn't a community, doesn't a community in science\nusually draw lines of what is and isn't possible? - [Andrej] Right. - And it's very hard to break out of that\nwithout going crazy. - Yeah. I mean I think a good example here is the deep learning revolution in some sense\nbecause you could be in computer vision at that time, during the deep learning revolution of 2012 and so on.\nYou could be improving a computer vision stack by 10% or it can just be saying actually all this is useless\nand how do I do 10x better computer vision? Well, it's not probably by tuning a HOG feature detector,\nI need a different approach. I need something that is scalable. Going back to Richard Suttons\nand understanding the philosophy of the Bitter Lesson and then being like actually, I need a much more scalable system,\nlike a neural network that in principle works. And then having some deep believers that can actually\nexecute on that mission, make it work. So that's the 10x solution.\n"}
{"pod": "Lex Fridman Podcast", "input": "Autonomous driving", "output": "- What do you think is the timeline to solve the problem of autonomous driving? That's still in part an open question.\n- Yeah, I think the tough thing with timelines of self-driving obviously, is that no one has created self-driving.\n- [Lex] Yeah. - So it's not like, what do you think is a timeline to build this bridge? Well, we've built a million bridges before,\nhere's how long that takes. No one has built autonomy, it's not obvious.\nSome parts turn out to be much easier than others. So it's really hard to forecast. You do your best based on trend lines and so on\nand based on intuition. But that's why fundamentally it's just really hard to forecast this. No one has- - So even still like being inside of it,\nit's hard to- - Yes. Some things turn out to be much harder and some things turned out to be much easier.\n- Do you try to avoid making forecasts? 'Cause Elon doesn't avoid them, right?\nAnd heads of car companies in the past have not avoided it either. Ford and other places have made predictions\nthat we're gonna solve level-four driving by 2020, 2021, whatever.\nAnd they all backtrack on that prediction. As an AI person, do you feel yourself privately\nmake predictions or do they get in the way of your actual ability to think about a thing?\n- Yeah, I would say what's easy to say is that this problem is tractable and that's an easy prediction to make.\nIt's tractable- - So it's solvable? - It's going to work. Yes. It's just really hard. Some things turned out to be harder and somethings turn out to be easier.\nBut it definitely feels tractable and it feels like, at least the team at Tesla, which is what I saw internally,\nis definitely on track to that. - How do you form a strong representation\nthat allows you to make a prediction about tractability? So you're the leader a lot of humans,\nyou have to say this is actually possible. - Yeah.\n- How do you build up that intuition? It doesn't have to be even driving, it could be other tasks. - [Andrej] Right. - It could be, what difficult tasks did you work on\nin your life? I mean classification, achieving certain, just an image at certain level\nof superhuman-level performance. - Yeah, expert intuition. It's just intuition, it's belief.\n- So just like thinking about it long enough, like studying, looking at sample data, like you said, driving.\nMy intuition is really flawed on this. I don't have a good intuition about tractability. It could be anything.\nIt could be solvable. The driving task could be simplified\ninto something quite trivial. Like the solution to the problem would be quite trivial.\nAnd at scale, more and more cars driving perfectly might make the problem much easier.\nThe more cars you have driving, like people learn how to drive correctly, not correctly, but in a way that's more optimal for heterogeneous system\nof autonomous, and semi-autonomous, and manually driven cars, that could change stuff. Then again, also I've spent a ridiculous number of hours\njust staring at pedestrians crossing streets, thinking about humans. And it feels like the way we use our eye contact,\nit sends really strong signals and there's certain quirks and edge cases of behavior.\nAnd of course, a lot of the fatalities that happen have to do with drunk driving,\nboth on the pedestrian side and the driver's side. So there's that problem of driving at night and all that kind of.\n- [Andrej] Yeah. - So I wonder, it's like the space of possible solution into autonomous driving includes so many human factor issues\nthat it's almost impossible to predict. There could be super clean, nice solutions.\n- Yeah. I would say definitely, to use a game analogy, there's some fog of war, but you definitely also see\nthe frontier of improvement and you can measure historically how much you've made progress. And I think for example, at least what I've seen\nin roughly five years at Tesla. When I joined it barely kept lane on the highway.\nI think going up from Palo Alto to SF was like three or four interventions. Anytime the road would do anything geometrically\nor turn too much it would just not work. And so going from that to like a pretty competent system in five years and seeing what happens also under the hood\nand what the scale which the team is operating now with respect to data, and compute, and everything else\nis just massive progress. - So you're climbing a mountain and it's fog\nbut you're making a lot of progress. - It's Fog. You're making progress and you see what the next directions are and you're looking at some of the remaining challenges\nand they're not perturbing you, and they're not changing your philosophy, and you're not contorting yourself.\nYou're like, actually, these are the things that we still need to do. - Yeah, it's the fundamental components of solving the problem seem to be there,\nfrom the data engine, to the compute, to the compute on the car, to the compute for the training, all that kind of stuff.\n- [Andrej] Yes. - Over the years you've been at Tesla, you've done a lot of amazing breakthrough ideas\n"}
{"pod": "Lex Fridman Podcast", "input": "Leaving Tesla", "output": "and engineering all of it from the data engine to the human side, all of it.\nCan you speak to why you chose to leave Tesla? - Basically, as I described, I think over time\nduring those five years I've kind of gotten myself into a little bit of a managerial position.\nMost of my days were meetings, and growing the organization, and making decisions about,\nhigh-level strategic decisions about the team and what it should be working on, and so on. And it's kind of like a corporate executive role.\nAnd I can do it. I think I'm okay at it. But it's not like fundamentally what I enjoy. And so I think when I joined,\nthere was no computer vision team because Tesla was just going from the transition of using MobilEye, a third-party vendor, for all of its computer vision\nto having to build its computer vision system. So when I showed up, there were two people training deep neural networks.\nAnd they were training them at a computer at their legs, like down, there was a work.\n- There was some kind of basic classification task. - Yeah. And so I like grew that into what I think\nis a fairly respectable deep learning team, a massive computer cluster, a very good data annotation organization.\nAnd I was very happy with where that was. It became quite autonomous and so I stepped away\nand I'm very excited to do much more technical things again. Yeah. And kind of like we focus on AGI.\n- What was that soul searching like? 'Cause you took a little time off, I think, how many mushrooms did you take?\nNo, I'm just kidding. I mean, what was going through your mind? The human lifetime is finite.\n- [Andrej] Yeah. - You did a few incredible things. You're one of the best teachers of AI in the world.\nYou're one of the best. And I mean that in the best possible way. You're one of the best tinkerers in the AI world.\nMeaning like understanding the fundamentals of how something works by building it from scratch\nand playing with the basic intuitions. It's like Einstein, Fineman, were all really good at this kind of stuff.\nLike small example of a thing, to play with it, to try to understand it. So that, and obviously now with Tesla,\nyou helped build a team of machine learning\nengineers and a system that actually accomplishes something in the real-world. So given all that, what was the soul searching like?\n- Well, it was hard because obviously, I love the company a lot, and I love Elon, I love Tesla,\nso it was hard to leave. I love the team, basically. But yeah, I think I actually,\nI really potentially interested in revisiting it, maybe coming back at some point, working in Optimus,\nworking in AGI at Tesla. I think Tesla's going to do incredible things. It's basically a massive large-scale robotics\nkind of company with a ton of in-house talent for doing real incredible things. And I think human robots are going to be amazing.\nI think autonomous transportation is going to be amazing. All this is happening at Tesla. So I think it's just a really amazing organization.\nSo being part of it and helping it along I think was very, basically, I enjoyed that a lot. Yeah, it was basically difficult for those reasons\nbecause I love the company. But I'm happy to potentially at some point come back for act two.\nBut I felt like at this stage I built the team, it felt autonomous and I became a manager\nand I wanted to do a lot more technical stuff. I wanted to learn stuff. I wanted to teach stuff. And I just felt like it was a good time\nfor a change of pace a little bit. - What do you think is the best movie sequel\nof all time speaking of part two? 'Cause most of 'em suck. - Movie sequels? - Movie sequels, yeah.\nAnd you Tweet about movies. So just a tiny tangent, what's a favorite movie sequel?\n\"Godfather Part II\"? Are you a fan of \"Godfather\"? 'Cause you didn't even Tweet or mention \"The Godfather\".\n- Yeah, I don't love that movie. I know it has a- - We're gonna edit that out. We're gonna edit out the hate towards \"The Godfather\".\nHow dare you disrespect? - I think I will make a strong statement. I don't know why but I basically don't like any movie\nbefore 1995, something like that. - Didn't you mention \"Terminator 2\".\n- Okay. Okay. That's like a, \"Terminator 2\" was a little bit later. 1990...\n- No, I think \"Terminator 2\" was in the eighties. - And I like \"Terminator\" one as well, So, okay. So a few exceptions but by and large\nfor some reason, I don't like movies before 1995 or something. They feel very slow.\nThe camera is like zoomed out. It's boring, it's kind of naive, it's kind of weird. - And also Terminator was very much ahead of its time.\n- Yes. And \"The Godfather\", there's like no AGI.\n- I mean but you have, \"Good Will Hunting\" was one of the movies you mentioned and that doesn't have any AGI either.\nI guess it has mathematics. - Yeah, I guess occasionally, I do enjoy movies that don't feature. - Or like \"Anchorman\" that has no, that's.\n- \"Anchorman\" is so good. - I don't understand, speaking of AGI,\n'cause I don't understand why Will Ferrell is so funny. It doesn't make sense. It doesn't compute.\nThere's just something about him. And he's a singular human. 'Cause, you don't get that many comedies these days.\nAnd I wonder if it has to do about the culture or the Machine of Hollywood or does it have to do with\njust we got lucky with certain people in comedy that came together, 'cause he is a singular human. - Yeah, yeah.\nI love his movies. - That was a ridiculous tangent, I apologize. But you mentioned humanoid robots.\n"}
{"pod": "Lex Fridman Podcast", "input": "Tesla's Optimus", "output": "So what do you think about Optimus, about Tesla Bot? Do you think we'll have robots in the factory\nand in the home in 10, 20, 30, 40, 50 years? - Yeah. I think it's a very hard project.\nI think it's going to take a while, but who else is going to build human robots at scale? - [Lex] Yeah.\n- And I think it is a very good form factor to go after because like I mentioned the world is designed for humanoid form factor. These things would be able to operate our machines.\nThey would be able to sit down in chairs, potentially even drive cars. Basically, the world is designed for humans,\nthat's the form factor you want to invest into and make work over time. I think, there's another school of thought which is,\nokay, pick a problem and design a robot to it. But actually, designing a robot and getting a whole data engine and everything behind it to work\nis actually an incredibly hard problem. So it makes sense to go after general interfaces that, okay, they are not perfect for any one given task,\nbut they actually have the generality of just with a prompt, with English, able to do something across.\nAnd so I think it makes a lot of sense to go after a general interface in the physical world.\nAnd I think it's a very difficult project. It's going to take time, but I've seen no other company\nthat can execute on that vision. I think it's going to be amazing. Basically, physical labor, if you think transportation\nis a large market, try physical labor. It's insane. - But it's not just physical labor, to me,\nthe thing that's also exciting is the social robotics. So the relationship we'll have on different levels\nwith those robots. - Yeah. - That's why I was really excited to see Optimus.\nPeople have criticized me for the excitement, but I've worked with a lot of research labs\nthat do humanoid-legged robots, Boston Dynamics, Unitree.\nThere's a lot of companies that do legged robots, but that's the elegance of the movement\nis a tiny, tiny part of the big picture. So the two big exciting things to me about Tesla\ndoing humanoid or any legged robots is clearly integrating into the data engine.\nSo the data engine aspect, so the actual intelligence for the perception and the control and the planning\nand all that kind of stuff. Integrating into this huge, the fleet that you mentioned. Right. And then speaking of fleet, the second thing is\nthe mass manufacturers just knowing culturally driving towards a simple robot\nthat's cheap to produce at scale. - [Andrej] Yeah. - And doing that well, having experience to do that well, that changes everything.\nThat's why that's a very different culture and style than Boston Dynamics. Who by the way, those robots are just-\nThe way they move, it'll be a very long time before Tesla could achieve the smoothness of movement.\nBut that's not what it's about. It's about the entirety of the system.\nLike we talked about the data engine and the fleet. - [Andrej] Right. - And that's super exciting, even the initial sort of models.\nBut that too was really surprising that in a few months you can get a pro a prototype.\n- Yep. And the reason that happened very quickly is, as you alluded to, there's a ton of copy-paste from what's happening in the autopilot.\nA lot. The amount of expertise that came out of the woodworks at Tesla for building the human robot was incredible to see.\nBasically, Elon said at one point we're doing this and then next day, basically, all these CAD models\nstarted to appear and people talk about the supply chain and manufacturing. - [Lex] Yeah. - And people showed up with Screwdrivers and everything\nthe other day and started to like put together the body. And I was like, whoa. All these people exist at Tesla.\nAnd fundamentally building a car is actually not that different from building a robot. And that is true not just for the hardware pieces.\nAnd also let's not forget hardware, not just for a demo, but manufacturing of that hardware at scale\nis a whole different thing. But for software as well, basically, this robot currently thinks it's a car.\n- It's gonna have a midlife crisis at some point. - It thinks it's a car. Some of the earlier demos, actually, we were talking about\npotentially doing them outside in the parking lot because that's where all of the computer vision was working out of the box.\n- [Lex] That's Funny. - Instead of inside. But all the operating system, everything just copy-pastes,\ncomputer vision mostly copy-paste. I mean you have to retrain the neural nets, but the approach and everything and data engine and offline trackers and the way we go about\nthe occupancy tracker and so on. Everything copy-paste, you just need to retrain the neural nets. And then the planning control, of course,\nhas to change quite a bit, but there's a ton of copy-paste from what's happening at Tesla. And if you were to go with goal of like, okay,\nlet's build a million human robots and you're not Tesla, that's a lot to ask, if you're at Tesla,\nit's actually like, that's not that crazy. - And then the follow-up question is then how difficult, just like with driving,\nhow difficult is the manipulation task? - [Andrej] Yep. - Such that it can have an impact at scale? I think depending on the context,\nthe really nice thing about robotics is that, unless you do a manufacturer and that kind of stuff,\nis there is more room for error? - [Andrej] Yep. - Driving is so safety-critical and also time critical,\na robot is allowed to move slower, which is nice. - Yes. I think it's going to take a long time.\nBut the way you want to structure the development is you need to say, okay, it's going to take a long time. How can I set up the product development roadmap\nso that I'm making revenue along the way? I'm not setting myself up for a zero-one-loss function where it doesn't work until it works.\nYou don't wanna be in that position. You want to make it useful almost immediately. And then you want to slowly deploy it and-\n- [Lex] At scale, hopefully. - At scale and you want to set up your data engine, your improvement loops, the telemetry, the evaluation,\nthe harness and everything. And you want to improve the product over time, incrementally. And you're making revenue along the way.\nThat's extremely important because otherwise, you cannot build these large undertakings, just don't make sense economically.\nAnd also from the point of view of the team working on it, they need the dopamine along the way. They're not just going to make a promise\nabout this being useful. This is going to change the world in 10 years when it works. This is not where you want to be.\nYou want to be in a place like I think autopilot today where it's offering increased safety and convenience of driving today.\nPeople pay for it, people like it, people purchase it. And then you also have the greater mission that you're working towards.\n- And you see that. So the dopamine for the team, that was the source of happiness? - Yes, hundred percent, you're deploying this.\nPeople like it, people drive it, people pay for it, they care about it. There's all these YouTube videos, your grandma drives it.\nShe gives you feedback. People like it, people engage with it. You engage with it. Huge. - Do people that drive Teslas recognize you\nand give you love? Like, hey thanks for this nice feature that it's doing.\n- Yeah, I think the tricky thing is some people really love you, some people, unfortunately, you're working on something that you think is extremely valuable, useful, et cetera,\nsome people do hate you. There's a lot of people who hate me and the team and the whole project.\nAnd I think- - Are they Tesla drivers? - Many cases they're not, actually. - Yeah.\nThat actually makes me sad about humans or the current ways that humans interact.\nI think that's actually fixable. I think humans want to be good to each other. I think Twitter and social media is part of the mechanism\nthat actually somehow makes the negativity more viral that it doesn't deserve,\ndisproportionately add a viral boost of negativity.\nBut I wish people would just get excited about, so suppress some of the jealousy,\nsome of the ego and just get excited for others. And then there's a karma aspect to that. You get excited for others, they'll get excited for you.\nSame thing in academia, if you're not careful, there is a dynamical system there. If you think of in silos and get jealous\nof somebody else being successful that actually perhaps counterintuitively\nleads the less productivity of you as a community and you individually. I feel like if you keep celebrating others,\nthat actually makes you more successful. - [Andrej] Yeah. - And I think people haven't, depending on the industry,\nhaven't quite learned that yet. - Yeah. Some people are also very negative and very vocal. So they're very prominently featured.\nBut actually, there's a ton of people who are cheerleaders, but they're silent cheerleaders. And when you talk to people just in the world,\nthey will all tell you it's amazing, it's great. Especially like people who understand how difficult it is to get this stuff working. People who have built products and makers and entrepreneurs,\nmaking this work and changing something is incredibly hard. Those people are more likely to cheerlead you.\n- Well, one of the things that makes me sad is some folks in the robotics community don't do the cheerleading and they should\n'cause they know how difficult it is. Well, they actually sometimes don't know how difficult it is to create a product at scale.\nRight? - [Andrej] Yep. - They actually deploy in the real-world. A lot of the development of robots and AI systems\nis done on very specific small benchmarks and as opposed to real-world additions.\n- Yes. Yeah. I think it's really hard to work on robotics in academic setting. - Or AI systems that apply in the real-world.\n"}
{"pod": "Lex Fridman Podcast", "input": "ImageNet", "output": "You've criticized, you flourished, and loved\nfor time the ImageNet, the famed ImageNet dataset and have recently had some words of criticism\nthat the academic research ML community gives a little too much love still to the ImageNet\nor those kinds of benchmarks. Can you speak to the strengths and weaknesses of data sets\nused in machine learning research? - Actually, I don't know that I recall the specific instance\nwhere I was unhappy or criticizing ImageNet. I think ImageNet has been extremely valuable.\nIt was basically a benchmark that allowed the deep learning community to demonstrate\nthat deep neural nets actually work. - [Lex] Yes. - There's a massive value in that.\nSo I think ImageNet was useful, but basically, it's become a bit of an EMNIST at this point. So EMNIST is like little 28 by 28 grayscale digits.\nThat's kind of a joke data set that everyone just crushes. - There's still papers written on EMNIST though, right?\nLike strong papers? - [Andrej] Yeah. - Like papers that focus on like how do we learn with a small amount of data, that kinda stuff.\n- Yeah. Yeah, I could see that being helpful but not in mainline computer vision research anymore, of course. - I think the way I've heard you just somewhere,\nmaybe I'm just imagining things, but I think you said like ImageNet was a huge contribution to the community for a long time\nand now it's time to move past those kinds of- - Well, ImageNet has been crushed. I mean, the error rates are, yeah,\nwe're getting like 90% accuracy in 1000 classification way prediction\nand I've seen those images and this is like really high, that's really good.\nIf I remember correctly, the top five error rate is now like 1% or something. - Given your experience with a gigantic real-world data set,\nwould you like to see benchmarks move into certain directions that the research community uses? - Unfortunately, I don't think academics\ncurrently have the next ImageNet. We've obviously, I think we've crushed EMNIST. We've basically crushed ImageNet\nand there's no next-big benchmark that the entire community rallies behind and uses\nfor further development of these networks. - Oh, yeah. I wonder what it takes for a dataset to captivate the imagination of everybody.\nLike where they all get behind it. That could also need a leader, right?\n- [Andrej] Yeah. - Somebody with popularity. I mean that, yeah, why did ImageNet takeoff?\nIs it just the accident of history? - It was the right amount of difficult, it was the right amount of difficult and simple\nand interesting enough it was the right time for that kind of a data set.\n- Question from Reddit. What are your thoughts on the role that synthetic data\n"}
{"pod": "Lex Fridman Podcast", "input": "Data", "output": "and game engines will play in the future of neural net model development? - I think as neural nets converge to humans,\nthe value of simulation to neural nets will be similar to value of simulation to humans.\nSo people use simulation because they can learn something in that kind of a system and without having\nto actually experience it. - But you're referring to the simulation we do in our head? Isn't that what thinking is?\n- Oh no, sorry. Simulation, I mean like video games or other forms of simulation for various professionals.\n- Well, so let me push back on that 'cause maybe there's simulation that we do in our heads, like simulate if I do this, what do I think will happen?\n- [Andrej] Okay. That's like internal simulation. - Yeah, internal. Isn't that what we're doing? Assuming before we act. - Oh, yeah.\nBut that's independent from the use of simulation in the sense of computer games, or using simulation for training set creation, or something.\n- Is it independent or is it just loosely correlated? 'Cause isn't that useful to do counterfactual\nor edge case simulation to what happens if there's a nuclear war?\nWhat happens if there's, like those kinds of things? - Yeah. That's a different simulation from Unreal Engine.\nThat's how I interpreted the question. - Ah, so like simulation of the average case?\nWhat's Unreal Engine? What do you mean by Unreal Engine? So simulating a world.\n- [Andrej] Yeah. - The physics of that world, Why is that different? 'Cause you also can add behavior to that world\nand you could try all kinds of stuff, right? You could throw all kinds of weird things into it.\n- [Andrej] Yeah. - Unreal Engine is not just about simulating, I mean I guess it is about simulating the physics of the world,\nit's also doing something with that. - Yeah. The graphics, the physics, and the agents\nthat you put into the environment and stuff like that. Yeah. - I feel like you said that it's not that important,\nI guess, for the future of AI development. Is that correct, to interpret you that way? - Well, I think, humans use simulators\nand they find them useful and so computers will use simulators and find them useful. - Okay, so you're saying it's not,\nI don't use simulators very often. I play a video game every once in a while but I don't think I derive any wisdom\nabout my own existence from those video games. It's a momentary escape from reality\nversus a source of wisdom about reality. So I think that's a very polite way of saying\nsimulation is not that useful. - Yeah. Maybe not. I don't see it as a fundamental, really important part\nof training neural nets currently. But I think as neural nets become more and more powerful,\nI think you will need fewer examples to train additional behaviors. And simulation is, of course, there's a domain gap\nin a simulation that's not the real-world, it's slightly something different. But with a powerful enough neural net\nyou need the domain gap can be bigger I think because neural net will understand that even though it's not the real-world,\nit has all this high-level structure that I'm supposed to learn from. - So the neural net will actually, yeah,\nit will be able to leverage the synthetic data better? - [Andrej] Yes.\n- By closing the gap but understanding in which ways this is not real data? - [Andrej] Exactly.\n- Reddit do better questions next time. That was a question. No, I'm just kidding. All right, so is it possible, do you think,\nspeaking of EMNIST to construct neural nets and training processes that require very little data.\nSo we've been talking about huge data sets like the internet for training. - [Andrej] Yeah. - I mean one way to say that is like you said,\nthe querying itself is another level of training I guess and that requires a little data.\n- [Andrej] Yeah. - But do you see any value in doing research\nand going down the direction of can we use very little data to construct a knowledge base?\n- A hundred percent. I just think at some point you need a massive data set and then when you pre-train your massive neural net\nand get something that is like a GPT or something, then you're able to be very efficient\nat training any arbitrary new task. So a lot of these GPTs you can do tasks\nlike sentiment analysis, or translation, or so on, just by being prompted with very few examples. Here's the kind of thing I want you to do.\nLike here's an input sentence, here's the translation into German, input sentence, translation to German, input sentence, blank, and the neural net\nwill complete the translation to German just by looking at the example you've provided. And so that's an example of a very few shot learning\nin the activations of the neural net, instead of the weights of the neural net. And so I think basically just like humans,\nneural nets will become very data efficient at learning any other new task. But at some point, you need a massive data set\nto pre-train your network. - I do get that. And probably, we humans have something like that.\nDo we have something like that? Do we have a passive in the background,\nbackground model constructing thing that just runs all the time in a self-supervised way?\nWe're not conscious of it? - I think humans definitely, I mean obviously, we learn a lot during our lifespan,\nbut also we have a ton of hardware that helps us, the initialization coming from evolution.\nAnd so I think that's also a really big component. A lot of people in the field, I think they just talk about the amounts of like seconds\nthat a person has lived, pretending that this is a tabula rasa, a zero initialization of a neural net.\nAnd it's not. You can look at a lot of animals for example, zebras. Zebras get born, and they see, and they can run,\nthere's zero training data in their lifespan. They can just do that. So somehow, I have no idea how, evolution has found a way\nto encode these algorithms and these neural net initializations that are extremely good into ATCGs.\nAnd I have no idea how this works, but apparently, it's possible because here's proof by existence.\n- There's something magical about going from a single-cell to an organism that is born\nto the first few years of life. I like the idea that the reason we don't remember anything about the first few years of our life\nis that it's a really painful process. Like it's a very difficult challenging training process.\n- [Andrej] Yeah. - Like intellectually and maybe, yeah, I mean I don't, why don't we remember any of that?\nThat might be some crazy training going on and maybe that's the background model training\nthat is very painful. - [Andrej] Yeah. - And so it's best for the system once it's trained\nnot to remember how it was constructed. - I think it's just like the hardware for long-term memory is just not fully developed.\n- [Lex] Sure. - I feel like the first few years of infants, it's not actually like learning, it's brain maturing.\n- [Lex] Yeah. - We're born premature and there's a theory along those lines because of the birth canal\nand the swelling of the brain. And so we're born premature and then the first few years we're just, the brain's maturing\nand then there's some learning eventually. It's my current view on it. - What do you think, do you think neural nets\ncan have long-term memory? Like that approach is something like humans?\nDo you think there needs to be another meta-architecture on top of it to add something like a knowledge base\nthat learns facts about the world and all that kind of stuff? - Yes, but I don't know to what extent it will be explicitly constructed.\nIt might take on intuitive forms where you are telling the GPT, hey, you have a declarative memory bank\nto which you can store and retrieve data from and whenever you encounter some information that you find useful just save it to your memory bank.\nAnd here's an example of something you have retrieved and here's how you say it and here's how you load from it. You just say, load whatever, you teach it in text,\nin English and then it might learn to use a memory bank from that. - Oh, so the neural net is the architecture\nfor the background model, the base thing and then everything else is just on top of it. - It's not just a text, right?\nYou're giving it gadgets and gizmos. So you're teaching it some kind of a special language by which it can save arbitrary information\nand retrieve it at a later time. - [Lex] Yeah. - And you're telling about these special tokens and how to arrange them to use these interfaces.\nIt's like, hey, you can use a calculator, here's how you use it. Just do five three plus four one equals\nand when equals is there, a calculator will actually read out the answer and you don't have to calculate it yourself\nand you just tell it in English, this might actually work. - Do you think in that sense Gato is interesting,\nthe DeepMind system that it's not just new language but actually throws it all in the same pile,\nimages, actions, all that kind of stuff. That's basically what we're moving towards.\n- Yeah, I think so. So Gato is very much a kitchen sink of an approach to reinforcement learning in lots of different environments\nwith a single fixed transformer model. Right? I think it's a very early result in that realm.\nBut I think, yeah, it's along the lines of what I think things will eventually look like. - Right. So this is the early days of a system\nthat eventually will look like this, from a Rich Sutton perspective. - Yeah. I'm not a super huge fan of, I think all these interfaces\nthat like look very different. I would want everything to be normalized into the same API.\nSo for example, screen pixels, very same API instead of having like different world environments that have very different physics and joint configurations\nand appearances and whatever. And you're having some kind of special tokens for different games that you can plug.\nI'd rather just normalize everything to a single interface so it looks the same to the neural net if that makes sense.\n- So it's all gonna be pixel-based Pong in the end? - [Andrej] I think so.\n- Okay. Let me ask you about your own personal life.\n"}
{"pod": "Lex Fridman Podcast", "input": "Day in the life", "output": "A lot of people wanna know you're one of the most productive and brilliant people in the history of AI. What is a productive day in the life\nof Andrej Karpathy look like? What time do you wake up? 'Cause imagine some kind of dance between\nthe average productive day and a perfect productive day. So the perfect productive day is the thing we strive towards\nand the average is kind of what it converges to, given all the mistakes and human eventualities and so on.\n- [Andrej] Yep. - So what time did you wake up? Are you a morning person? - I'm not a morning person. I'm a night owl, for sure.\n- Is it stable or not? - It's semi-stable like eight or nine or something like that.\nDuring my PhD, it was even later, I used to go to sleep usually at 3:00 AM, I think the AM hours are precious\nand a very interesting time to work because everyone is asleep. At 8:00 AM or 7:00 AM the east coast is awake.\nSo there's already activity, there's already some text messages, whatever. There's stuff happening. You can go on some news website\nand there's stuff happening, it's distracting. At 3:00 AM everything is totally quiet and so you're not gonna be bothered\nand you have solid chunks of time to do work. So I like those periods, night owl by default.\nAnd then I think productive time, basically, what I like to do is you need to build\nsome momentum on the problem without too much distraction and you need to load your ram, your working memory\nwith that problem. And then you need to be obsessed with it when you're taking shower, when you're falling asleep,\nyou need to be obsessed with the problem and it's fully in your memory and you're ready to wake up and work on it right there. - So is this in a scale temporal scales of a single day\nor a couple of days a week, a month? - Yeah. So I can't talk about one day, basically, in isolation because it's a whole process.\nWhen I wanna get productive in the problem, I feel like I need a span of a few days where I can really get in on that problem\nand I don't wanna be interrupted and I'm going to just be completely obsessed with that problem. And that's where I do most of my good work, I would say.\n- You've done a bunch of cool, like little projects in a very short amount of time, very quickly, so that requires you just focusing on it.\n- Yeah, basically, I need to load my working memory with the problem and I need to be productive because there's always a huge fixed cost\nto approaching any problem. I was struggling with this for example at Tesla because I want to work on small side project, but okay,\nyou first need to figure out, oh, okay, I need to associate into my cluster, I need to bring up a VS Code editor so I can work on this.\nI ran into some stupid error because of some reason. You're not at a point where you can be just productive right away.\nYou are facing barriers. And so it's about really removing all of that barrier\nand you're able to go into the problem and you have the full problem loaded in your memory. - And somehow avoiding distractions of all different forms.\n- [Andrej] Yes. - Like news stories, emails, but also distractions\nfrom other interesting projects that you previously worked on or currently working on and so on. You just wanna really focus your mind.\n- Yeah. And I mean I can take some time off for distractions and in between, but I think it can't be too much.\nMost of your day is sort of spent on that problem. And then, I drink coffee, I have my morning routine,\nI look at some news, Twitter, Hacker News, Wall Street Journal, et cetera. It's great.\n- So basically, you wake up, you have some coffee, are you trying to get to work as quickly as possible? Do you take in this diet of what the hell's happening\nin the world first? - I do find it interesting to know about the world. I don't know that it's useful or good,\nbut it is part of my routine right now. So I do read through a bunch of news articles and I wanna be informed and I'm suspicious of it.\nI'm suspicious of the practice, but currently, that's where I am. - Oh, you mean suspicious about the positive effect?\n- [Andrej] Yeah. - Of that practice on your productivity and your well-being? - My well-being, psychologically, yeah.\n- And also on your ability to deeply understand the world because there's a bunch of sources of information\nyou're not really focused on deeply integrating it. - Yeah, it's a little bit distracting. Yeah. - In terms of a perfectly productive day\nfor how long of a stretch of time in one session do you try to work and focus on a thing?\nIs it a couple hours, is it one hour, is it 30 minutes? Is it 10 minutes? - I can probably go a small few hours\nand then I need some breaks in between for food and stuff and yeah.\nBut I think, it's still really hard to accumulate hours. I was using a tracker that told me exactly how much time\nI spent coding any one day. And even on a very productive day, I still spent only six or eight hours.\n- [Lex] Yeah. - And it's just because there's so much padding, commute, talking to people, food, et cetera.\nThere's a cost of life just living and sustaining and homeostasis and just maintaining yourself\nas a human is very high. - And there seems to be a desire within the human mind\nto participate in society that creates that padding. - [Andrej] Yeah. - 'Cause the most productive days I've ever had\nis just completely from start to finish is tuning out everything. - [Andrej] Yep. - And just sitting there and then you could do more\nthan six in eight hours. - Yep. - Is there some wisdom about what gives you strength to do tough days of long focus?\n- Yeah, just whenever I get obsessed about a problem, something just needs to work. Something just needs to exist. - It needs to exist.\nSo you're able to deal with bugs and programming issues and technical issues and design decisions\nthat turn out to be the wrong ones. You're able to think through all of that given that you want a thing to exist. - Yeah, it needs to exist.\nAnd then I think to me also a big factor is, are other humans are going to appreciate it? Are they going to like it?\nThat's a big part of my motivation. If I'm helping humans and they seem happy, they say nice things, they Tweet about it or whatever,\nthat gives me pleasure because I'm doing something useful. - So you do see yourself sharing it with the world?\nWith GitHub, with the blog post or through videos? - Yeah, I was thinking about it like, suppose I did all these things but did not share them.\nI don't think I would have the same amount of motivation that I can build up. - You enjoy the feeling of other people gaining value\nand happiness from the stuff you've created. - [Andrej] Yeah. - What about diet?\nI saw you played with intermittent fasting. Do you fast? Does that help? - I play with everything.\n- With the things you played, what's been most beneficial to your ability to mentally focus on a thing\nand just mental productivity and happiness? You still fast? - Yeah.\nI still fast but I do intermittent fasting but really what it means at the end of the day is I skip breakfast. - [Lex] Yeah. - So I do 18/6 roughly by default\nwhen I'm in my steady state, if I'm traveling or doing something else I will break the rules. But in my steady state, I do 18/6.\nSo I eat only from 12:00 to 6:00. Not a hard rule and I break it often, but that's my default. And then, yeah, I've done a bunch of random experiments\nfor the most part right now where I've been for the last year and a half I wanna say is I'm plant-based or plant-forward.\nI heard plant-forward, it sounds better. - [Lex] What does that mean exactly? - I don't actually know what the difference is, but it sounds better in my mind. But it just means I prefer plant-based food and-\n- Raw or cooked. - I prefer cooked and plant-based. - So plant-based, forgive me,\nI don't actually know how wide the category of plant entails. - Well, plant-based just means\nthat you're not militant about it and you can flex and you just prefer to eat plants and you're not making,\nyou're not trying to influence other people. And you come to someone's house party and they serve you a steak that they're really proud of,\nyou will eat it. - Yes. Right. You're not judgmental. That's beautiful. I mean, I'm the flip side of that,\nbut I'm very sort of flexible. Have you tried doing one meal a day? - I have accidentally but not consistently,\nbut I've accidentally had that. I don't like it. I think it makes me feel not good. It's too much of a hit.\n- [Lex] Yeah. - And so currently I have about two meals a day, 12:00 and 6:00, probably. - I do that nonstop.\nI'm doing it now. I do one meal a day. - [Andrej] Okay. - It's interesting. It's an interesting feeling.\nHave you ever fasted longer than a day? - Yeah, I've done a bunch of water fasts. 'Cause I was curious what happens. - [Lex] What happens, anything interesting?\n- Yeah, I would say so. I mean, what's interesting is that you're hungry for two days and then starting day three or so,\nyou're not hungry. It's such a weird feeling because you haven't eaten in a few days and you're not hungry.\n- Yeah, isn't that weird? - [Andrej] It's really weird. - One of the many weird things about human biology. - [Andrej] Yeah.\n- It figures something out, it finds another source of energy or something like that. Or relaxes the system.\nI don't know how it works. - Yeah, the body is like, \"You're hungry, you're hungry.\" And then it just gives up. It's like, \"Okay, I guess we're fasting now.\" There's nothing.\nAnd then it's just focuses on trying to make you not hungry and not feel the damage of that and trying to give you\nsome space to figure out the food situation. - So are you still to this day most productive at night?\n- I would say I am, but it is really hard to maintain my PhD schedule.\nEspecially, when I was say working at Tesla and so on. It's a non-starter. But even now, people want to meet for various events.\nSociety lives in a certain period of time. - [Lex] Yeah. - And you have to work with that. - It's hard to do a social thing\nand then after that return and do work. - Yeah. It's just really hard.\n- That's why I try, when I do social thing, I try not to do too much drinking so I can return and continue doing work.\n- [Andrej] Yeah. - But at Tesla is there conversions, not Tesla,\nbut any company, is there a convergence to always a schedule or is that how humans behave when they collaborate?\nI need to learn about this? - [Andrej] Yeah. - Do they try to keep a consistent schedule where you're all awake at the same time? - I mean, I do try to create a routine\nand I try to create a steady state in which I'm comfortable in. So I have a morning routine, I have a day routine.\nI try to keep things to a steady state and things are predictable and then your body just sticks to that.\nAnd if you try to stress that a little too much, it will create, when you're traveling and you're dealing with jet lag, you're not able to really ascend to where you need to go.\n- Yeah. Yeah. That's weird too about us humans with the habits and stuff. What are your thoughts on work-life balance\nthroughout a human lifetime? So Tesla in part was known for pushing people\nto their limits, in terms of what they're able to do, in terms of what they're trying to do,\nin terms of how much they work, all that kind of stuff. - Yeah, I mean I will say Tesla gets a little too much bad rep for this\nbecause what's happening is Tesla, it's a bursty environment. So I would say the baseline,\nmy only point of reference is Google where I've interned three times and I saw what it's like inside Google and DeepMind,\nI would say the baseline is higher than that. But then there's a punctual equilibrium where once in a while there's a fire\nand people work really hard and so it's spiky and bursty and then all the stories get collected-\n- [Lex] Above the bursts. Yeah. - And then it gives the appearance of total insanity. But actually, it's just a bit more intense environment\nand there are fires and sprints and so I think definitely though I would say\nit's a more intense environment than something you would get at Google. - But in your personal, forget all of that, just in your own personal life,\nwhat do you think about the happiness of a human being? A brilliant person like yourself.\nabout finding a balance between work and life or is such a thing not a good thought experiment?\n- Yeah, I think balance is good but I also love to have sprints that are out of distribution\nand that's when I think I've been pretty creative as well.\n- So sprints out of distribution means that most of the time you have a quote-unquote balance.\n- I have balance most of the time and I like being obsessed with something once in a while. - Once in a while is what, once a week,\nonce a month, once a year? - Yeah. Probably I'd like say once a month or something. Yeah. - And that's when we get and you get Git-Repo for market.\n- Yeah. That's when you're like really care about a problem, it must exist. This will be awesome. You're obsessed with it and now you can't just do it\non that day, you need to pay the fixed cost of getting into the groove. - [Lex] Yeah. - And then you need to stay there for a while\nand then society will come and they will try to mess with you and they will try to distract you. - [Lex] Yeah. - Yeah.\nThe worst thing is a person who's like, \"I just need five minutes of your time.\" - [Lex] Yeah. - The cost of that is not five minutes.\n- [Lex] Yes. - And society needs to change how it thinks about just five minutes of your time.\n- Right. It's never just one minute, just 30. Just a quick thing. - [Andrej] What's the big deal?\nWhy are you being, so? - Yeah, no. What's your computer setup?\nWhat's like the perfect- Are you somebody that's flexible to no matter what laptop, four screens?\n- [Andrej] Yeah. - Or do you prefer a certain setup that you're most productive with?\n- I guess the one that I'm familiar with is one large screen, 27-inch and my laptop on the side.\n- What operating system? - I do MaX, that's my primary. - For all tasks? - I would say OS X.\nBut when you're working on deep-learning, everything is Linux, you're SSH into a cluster and you're working remotely. - But what about the actual development?\nLike using the IDE? - Yeah. You would use, I think a good way is you just run VS Code,\nmy favorite editor right now on your Mac. But you are actually, you have a remote folder through SSH.\nSo the actual files that you're manipulating are on a cluster somewhere else. - So what's the best IDE, VS Code?\n"}
{"pod": "Lex Fridman Podcast", "input": "Best IDE", "output": "What else do people use? So I use Emax, still. - That's old school.\n- It may be cool, I don't know if it's maximum productivity. So what do you recommend in terms of editors?\nYou worked with a lot of software engineers, editors for Python, C++, machine learning applications.\n- I think the current answer is VS Code, currently, I believe that's the best IDE.\nIt's got a huge amount of extensions. It has GitHub Copilot integration,\nwhich I think is very valuable. - What do you think about the Copilot integration? I got to talk a bunch with Guido van Rossum\nwho's the creator of Python and he loves Copilot, he programs a lot with it.\n- [Andrej] Yeah. - Do you? - Yeah, I use Copilot. I love it. And it's free for me but I would pay for it.\nYeah. I think it's very good. And the utility that I found with it was, I would say there's a learning curve\nand you need to figure out when it's helpful and when to pay attention to its outputs and when it's not going to be helpful\nwhere you should not pay attention to it. Because if you're just reading its suggestions all the time, it's not a good way of interacting with it.\nBut I think I was able to sort of mold myself to it. I find it's very helpful, number one, in copy-paste\nand replace some parts. So when the pattern is clear, it's really good at completing the pattern.\nAnd number two, sometimes it suggests APIs that I'm not aware of. So it tells you about something that you didn't know.\n- And that's an opportunity to discover a new thing. - It's an opportunity to. So I would never take Copilot code as given.\nI almost always copy-paste into a Google search and you see what this function is doing and then you're like, \"Oh, that's actually exactly\nwhat I need.\" Thank you, Copilot. So you learn something. - So it's in part of search engine, in part maybe getting the exact syntax correctly\nthat once you see it, it's that MPR thing. Once you see it, you know it's correct.\n- [Andrej] Yes, exactly. Exactly. - You, yourself can struggle. - [Andrej] You can verify. - You can verify efficiently but you can't generate efficiently.\n- And Copilot really, I mean it's autopilot for programming. Right? And currently is doing the link following\nwhich is the simple copy-paste and sometimes suggest, but over time it's going to become more and more autonomous.\nAnd so the same thing will play out in not just coding but actually across many, many different things probably.\n- But coding is an important one, right? - [Andrej] Very. - Like writing programs. - [Andrej] Yeah. - How do you see the future of that developing\nthe program synthesis, like being able to write programs that are more and more complicated? 'Cause right now it's human-supervised in interesting ways.\n- [Andrej] Yes. - It feels like the transition will be very painful. - My mental model for it is the same thing will happen\nas with the autopilot. So currently, he's doing lane following, he is doing some simple stuff, and eventually,\nwe'll be doing autonomy and people will have to intervene less and less. And those could be like testing mechanisms.\nIf it writes a function and that function looks pretty damn correct. But how do you know it's correct\n'cause you're like getting lazier and lazier as a programmer, your ability to, 'cause like little bugs\nbut I guess it won't make little mistakes. - No it will, Copilot will make off by one subtle bug.\nIt has done that to me. - But do you think future systems will or is it really the off by one\nis actually a fundamental challenge of programming. - In that case it wasn't fundamental and I think things can improve but yeah,\nI think humans have to supervise. I am nervous about people not supervising what comes out and what happens to, for example,\nthe proliferation of bugs in all of our systems. I'm nervous about that but I think there will probably be\nsome other Copilots for bug finding and stuff like that, at some point. 'Cause there'll be a lot more automation for-\n- Oh man, a Copilot that generates a compiler,\none that does a linter. - [Andrej] Yes. - One that does like a type checker. - Yeah.\nIt's a committee of a GPT sort of like- - And then there'll be like a manager for the committee. - [Andrej] Yeah.\n- And then there'll be somebody that says, a new version of this is needed. We need to regenerate it. - Yeah. There were 10 GPTs that were forwarded\nand gave 50 suggestions. Another one looked at it and picked a few that they like, a bug one looked at it\nand it was like, it's probably a bug, they got re-ranked by some other thing and then a final ensemble GPT comes in\nand is like, okay, given everything you guys have told me, this is probably the next token. - You know the feeling is the number of programmers\nin the world has been growing and growing very quickly. - [Andrej] Yeah. - Do you think it's possible that it'll actually level out and drop to a very low number in this kind of world?\n'Cause then you'll be doing Software 2.0 programming and you'll be doing this generation\nof Copilot-type systems programming. But you won't be doing the old school\nSoftware 1.0 programming. - I don't currently think that they're just going to replace human programmers.\nI'm so hesitant saying stuff like this, right? - Yeah. Because this is gonna be replayed in five years and no,\nit's going to show that like this is where we thought, because I agree with you but I think we might be very surprised, right?\nWhat's your sense of where we stand with language models? Does it feel like the beginning, or the middle, or the end? - The beginning, a hundred percent.\nI think the big question in my mind is for sure GPT will be able to program quite well, competently and so on. - [Lex] Yeah.\n- How do you steer the system? You still have to provide some guidance to what you actually are looking for. And so how do you steer it and how do you say,\nhow do you talk to it? How do you audit it and verify that what it's done is correct\nand how do you work with this? And it's as much not just an AI problem but a UI, UX problem.\n- [Lex] Yeah. - So beautiful fertile ground for so much interesting work\nfor VS Code++ where you're not just, it's not just human programming anymore. It's amazing. - Yeah.\nSo you're interacting with the system so not just one prompt but it's iterative prompting. - [Andrej] Yeah.\n- You're trying to figure out, having a conversation with the system. - [Andrej] Yeah. - That actually, I mean to me that's super exciting to have a conversation with the program I'm writing.\n- Yeah. Yeah. Maybe at some point you're just conversing with it. It's like, okay, here's what I wanna do, actually this variable.\nMaybe it's not even that low-level as a variable, but. - You can also imagine like can you translate\nthis to C++ and back to Python and back to? - Yeah, that already kind of exists in some way. - No, but just like doing it as part\nof the program experience. Like I think I'd like to write this function in C++\nor you just keep changing from different programs 'cause of the different syntax,\nmaybe I want to convert this into a functional language. - [Andrej] Yeah. - And so you get to become multilingual as a programmer\nand dance back and forth efficiently. - Yeah. I mean I think the UI, UX of it though is still very hard to think through.\n- [Lex] Yeah. - Because it's not just about writing code on a page. You have an entire developer environment, you have a bunch of hardware on it,\nyou have some environmental variables, you have some scripts that are running in a Chrome job. There's a lot going on to working with computers\nand how do these systems set up environment flags, and work across multiple machines,\nand set up screen sessions, and automate different processes. like how all that works and is auditable by humans and so on\nis like massive question at the moment. - You've built arxiv-sanity. What is arxiv and what is the future\n"}
{"pod": "Lex Fridman Podcast", "input": "arXiv", "output": "of academic research publishing that you would like to see? - So arxiv is this pre-print server.\nSo if you have a paper you can submit it for publication to journals or conferences and then wait six months\nand then maybe get a decision pass or fail, or you can just upload it to arxiv and then people can Tweet about it three minutes later.\nAnd then everyone sees it, everyone reads it, and everyone can profit from it in their own little ways. - And you can cite it and it has an official look to it.\nIt feels like a publication process. - [Andrej] Yeah. - It feels different than if you just put in a blog post.\n- Oh, yeah. Yeah. I mean it's a paper and usually the bar is higher for something that you would expect on arxiv\nas opposed to something you would see in a blog post. - Well, the culture created the bar 'cause you could probably post\na pretty crappy paper or an arxiv. - [Andrej] Yes. - So what's that make you feel like, what's that make you feel about peer review?\nSo rigorous peer review by two, three experts versus the peer review of the community right\nas it's written? - Yeah. Basically, I think the community is very well able to peer-review things very quickly on Twitter.\nAnd I think maybe it just has to do something with AI machine learning field specifically though, I feel like things are more easily auditable\nand the verification is easier potentially than the verification somewhere else.\nSo it's like, you can think of these scientific publications as little block-chains where everyone's building on each other's work\nand citing each other and you sort of have AI, which is this much faster and loose blockchain,\nbut then you have, and any one individual entry is very cheap to make.\nAnd then you have other fields where maybe that model doesn't make as much sense. And so I think in AI at least\nthings are pretty easily verifiable. And so that's why when people upload papers, they have a really good idea and so on.\nPeople can try it out the next day and they can be the final arbiter of whether it works or not on their problem.\nAnd the whole thing just moves significantly faster. So I feel like academia still has a place, sorry, this conference, journal process still has a place,\nbut it's sort of it lags behind I think, and it's a bit more maybe higher quality process.\nBut it's not the place where you will discover cutting-edge work anymore. - [Lex] Yeah. - It used to be the case when I was starting my PhD\nthat you go to conferences and journals and you discuss all the latest research. Now when you go to a conference or a journal,\nno one discusses anything that's there because it's already like three generations ago, irrelevant. - Yes.\nWhich makes me sad about like DeepMind for example, where they still publish in nature and these big prestigious, I mean there's still value,\nI suppose to the prestige that comes with these big venues. - [Andrej] Yeah. - But the result is that they'll announce\nsome breakthrough performance and it'll take like a year to actually publish the details.\nI mean, and those details, if they were published immediately would inspire the community to move in certain directions, would they?\n- Yeah. It would speed up the rest of the community, but I don't know to what extent that's part of their objective function also.\n- That's true. So it's not just the prestige. A little bit of the delay is part. - Yeah, they certainly, DeepMind specifically,\nhas been working in the regime of having slightly higher quality basically process\nand latency and publishing those papers that way. - Another question from Reddit.\nDo you or have you suffered from imposter syndrome, being the director of AI Tesla, being this person\nwhen you're at Stanford where the world looks at you as the expert in AI to teach the world\nabout machine learning. - When I was leaving Tesla after five years, I spent a ton of time in meeting rooms\nand I would read papers. In the beginning, when I joined Tesla, I was writing code and then I was writing less and less code, and I was reading code and then I was reading\nless and less code. And so this is just a natural progression that happens I think. And definitely, I would say near the tail end,\nthat's when it starts to hit you a bit more. That you're supposed to be an expert but actually, the source of truth is the code\nthat people are writing, the GitHub and the actual code itself. And you're not as familiar with that as you used to be.\nAnd so I would say maybe there's some insecurity there. - Yeah, that's actually pretty profound, that a lot of the insecurity has to do\nwith not writing the code in the computer science space 'cause that is the truth. That right there.\n- The code is the source of truth. The papers and everything else, it's a high-level summary. I don't, yeah, just a high-level summary,\nbut at the end of the day you have to read code. It's impossible to translate all that code into actual paper form.\nSo when things come out, especially when they have a source code available, that's my favorite place to go. - So like I said, you're one of the greatest teachers\n"}
{"pod": "Lex Fridman Podcast", "input": "Advice for beginners", "output": "of machine learning AI ever from CS231n to today,\nwhat advice would you give to beginners interested in getting into machine learning? - Beginners are often focused on what to do\nand I think the focus should be more how much you do. So I am a believer on the high-level, in this 10,000 hours concept where you just have to\njust pick the things where you can spend time and you care about and you're interested in. You literally have to put in 10,000 hours of work.\nIt doesn't even matter as much where you put it, you'll iterate and you'll improve and you'll waste some time.\nI dunno if there's a better way. You need to put in 10,000 hours. But I think it's actually really nice 'cause I feel like there's some sense of determinism\nabout being an expert at a thing if you spend 10,000 hours. you can literally pick an arbitrary thing\nand I think if you spend 10,000 hours of deliberate effort and work, you actually will become an expert at it.\nAnd so I think it's like a nice thought. And so basically I would focus more on\nare you spending 10,000 hours? That's what I would focus on. - And then thinking about what kind of mechanisms maximize\nyour likelihood of getting to 10,000 hours. - [Andrej] Yes, exactly. - Which for us silly humans means probably forming\na daily habit of every single day actually doing thing. - Whatever helps you. So I do think to a large extent\nit's a psychological problem for yourself. - [Lex] Yeah. - One other thing that I think is helpful for the psychology of it,\nis many times people compare themselves to others in the area, I think this very harmful. Only compare yourself to you from some time ago.\nLike say a year ago, are you better than you a year ago? This is the only way to think.\nAnd I think then you can see your progress and it's very motivating. - That's so interesting. That focus on the quantity of hours.\n'Cause I think a lot of people in the beginner stage but actually throughout get paralyzed by the choice.\n- [Andrej] Yeah. - Like which one do I pick this path or this path? - [Andrej] Yeah. - They'll literally get paralyzed by which IDE to use?\n- Well, they're worried, yeah, they'll worried about all these things. But the thing is, you will waste time doing something wrong.\n- [Lex] Yes. - You will eventually figure out it's not right. You will accumulate scar tissue and next time you'll grow stronger\nbecause next time you'll have the scar tissue, and next time you'll learn from it. And now next time you come to a similar situation\nyou'll be like, oh, I messed up. I've spent a lot of time working on things that never materialized into anything\nand I have all that scar tissue and I have some intuitions about what was useful, what wasn't useful, how things turned out.\nSo all those mistakes were not dead work. So I just think they should just focus on working.\nWhat have you done, what have you done last week? - That's a good question actually\nto ask for a lot of things, not just machine learning. It's a good way to cut the, I forgot the term we use,\nbut the fluff, the blubber, whatever the inefficiencies in life.\nWhat do you love about teaching? You seem to find yourself often in the, drawn to teaching.\nYou're very good at it but you're also drawn to it. - Yeah, I mean I don't think I love teaching. I love happy humans and happy humans like when I teach.\n- Yes. - I wouldn't say I hate teaching, I tolerate teaching. - [Lex] Yes. - But it's not like the act of teaching that I like,\nit's that I have something, I'm actually okay at it.\n- [Lex] Yes. - I'm okay at teaching and people appreciate it a lot. - [Lex] Yeah. - And so I'm just happy to try to be helpful\nand teaching itself is not like the most, I mean it can be really annoying, frustrating.\nI was working on a bunch of lectures just now. I was reminded back to my days of 231n just how much work it is to create some of these materials\nand make them good. The amount of iteration and thought and you go down blind alleys and just how much you change it.\nSo creating something good in terms of educational value is really hard and it's not fun.\n- It's difficult. So people should definitely go watch your new stuff you put out. There are lectures where you're actually building the thing,\nlike you said, \"The code is truth.\" So discussing back-propagation by building it,\nby looking through and just the whole thing. - [Andrej] Yeah. - So how difficult is that to prepare for? I think that's a really powerful way to teach.\nDid you have to prepare for that or are you just live thinking through it? - I will typically do like say three takes\nand then I take the better take. So I do multiple takes and I take some of the better takes and then I just build out a lecture that way.\nSometimes I have to delete 30 minutes of content. - [Lex] Yeah. - Because it just went down the alley that I didn't like too much. So there's about a bunch of iteration\nand it probably takes me somewhere around 10 hours to create one hour of content. - To get one hour.\nIt's interesting. I mean is it difficult to go back to the basics? Do you draw a lot of wisdom from going back to the basics?\n- Yeah, going back to backropagation, loss functions, where they come from. And one thing I like about teaching a lot honestly is\nit definitely strengthens your understanding. So it's not a purely altruistic activity, it's a way to learn.\nIf you have to explain something to someone, you realize you have gaps in knowledge.\nAnd so I even surprised myself in those lectures like, well, the result will obviously look like this\nand then the result doesn't look like it. And I'm like, okay, I thought I understood this. - Yeah.\nWell, that's why it's really cool, they literally code, you run it in the notebook and it gives you a result\nand you're like, oh, wow. - [Andrej] Yes. - And like actual numbers, actual input, actual code. - Yeah.\nIt's not mathematical symbols, et cetera. The source of truth is the code. It's not slides, it's just like let's build it.\n- It's beautiful. You're a rare human in that sense. What advice would you give to researchers\ntrying to develop and publish an idea that have a big impact in the world of AI?\nSo maybe undergrads, maybe early-graduate students. - Yeah.\nI mean I would say they definitely have to be a little bit more strategic than I had to be as a PhD student because of the way AI is evolving,\nit's going the way of physics. Where in physics you used to be able to do experiments on your bench-top and everything was great\nand you could make progress and now you have to work in like LHC or like CERN and so AI\nis going in that direction as well. So there's certain kinds of things that's just not possible to do on the bench-top anymore.\nAnd I think that didn't used to be the case at the time. - Do you still think that there's like GAN type papers\nto be written where like very simple idea. - [Andrej] Yes. - That requires just one computer\nto illustrate a simple example? - I mean one example that's been very influential recently is diffusion models, diffusion models are amazing.\nDiffusion models are six years old. For the longest time, people were ignoring them as far as I can tell.\nAnd they're an amazing generative model, especially in images and so stable diffusion and so on,\nit's all diffusion-based. Diffusion is new, it was not there and it came from, well, it came from Google but a researcher\ncould have come up with it. In fact, some of the first, actually no, those came from Google as well.\nBut a researcher could come up with that in an academic institution. - Yeah. What do you find most fascinating about diffusion models?\nSo from the societal impact of the technical architecture. - What I like about diffusion is it works so well.\n- Is that surprising to you? The amount of the variety, almost the novelty of the synthetic data it's generating?\n- Yeah, so the stable diffusion images are incredible. It's the speed of improvement in generating images\nhas been insane. We went very quickly from generating tiny digits to tiny faces and it all looked messed up.\nAnd now we have stable diffusion and that happened very quickly. There's a lot that academia can still contribute. For example, FlashAttention is a very efficient kernel\nfor running the attention operation inside the transformer that came from academic environment.\nIt's a very clever way to structure the kernel, that's the calculation. So it doesn't materialize the attention matrix.\nAnd so, I think there's still like lots of things to contribute but you have to be just more strategic. - Do you think neural networks could be made to reason?\n- Yes. - Do you think they already reason? - Yes. - [Lex] What's your definition of reasoning?\n- Information processing. - So in the way that humans think through a problem\nand come up with novel ideas, it feels like a reasoning.\n- Yeah. - So the novelty, I don't wanna say but auto-distribution ideas, you think it's possible?\n- Yes. And I think we're seeing that already in the current neural nets. You're able to remix the training set information\ninto true generalization in some sense. - That doesn't appear- - It doesn't appear verbatim in the training set.\nYou're doing something interesting algorithmically, you're manipulating some symbols and you're coming up with some correct unique answer\nin a new setting. - What would illustrate to you, holy shit,\nthis thing is definitely thinking? - To me thinking or reasoning is just information processing and generalization.\nAnd I think the neural nets already do that today. - So being able to perceive the world or perceive the, whatever the inputs are\nand to make predictions based on that or actions based on that's reasoning?\n- Yeah. You're giving correct answers in novel settings by manipulating information.\nYou've learned the correct algorithm, you're not doing just some kind of a lookup table and nearest neighbor search. Something like that.\n"}
{"pod": "Lex Fridman Podcast", "input": "Artificial general intelligence", "output": "- Let me ask you about AGI. What are some moonshot ideas you think might make significant progress towards AGI\nand maybe another way is, what are the big blockers that we're missing now? - So basically, I am fairly bullish on our ability\nto build AGIs, basically automated systems that we can interact with that are very human-like\nand we can interact with them in a digital realm or a physical realm. Currently, it seems most of the models\nthat do these magical tasks are in a text realm.\nI think, as I mentioned, I'm suspicious that text realm is not enough to actually build full understanding\nof the world. I do actually think you need to go into pixels and understand the physical world and how it works.\nSo I do think that we need to extend these models to consume images and videos and train on a lot more data\nthat is multimodal in that way. - Do you think you need to touch the world to understand it also? - Well, that's the big open question\nI would say in my mind, is if you also require the embodiment and the ability to interact with the world,\nrun experiments and have a data of that form, then you need to go to Optimus or something like that.\n- [Lex] Yeah. - And so I would say Optimus in some way is like a hedge\nin AGI because it seems to me that it's possible that just having data from the internet is not enough.\nIf that is the case, then Optimus may lead to AGI. Because Optimus would, to me,\nthere's nothing beyond Optimus. You have like this humanoid form factor that can actually do stuff in the world. You can have millions of them\ninteracting with humans and so on. And if that doesn't give a rise to AGI at some point,\nI'm not sure what will. So from a completeness perspective, I think that's a really good platform\nbut it's a much more harder platform because you are dealing with atoms and you need to actually build these things\nand integrate them into society. So I think that path takes longer but it's much more certain.\nAnd then there's a path of the internet and just training these compression models effectively on trying to compress all the internet.\nAnd that might also give these agents as well. - Compress the internet but also interact with the internet.\n- [Andrej] Yeah. - So it's not obvious to me. In fact, I suspect you can reach AGI\nwithout ever entering the physical world, which is a little bit more concerning\nbecause that results in it happening faster.\nSo it just feels like we're in boiling water. We won't know as it's happening.\nI would like to, I'm not afraid of AGI, I'm excited about it. There's always concerns\nbut I would like to know when it happens. - [Andrej] Yeah. - And have like hints about when it happens,\nlike a year from now it will happen, that kind of thing. - [Andrej] Yeah. - I just feel like in the digital realm it just might happen.\n- Yeah. I think all we have available to us because no one has built AGI again, so all we have available to us is,\nis there enough fertile ground on the periphery? I would say, yes. And we have the progress so far, which has been very rapid and there are next steps\nthat are available. And so I would say, yeah, it's quite likely that we'll be interacting with digital entities.\n- How will you know that somebody has built AGI? - I think it's going to be a slow incremental transition.\nIt's going to be product-based and focused. It's going to be GitHub Copilot going better. And then GPTs helping you write and then these oracles\nthat you can go to with mathematical problems. I think we're on a verge of being able to ask very complex questions in chemistry, physics,\nmath of these oracles and have them complete solutions. - So AGI to use primarily focused on intelligence\nso consciousness doesn't enter into it.\n- So in my mind, consciousness is not a special thing you will figure out and bolt on. I think it's an emergent phenomenon of a large enough\nand complex enough generative model sort of. So if you have a complex enough world model\nthat understands the world, then it also understands its predicament in the world as being a language model,\nwhich to me is a form of consciousness or self-awareness. - So in order to understand the world deeply\nyou probably have to integrate yourself into the world. - [Andrej] Yeah. - And in order to interact with humans and other living beings,\nconsciousness is a very useful tool. - Yeah. I think consciousness is like a modeling insight.\n- Modeling insight. - Yeah. You have a powerful enough model of understanding the world that you actually understand\nthat you are an entity in it. - Yeah. But there's also this, perhaps just a narrative we tell ourselves, it feels like something\nto experience the world, the hard problem of consciousness. - [Andrej] Yeah. - But that could be just a narrative that we tell ourselves.\n- Yeah. I don't think we'll, yeah, I think it will emerge. I think it's going to be something very boring. We'll be talking to these digital AIs,\nthey will claim they're conscious, they will appear conscious, they will do all the things that you would expect of other humans\nand it's going to just be a stalemate. - I think there will be a lot of actual fascinating ethical questions,\nlike supreme court level questions of whether you're allowed to turn off a conscious AI,\nif you're allowed to build a conscious AI, maybe there would have to be the same kind of debates\nthat you have around, sorry to bring up a political topic, but abortion, which is the deeper question with abortion\nis what is life? And the deep question with AI is also,\nwhat is life and what is conscious? - [Andrej] Right. - And I think that'll be very fascinating\nto bring up, it might become illegal to build systems that are capable of such level of intelligence\nthat consciousness would emerge and therefore the capacity to suffer would emerge. And a system that says, no, please don't kill me.\n- Well, that's what the LaMDA chatbot already told this Google engineer, right?\nIt was talking about not wanting to die or so on. - So that might become illegal to do that.\n- [Andrej] Right. - 'Cause otherwise, you might have a lot of creatures\nthat don't want to die and they will- - [Andrej] You can just spawn infinity of them on a cluster.\n- And then that might lead to horrible consequences. 'Cause then there might be a lot of people that secretly love murder\nand they'll start practicing murder on those systems. I mean there's just, to me all of this stuff just brings\na beautiful mirror to the human condition and human nature and we get to explore it. - [Andrej] Yes.\n- And that's what like the best of the supreme court of all the different debates we have about ideas\nof what it means to be human, we get to those deep questions that we've been asking throughout human history.\nThere's always been the other in human history. We're the good guys and that's the bad guys\nand we're going to throughout human history, let's murder the bad guys. And the same will probably happen with robots.\nIt'll be the other at first. And then we'll get to ask questions, that what does it mean to be alive? What does it mean to be conscious?\n- Yep. And I think there's some canary in the coal mines even with what we have today. And for example, there's these waifus\nthat you can work with and some people are trying to, this company's going to shut down, but this person really loved their waifu\nand is trying to like port it somewhere else. And it's not possible. And I think definitely people will have feelings\ntowards these systems because in some sense they are like a mirror of humanity\nbecause they are like a big average of humanity. - [Lex] Yeah. - In a way that it's trained.\n- But that average, we can actually watch. It's nice to be able to interact\nwith the big average of humanity. - [Andrej] Yeah. - And do a search query on it. - Yeah. Yeah.\nIt's very fascinating. And we can also of course, also shape it. It's not just a pure average. We can mess with the training data,\nwe can mess with the objective, we can fine-tune them in various ways. So we have some impact on what those systems look like.\n- If you want to achieve AGI and you could have a conversation with her\nand ask her, talk about anything, maybe ask her a question. What kind of stuff would you ask?\n- I would've some practical questions in my mind like do I or my loved ones really have to die?\nWhat can we do about that? - Do you think it will answer clearly or would it answer poetically?\n- I would expect it to give solutions. I would expect it to be like, well, I've read all of these textbooks and I know all these things\nthat you've produced and it seems to me like here are the experiments that I think it would be useful to run next. And here are some gene therapies\nthat I think would be helpful, and here are the kinds of experiments that you should run. - Okay, let's go with this thought experiment.\nOkay. Imagine that mortality is actually\na prerequisite for happiness. So if we become immortal,\nwe'll actually become deeply unhappy and the model is able to know that. So what is it supposed to tell you?\nA stupid human about it? Yes, you can become a mortal but you'll become deeply unhappy. If the AGI system is trying to empathize with you human,\nwhat is it supposed to tell you. That yes, you don't have to die but you're really not gonna like it?\nIs it gonna be deeply honest? There's an \"Interstellar\", what is it the AI says like humans want 90% honesty.\nSo you have to pick how honest do I want to answer these practical questions? - Yeah. I love AI \"Interstellar\" by the way.\nI think it's like such a sidekick to the entire story but at the same time, it's really interesting.\n- It's kind of limited in certain ways, right? - Yeah, it's limited and I think that's totally fine by the way.\nI think it's fine and plausible to have a limited and imperfect AGIs.\n- Is that a feature almost? - As an example, it has a fixed amount of compute on its physical body.\nAnd it might just be that even though you can have a super amazing mega brain, super-intelligent AI,\nyou also can have less intelligent AI that you can deploy in a power-efficient way.\nAnd then they're not perfect, they might make mistakes. - No, I meant more like say you had infinite compute\nand it's still good to make mistakes sometimes. In order to integrate yourself. Like, what is it?\nGoing back to \"Goodwill Hunting\", Robin Williams character says the human imperfections, that's good stuff, right?\nWe don't want perfect, we want flaws in part to form connections with each other.\n'Cause it feels like something you can attach your feelings to, the flaws.\nIn that same way you want an AI that's flawed. I don't know. I feel like perfection is cold.\n- [Andrej] Okay, yeah. - But that's not AGI. But see AGI would need to be intelligent enough\nto give answers to humans that humans don't understand. And I think perfect is something humans can't understand\nbecause even science doesn't give perfect answers. There's always gaps and mysteries and I don't know,\nI don't know if humans want perfect. - Yeah, I could imagine just having a conversation\nwith this oracle entity as you'd imagine them and yeah, maybe it can tell you about,\nbased on my analysis of human condition, you might not want this and here are some of the things that might-\n- But every dumb human will say, yeah, yeah, yeah, yeah, trust me, give me the truth, I can handle it.\n- But that's the beauty, like people can choose. - But then, it's the old marshmallow test\nwith the kids and so on, I feel like too many people can't handle the truth, probably including myself.\nDeep truth to the human condition. I don't know if I can handle it. What if there's some dark stuff?\nWhat if we are an alien science experiment and it realizes that. What if it hacked, I mean?\n- I mean, this is \"The Matrix\" all over again. - \"The Matrix\", I don't know, what would I talk about?\nI don't even, yeah, probably I will go with the safer scientific questions at first\nthat have nothing to do with my own personal life. - [Andrej] Yeah. - Immortality just like about physics and so on.\n- [Andrej] Yeah. - To build up see where it's at or maybe see if it has a sense of humor.\nThat's another question. Presumably in order to, if it understands humans deeply,\nwould it able to generate humor.\n- Yeah. I think that's actually a wonderful benchmark almost, like is it able, I think that's a really good point, basically.\n- [Lex] To make you laugh. - Yeah. If it's able to be a very effective standup comedian that is doing something very interesting computationally.\nI think being funny is extremely hard. - Yeah, because it's hard in a way like a touring test,\nthe original intent of the touring test is hard because you have to convince humans and that's why comedians talk about this,\nlike this is deeply honest. 'Cause if people can't help but laugh and if they don't laugh that means you're not funny,\nif they laugh, it's funny. - Yeah. And you're showing, you need a lot of knowledge to create humor about like you mentioned\nhuman condition and so on. And then you need to be clever with it. - You mentioned a few movies, you Tweeted, \"Movies that I've seen five-plus times\n"}
{"pod": "Lex Fridman Podcast", "input": "Movies", "output": "but am ready and willing to keep watching: 'Interstellar', 'Gladiator', 'Contact', 'Goodwill Hunting',\n'The Matrix', 'Lord of the Rings', all three, 'Avatar', 'Fifth Element',\" and so on, it goes on, \"'Terminator 2'.\"\n\"Mean Girls\" I'm not gonna ask about that one. - \"Mean Girls\" is great.\n- What are some that jump out to you in your memory that you love and why?\nYou mentioned \"The Matrix\" as a computer person, why do you love \"The Matrix\"?\n- There's so many properties that make it beautiful and interesting. So there's all these philosophical questions but then there's also AGIs, and there's simulation,\nand it's cool, and there's the black. - [Lex] The look of it, the feel of it.\n- Yeah. The look of it, the feel of it, the action, the bullet time. It was just like innovating in so many ways.\n- And then \"Goodwill Hunting\". Why do you like that one? - Yeah, I really like this tortured genius character\nwho's grappling with whether or not he has any responsibility or what to do\nwith this gift that he was given or how to think about the whole thing and- - But there's also a dance between the genius\nand the personal, like what it means to love another human being. - Yeah.\nThere's a lot of themes there. It's just a beautiful movie. - And then the fatherly figure, the mentor and the psychiatrist.\n- It really messes with you. There's some movies that just like really mess with you\non a deep level. - Do you relate to that movie at all? - No. - It's not your fault Andrej, as I said.\n\"Lord of the Rings\", that's self-explanatory. \"Terminator 2\", which is interesting,\nyou rewatch that a lot. Is that better than Terminator one? You don't like Arnold as he comes back?\n- I do like Terminator one as well. I like \"Terminator 2\" a little bit more. But in terms of its surface properties.\n- Do you think Skynet is at all a possibility? - Yes. - Like the actual autonomous weapon system kind of thing?\nDo you worry about that stuff? So AI being used for war? - I a hundred percent worry about it.\nAnd so the, I mean, some of these fears of AGIs and how this will plan out, I mean these will be\nvery powerful entities probably at some point. And so for a long time, there are going to be tools in the hands of humans.\nPeople talk about alignment of AGIs and how to make, the problem is even humans are not aligned.\nSo how this will be used and what this is gonna look like is, yeah, it's troubling.\n- Do you think it'll happen slowly enough that we'll be able to as a human civilization\nthink through the problems? - Yes, that's my hope, is that it happens slowly enough and in an open enough way where a lot of people can see\nand participate in it. Just to figure out how to deal with this transition, I think, which is gonna be interesting.\n- I draw a lot of inspiration from nuclear weapons 'cause I sure thought it would be fucked\nonce they develop nuclear weapons. But it's almost like when the systems are not so dangerous\nthey destroy human civilization. We deploy them and learn the lessons and then we quickly,\nif it's too dangerous we quickly, quickly, we might still deploy it but you very quickly learn\nnot to use them. And so there'll be like this balance achieved, humans are very clever as a species. It's interesting, we exploit the resources as much as we can\nbut we avoid destroying ourselves it seems like. - Yeah. Well, I dunno about that actually.\n- I hope it continues. - I mean I'm definitely like concerned about nuclear weapons and so on,\nnot just as a result of the recent conflict, even before that. That's probably like my number one concern for humanity.\n- So if humanity destroys itself or destroys 90% of people\nthat would be because of nukes? - Yeah, I think so. And it's not even about full destruction,\nto me, it's bad enough if we reset society, that would be terrible. That would be really bad. And I can't believe we're so close to it.\n- [Lex] Yeah. - It's like so crazy to me. - It feels like we might be a few Tweets away from something like that. - Yep.\nBasically, it's extremely unnerving and has been for me for a long time. - It seems unstable that world leaders\njust having a bad mood can take one step\ntowards a bad direction and then it escalates. - Yeah. - And because of a collection of bad moods,\nit can escalate without being able to stop. - Yeah.\nIt's a huge amount of power. And then also with the proliferation and basically, I don't actually really see,\nI don't actually know what the good outcomes are here, so I'm definitely worried about that a lot. And then AGI is not currently there\nbut I think at some point it will more and more become something like it. The danger with AGI even is that\nI think it's even slightly worse in the sense that there are good outcomes of AGI\nand then the bad outcomes are an epsilon way, like a tiny run away. And so I think capitalism and humanity, and so on\nwill drive for the positive ways of using that technology. But then if bad outcomes are just like a tiny,\nlike flip a minus sign away, that's a really bad position to be in. - A tiny perturbation of the system\nresults in the destruction of the human species. - [Andrej] Yeah. - It's a weird line to walk. - Yeah, I think in general what's really weird\nabout the dynamics of humanity and this explosion we talked about is just the insane coupling afforded by technology.\n- [Lex] Yeah. - And just the instability of the whole dynamical system. I think it doesn't look good, honestly.\n- Yes. That explosion could be destructive or constructive and the probabilities are non-zero in both ends of it.\n- I'm gonna have to, I do feel like I have to try to be optimistic and so on and I think even in this case I still am predominantly optimistic but there's definitely-\n"}
{"pod": "Lex Fridman Podcast", "input": "Future of human civilization", "output": "- Me too. Do you think we'll become a multi-planetary species? - Probably, yes.\nBut I don't know if it's dominant feature of future humanity. There might be some people on some planets and so on\nbut I'm not sure if it's like, yeah, if it's like a major player in our culture and so on.\n- We still have to solve the drivers of self-destruction here on earth. So just having a backup on Mars\nis not gonna solve the problem. - So by the way, I love the backup on Mars. I think that's amazing. We should absolutely do that.\n- [Lex] Yes. - And I'm so thankful. - Would you go to Mars? - Personally, no, I do like earth quite a lot.\n- Okay. I'll go to Mars. I'll go for you. I'll Tweet at you from there. - Maybe eventually I would, once it's safe enough.\nBut I don't actually know if it's on my lifetime scale unless I can extend it by a lot.\nI do think that for example, a lot of people might disappear into virtual realities and stuff like that and I think that could be the major thrust\nof the cultural development of humanity if it survives. So it might not be, it's just really hard to work\nin physical realm and go out there and I think ultimately all your experiences are in your brain.\n- [Lex] Yeah. - And so it's much easier to disappear into digital realm and I think people will find them more compelling, easier,\nsafer, more interesting. - So you're a little bit captivated by virtual reality, by the possible worlds, whether it's the metaverse\nor some other manifestation of that? - [Andrej] Yeah. - Yeah. It's really interesting.\nI'm interested, just talking a lot to Carmack, where's the thing that's currently preventing that?\n- Yeah, I mean to be clear, I think what's interesting about the future is it's not that, I feel like\nthe variance in the human condition grows. That's the primary thing that's changing. It's not as much the mean of the distribution,\nit's like the variance of it. So there will probably be people on Mars and there will be people in VR, and there will people here on earth.\nIt's just like there will be so many more ways of being. And so feel like, I see it as like a spreading out\nof a human experience. - There's something about the internet that allows you to discover those little groups and you gravitate to, something about your biology\nlikes that kind of world and you find each other. - Yeah. And we'll have trans-humanists and then we'll have the Amish and everything is just gonna coexist.\n- Yeah. The cool thing about it 'cause I've interacted with a bunch of internet communities is they don't know about each other.\nLike you can have a very happy existence just having a very close-knit community and not knowing about each other.\nI mean even you even sense this, just having traveled to Ukraine, they don't know so many things about America.\n- [Andrej] Yeah. - When you travel across the world I think you experience this too. There are certain cultures that are like,\nthey have their own thing going on, they don't. And so you can see that happening more and more and more\nand more in the future. We have little communities. - Yeah. Yeah. I think so. That seems to be how it's going right now.\nAnd I don't see that trend really reversing. I think people are diverse and they're able to choose their own path in existence and I celebrate that.\nAnd so- - Will you spend some, much time in the metaverse, in the virtual reality? Or which community are you,\nare you the physicalist, the physical reality enjoyer\nor do you see drawing a lot of pleasure and fulfillment in the digital world?\n- Yeah, I think, well currently, the virtual reality is not that compelling. - [Lex] Yes. - I do think it can improve a lot\nbut I don't really know to what extent. Maybe there's actually even more exotic things you can think about with neural links or stuff like that.\nSo currently, I kind of see myself as mostly a team, human person, I love nature.\n- [Lex] Yeah. - I love harmony, I love people, I love humanity. I love emotions of humanity and I just want to be\nin this solar punk little utopia. That's my happy place. - [Lex] Yes. - My happy place is people I love,\nthinking about cool problems, surrounded by a lush, beautiful dynamic nature. - [Lex] Yeah. - And secretly high-tech in places that count.\n- Places that count. So you use technology to empower that love for other humans and nature.\n- Yeah, I think a technology used very sparingly. I don't love when it gets in the way of humanity\nin many ways. I like just people being humans in a way, we slightly evolved and prefer I think\njust by default. - People kept asking me 'cause they know you love reading. Are there particular books that you enjoyed\n"}
{"pod": "Lex Fridman Podcast", "input": "Book recommendations", "output": "that had an impact on you for silly or for profound reasons that you would recommend?\nYou mentioned \"The Vital Question\". - Many, of course. I think in biology as an example, \"The Vital Question\" is a good one.\nAnything by Nick Lane really, \"Life Ascending\" I would say is a bit more potentially representative\nas like a summary of a lot of the things he's been talking about. I was very impacted by \"The Selfish Gene\".\nI thought that was a really good book, it helped me understand altruism as an example and where it comes from. And just realizing that the selection\nand the levels of genes was a huge insight for me at the time and it cleared up a lot of things for me. - What do you think about the idea\nthat ideas are the organisms, the memes? - Yeah. Love it. A hundred percent.\n- Are you able to walk around with that notion for a while? That there's an evolutionary kind of process\nwith ideas as well? - There absolutely is. There's memes just like genes and they compete and they live in our brains.\nIt's beautiful. - Are we silly humans thinking that we are the organisms? Is it possible that the primary organisms are the ideas?\n- Yeah, I would say like the ideas kind of live in the software of our civilization in the minds\nand so on. We think as humans that the hardware is the fundamental thing. I human is a hardware entity.\n- [Andrej] Yeah. - But it could be the software, right? - Yeah. Yeah.\nI would say there needs to be some grounding at some point to a physical reality. - Yeah, but if we clone an Andrej,\nthe software is a thing that makes that thing special. Right?\n- Yeah. I guess you're right. - But then cloning might be exceptionally difficult. There might be a deep integration between the software and the hardware\nin ways we don't quite yet understand. - Well, from the altruism point of view, what makes me special is more the gang of genes\nthat are riding in my chromosomes I suppose. Right? They're the replicating unit I suppose-\n- No, but that's just the compute, the thing that makes you special, sure. Well, the reality is what makes you special\nis your ability to survive based on the software that runs on the hardware that was built by the genes.\nSo the software is the thing that makes you survive. Not the hardware or- - It's a little bit of both. It's just like a second layer.\nIt's a new second layer that hasn't been there before the brain. They both coexist. - But there's also layers of the software.\nI mean it's an abstraction on top of abstractions.\nOkay, \"Selfish Gene\". - So \"Selfish Gene\", Nick Lane. I would say sometimes books are not sufficient.\nI like to reach for textbooks sometimes. I feel like books are for too much\nof a general consumption sometime and they're too high up in the level of abstraction and it's not good enough.\n- [Lex] Yeah. - So I like textbooks, I like \"The Cell\". I think \"The Cell\" was pretty cool.\nThat's why also I like the writing of Nick Lane is because he's pretty willing to step one level down\nand he doesn't, yeah, he's willing to go there but he's also willing to be throughout the stack.\nSo he'll go down to a lot of detail but then he will come back up and I think he has a, yeah, basically, I really appreciate that.\n- That's why I love college, early college, even high school, just textbooks on the basics of computer science, of mathematics,\nof biology, of chemistry. - [Andrej] Yes. - Those are, they condense down, it's sufficient in general\nthat you can understand both the philosophy and the details but also you get homework problems\nand you get to play with it as much as you would if you were in programming stuff. - Yeah.\nAnd then I'm also suspicious of textbooks honestly because as an example in deep-learning there's no amazing textbooks and the field is changing very quickly.\nI imagine the same is true in say synthetic biology and so on, these books like \"The Cell\" are kind of outdated.\nThey're still high-level, like what is the actual real source of truth? It's people in wet labs working with cells.\n- Yeah. - Sequencing genomes and, yeah, actually working with it.\nAnd I don't have that much exposure to that or what that looks like. So I still don't fully, I'm reading through the cell\nand it's kind of interesting, and I'm learning but it's still not sufficient I would say in terms of understanding. - Well, it's a clean summarization\nof the mainstream narrative. - [Andrej] Yeah. - But you have to learn that before you break out.\n- [Andrej] Yeah, - Towards the cutting edge. - Yeah. But what is the actual process of working with these cells and growing them and incubating them\nand it's like a massive cooking recipe. So making sure your cell slows and proliferate and then you're sequencing them, running experiments\nand just how that works, I think is the source of truth of at the end of the day what's really useful\nin terms of creating therapies and so on. - Yeah. I wonder what in the future AI textbooks will be\n'cause you know there's \"Artificial Intelligence: A Modern Approach\". I actually haven't read, if it's come out, the recent version, there's been a recent edition.\nI also saw there's a science of deep learning book. I'm waiting for textbooks that are worth recommending, worth reading.\n- [Andrej] Yeah. - It's tricky 'cause it's like papers and code, code, code. - Honestly, I find papers are quite good.\nI especially like the appendix of any paper as well. It's like the most detail you can have.\n- It doesn't have to be cohesive, connected to anything else. You just described me a very specific way you saw the particular thing.\nYeah. - Yeah, many times papers can be actually quite readable, not always, but sometimes the introduction and the abstract is readable even for someone outside of the field.\nThis is not always true and sometimes I think, unfortunately, scientists use complex terms even when it's not necessary.\nI think that's harmful. I think there's no reason for that. - And papers sometimes are longer than they need to be\nin the parts that don't matter. - [Andrej] Yeah. - The appendix should be long but then the papers itself, look at Einstein,\nmake it simple. - Yeah. But certainly, I've come across papers I would say, say like synthetic biology or something that I thought were quite readable for the abstract\nand the introduction and then you're reading the rest of it and you don't fully understand but you kind of are getting a gist and I think it's cool.\n"}
{"pod": "Lex Fridman Podcast", "input": "Advice for young people", "output": "- You give advice to folks interested in machine learning and research but in general life advice\nto a young person, high school, early college about how to have a career they can be proud of\nor a life they can be proud of? - Yeah, I think I'm very hesitant to give general advice.\nI think it's really hard. I've mentioned, some of the stuff I've mentioned is fairly general, I think. Like focus on just the amount of work you're spending\non like a thing. Compare yourself only to yourself, not to others. - [Lex] That's good. - [Andrej] I think those are fairly general.\n- How do you pick the thing? - You just have like a deep interest in something\nor try to find the argmax over the things that you're interested in. - Argmax at that moment and stick with it.\n- [Lex] Yeah. - How do you not get distracted and switch to another thing? - You can if you like.\n- Well, if you do an argmax repeatedly every week, every month. - [Andrej] Yeah, it doesn't converge. - It's a problem.\n- Yeah. You can like low-pass filter yourself in terms of what has consistently been true for you.\nBut yeah, I definitely see how it can be hard but I would say you're going to work the hardest on the thing that you care about the most.\nSo low pass filter yourself and really introspect in your past, what are the things that gave you energy\nand what are the things that took energy away from you? Concrete examples. And usually, from those concrete examples,\nsometimes patterns can merge. I like it when things look like this when I'm in these positions. - So that's not necessarily the field\nbut the kind of stuff you're doing in a particular field. So for you, it seems like you were energized by implementing stuff, building actual things.\n- Yeah, being low-level, learning and then also communicating so that others can go through\nthe same realizations and shortening that gap. Because I usually have to do way too much work to understand a thing and then I'm like, okay,\nthis is actually like, okay, I think I get it and like why was it so much work? It should have been much less work.\nAnd that gives me a lot of frustration and that's why I sometimes go teach. - So aside from the teaching you're doing now,\n"}
{"pod": "Lex Fridman Podcast", "input": "Future of machine learning", "output": "putting out videos, aside from a potential \"Godfather II\"\nwould the AGI at Tesla and beyond, what does the future for Andrej Karpathy hold, have you figured that out yet or no?\nI mean as you see through the fog of war that is all of our future, do you start seeing silhouettes\nof what that possible future could look like? - The consistent thing I've been always interested in,\nfor me at least is Ai. And that's probably what I'm spending the rest of my life on\nbecause I just care about it a lot. And I actually care about many other problems as well. Like say aging, which I basically view as disease\nand I care about that as well. But I don't think it's a good idea to go after it, specifically.\nI don't actually think that humans will be able to come up with the answer. I think the correct thing to do is to ignore those problems\nand you solve AI and then use that to solve everything else. And I think there's a chance that this will work. I think it's a very high chance\nand that's the way I'm betting at least. - So when you think about AI,\nare you interested in all kinds of applications? - [Andrej] Yes. - All kinds of domains.\nAnd any domain you focus on will allow you to get insights to the big problem of AGI? - Yeah, for me it's the ultimate meta-problem.\nI don't wanna work on any one specific problem, there's too many problems. So how can you work on all problems simultaneously? You solve the meta-problem, which to me is just intelligence\nand how do you automate it? - Is there cool small projects like arxiv-sanity\nand so on that you're thinking about that ML world can anticipate.\n- There's always some fun side projects. - [Lex] Yeah. - arxiv-sanity is one, yeah, basically, there's way too many archive papers,\nhow can I organize it and recommend papers and so on. I transcribed all of your podcasts.\n- What did you learn from that experience, from transcribing the process of like\nyou consuming audiobooks and podcasts and so on? - [Andrej] Yeah. - And here's a process that achieves\ncloser to human-level performance on annotation. - Yeah, well, I definitely was surprised that transcription with OpenAI Whisper\nwas working so well compared to what I'm familiar with, from Siri and a few other systems I guess, it works so well.\nAnd that's what gave me some energy to try it out. And I thought it could be fun to run on podcasts.\nIt's not obvious to me why Whisper is so much better compared to anything else because I feel like\nthere should be a lot of incentive for a lot of companies to produce transcription systems and that they've done so over a long time. Whisper is not a super exotic model, it's a transformer,\nit takes mel spectrograms and it just outputs tokens of text. It's not crazy.\nThe model and everything has been around for a long time. I'm not actually a hundred percent sure why this came about. - Yeah, it's not obvious to me either.\nIt makes me feel like I'm missing something for the middle. - [Andrej] I'm missing something. - Yeah, because there is a huge, even Google and so on,\nYouTube transcription. - [Andrej] Yeah. - Yeah. It's unclear. But some of it is also integrating into a bigger system.\n- [Andrej] Yeah. - So the user interface, how it's deployed and all that kind of stuff. Maybe running it as an independent thing is much easier,\nlike an order of magnitude easier than deploying it to a large integrated system like YouTube transcription, or anything,\nlike meetings, like Zoom has transcription, that's kind of crappy.\nBut creating interface where it detects the different individual speakers, it's able to display it in compelling ways,\nrun it real-time, all that kind of stuff. Maybe that's difficult. That's the only explanation I have\nbecause I'm currently paying quite a bit for human transcription, human caption.\n- [Andrej] Right. - Annotation. And like it seems like there's a huge incentive to automate that.\n- [Andrej] Yeah. - It's very confusing. - And I think, I mean, I dunno if you looked at some of the Whisper transcripts, but they're quite good. - They're good.\nAnd especially in tricky cases. - [Andrej] Yeah. - I've seen Whisper's performance on super tricky cases\nand it does incredibly well. So I don't know, a podcast is pretty simple. It's like high-quality audio\nand you're speaking usually pretty clearly. - [Andrej] Yeah. - And so I don't know,\nI don't know what OpenAIs plans are either. - But yeah, there's always fun projects basically.\nAnd stable diffusion also is opening up a huge amount of experimentation I would say in the visual realm and generating images, and videos, and movies ultimately.\n- [Lex] Yeah, videos now. - And so that's going to be pretty crazy. That's going to almost certainly work\nand it's going to be really interesting when the cost of content creation is going to fall to zero. You used to need a painter for a few months to paint a thing\nand now it's going to be speak to your phone to get your video. - So if Hollywood will start using that to generate scenes\nwhich completely opens up. Yeah. So you can make a movie like \"Avatar\" eventually\nfor under a million dollars. - Much less maybe just by talking to your phone. I mean, I know it sounds kind of crazy.\n- And then there'd be some voting mechanism, would there be a show on Netflix that's generated completely automatedly?\nSemi-automatedly? - Yeah, potentially. Yeah. And what does it look like also when you can just generate it on demand\nand there's infinity of it? - Yeah.\nOh, man. All the synthetic content. I mean it's humbling because we treat ourselves as special\nfor being able to generate art, and ideas, and all that kind of stuff. If that can be done in an automated way by Ai.\n- Yeah. I think it's fascinating to me how these, the predictions of AI and what it's going to look like and what it's going to be capable of\nare completely inverted and wrong. And sci-fi of fifties and sixties, were just totally not right.\nThey imagine AI is like super calculating, theorem provers, and we're getting things that can talk to you about emotions.\nThey can do art, it's just weird. - Are you excited about that future? just AI's, like hybrid systems, heterogeneous systems\nof humans and AIs talking about emotions, Netflix and chill with an AI system.\nOr the Netflix thing you watch is also generated by AI? - I think it's going to be interesting for sure\nand I think I'm cautiously optimistic but it's not obvious. - Well, the sad thing is your brain and mine developed\nin a time before Twitter, before the internet.\nSo I wonder people that are born inside of it might have a different experience. Like I, and maybe you will still resist it\nand the people born now will not. - Well, I do feel like humans are extremely malleable. - [Lex] Yeah.\n- And you're probably right. - What is the meaning of life, Andrej?\n"}
{"pod": "Lex Fridman Podcast", "input": "Meaning of life", "output": "We talked about the universe having a conversation with us humans\nor with the systems we create to try to answer. For the creator of the universe to notice us,\nwe're trying to create systems that are loud enough to answer back.\n- I dunno if that's the meaning of life. That's like meaning of life for some people. The first level answer I would say is anyone can choose their own meaning of life\nbecause we are a conscious entity and it's beautiful, number one. But I do think that a deeper meaning of life\nif someone is interested is along the lines of like, what the hell is all this? And like why?\nAnd if you look into fundamental physics and the quantum field theory and the standard model, they're very complicated.\nAnd there's this 19 free parameters of our universe\nand what's going on with all this stuff and why is it here? And can I hack it? Can I work with it?\nIs there a message for me? Am I supposed to create a message? And so I think there's some fundamental answers there\nbut I think there's actually even like, you can't actually really make dent in those without more time.\nAnd so to me also there's a big question around just getting more time, honestly. Yeah.\nThat's what I think about quite a bit as well. - So kind of the ultimate, or at least first way to sneak up to the why question\nis to try to escape the system, the universe?\n- [Andrej] Yeah. - And then for that you backtrack and say, okay, for that, that's gonna take a very long time.\nSo the why question boils down from an engineering perspective to how do we extend? - Yeah.\nI think that's the question number one, practically speaking, because you're not gonna calculate the answer to the deeper questions in the time you have.\n- And that could be extending your own lifetime or extending just the lifetime of human civilization.\n- Of whoever wants to, many people might not want that. - [Lex] Yeah. - But I think people who do want that,\nI think it's probably possible, and I don't know that people fully realize this.\nI feel like people think of death as an inevitability but at the end of the day, this is a physical system.\nSome things go wrong. It makes sense why things like this happen, evolutionarily speaking,\nand there's most certainly interventions that mitigate it. - That would be interesting if death is eventually looked at\nas a fascinating thing that used to happen to humans. - I don't think it's unlikely.\nI think it's likely. - And it's up to our imagination to try to predict\nwhat the world without death looks like. - [Andrej] Yeah. - It's hard to, I think the values will completely change.\n- Could be, I don't really buy all these ideas that, oh, without death, there's no meaning, there's nothingness.\nI don't intuitively buy all those arguments. I think there's plenty of meaning, plenty of things to learn.\nThey're interesting, exciting. I want to know, I want to calculate, I want to improve the condition of all the humans\nand organisms that are alive. - Yeah. The way we find meaning might change. There is a lot of humans, probably including myself,\nthat finds meaning in the finiteness of things, but that doesn't mean that's the only source of meaning.\n- Yeah. I do think many people will go with that, which I think is great. I love the idea that people\ncan just choose their own adventure. You are born as a conscious, free entity by default.\nI'd like to think. - [Lex] Yeah. - And you have your unalienable rights for life.\n- In the pursuit of happiness? I don't know if you that, and the nature, the landscape of happiness.\n- And you can choose your own adventure, mostly. And that's not fully true but. - I'm still am pretty sure I'm an NPC,\nbut an NPC can't know it's an NPC.\nThere could be different degrees and levels of consciousness. I don't think there's a more beautiful way to end it.\nAndrej, you're an incredible person. I'm really honored you would talk with me, everything you've done for the machine learning world,\nfor the AI world to just inspire people, to educate millions of people.\nIt's been great and I can't wait to see what you do next. It's been an honor, man. Thank you so much for talking today.\n- Awesome. Thank you. Thanks for listening to this conversation with Andrej Karpathy, to support this podcast\nplease check out our sponsors in the description. And now, let me leave you some words from Samuel Karlin,\n\"The purpose of models is not to fit the data but to sharpen the questions.\"\nThanks for listening and hope to see you next time.\n"}
