What are the different ways you think?
aji might go wrong
That concern you you said that
Uh fear a little bit of fear is very appropriate here
He's been very transparent bob being mostly excited but also scared
I think it's weird when people like think it's like a big dunk that I say like i'm a little bit afraid
And I think it'd be crazy not to be a little bit afraid
And I empathize with people who are a lot afraid
What do you think about that moment of a system becoming super intelligent do you think you would know?
The current worries that I have are that
They're going to be disinformation problems or economic shocks
or something else
at a level far beyond
anything we're prepared for
And that doesn't require super intelligence. That doesn't require a super deep alignment problem in the machine waking up and trying to deceive us
And I don't think that gets
enough attention
I mean it's starting to get more I guess
so these systems
deploy the scale
can um
shift
The winds of geopolitics and so on. How would we know if like on twitter we were mostly having
like llms direct the
Whatever's flowing through that hive mind
Yeah on twitter and then perhaps beyond and then as on twitter so everywhere else eventually
Yeah, how would we know my statement is we wouldn't
And that's a real danger
How do you prevent that danger? I think there's a lot of things you can try
um
but
At this point it is a certainty
There are soon going to be a lot of capable open-source llms with very few to none. No safety controls on them
and so
You can try with regulatory approaches
You can try with using more powerful ais to detect this stuff happening
Um, i'd like us to start trying a lot of things very soon
How do you under this pressure that there's going to be a lot of?
